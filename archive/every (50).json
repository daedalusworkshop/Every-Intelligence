{
  "metadata": {
    "total_articles": 50,
    "scraped_at": "2025-06-10 23:14:00",
    "source": "every.to",
    "scraper_version": "1.0.0"
  },
  "articles": [
    {
      "url": "https://every.to/also-true-for-humans/how-to-become-an-expert-at-anything-with-ai-d29bbe6b-3fab-4a9d-b211-7fdf4991f667",
      "title": "How to Become an Expert at Anything With AI",
      "author": "Michael Taylor",
      "author_url": "/@mike_2114",
      "publication_date": "June 26, 2024",
      "content": "How to Become an Expert at Anything With AI\n\nUsing ChatGPT and Claude for memetic analysis\n\nThis week we’re bringing you some of our best writing on practical applications of AI by Michael Taylor, whose new column, Also True for Humans, examines how we manage AI tools like we would human coworkers. (He’s also the co-author of a new book, Prompt Engineering for Generative AI.) Up today is this tactical piece about how AI is helping us redefine expertise.—Kate Lee\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nBeginners come at problems from a very different place. They have to. Without the benefit of experience, they can’t rely on intuition, and must make decisions slowly and deliberately in order to arrive at the correct one.\n\nThe Dreyfus model for skill development says that the first step to go from novice to expert is to identify and apply many recipes or templates for accomplishing a task. Eventually, through research and analysis, they can build intuition about what recipe will help solve a problem, and how to improvise or combine recipes to create their own. They can develop expertise.\n\nBut that takes time—or at least it used to before AI. ChatGPT’s ability to help you summarize and analyze is like a superpower to beginners, who haven’t had time to build expertise in an area. I’ll help you learn how to use this superpower, from figuring out what people care about when you’re pitching them to finding best-selling titles for your article or book.\n\n\n\n\n\n",
      "word_count": 257,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3140/image.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3160/thumbnail_Screenshot_2024-07-22_at_10.16.51_AM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "also-true-for-humans"
    },
    {
      "url": "https://every.to/also-true-for-humans/mon-6-24",
      "title": "Emotion Prompting: Why AI Responds Well to Threats",
      "author": "Michael Taylor",
      "author_url": "/@mike_2114",
      "publication_date": "June 24, 2024",
      "content": "Emotion Prompting: Why AI Responds Well to Threats\n\nI shouted at my AI coworker—and it worked\n\nAs Dan has written, AI has the potential to turn us all into managers, overseeing the work of our AI assistants. One crucial skill of the “allocation economy” will be to understand how to use AI effectively. That’s why we’re excited to debut Also True for Humans, a new column by Michael Taylor about managing AI tools like you’d manage people. In his work as a prompt engineer, Michael encounters many issues in managing AI—such as inconsistency, making things up, and a lack of creativity—that he used to struggle with when he ran a 50-person marketing agency. It’s all about giving these tools the right context to do the job, whether they’re AI or human. In his first column, Michael experiments with adding emotional appeals to prompts and documents the results, so that you can learn how to better manage your AI coworkers.\n\nMichael is also the coauthor of the book Prompt Engineering for Generative AI, which will be published on June 25.—Kate Lee\n\n\n\n\n\nAdding a dash of emotion sometimes makes the AI pay more attention to instructions. For instance, I found that adding, “I’LL LOSE MY JOB IF…” to a prompt generated 13 percent longer blog posts. It’s generally considered rude to shout at your coworkers, but your AI colleagues aren’t sentient, so they don’t mind. In fact, they respond well to human emotion, because they’ve learned from our habits that you should behave according to emotional cues present in the prompt.\n\nWe’re going to look into the science behind emotion prompting and work through a case study of getting a chatbot called Golden Gate Claude (more on that later) to talk about anything other than bridges. These prompt engineering strategies bring us closer to understanding the ways in which we can work with AIs to get optimal answers, even as we grapple with the ethical and tactical questions about the interplay between human and automated systems.\n\n\n\n\n\n\n\n\n\nThese were genuine time savers for me while ChatGPT went through its so-called lazy phase, when ChatGPT learned from its human-created training data that we give shorter responses in December relative to other months (the latest model, GPT-4o, is harder working year round). Since large language models mimic human writing, they can slack off  around the winter holidays just as much as we do.\n\n\n\n\n\nBecome a paid subscriber to Every to learn about:",
      "word_count": 407,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3138/M-Cover.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3160/thumbnail_Screenshot_2024-07-22_at_10.16.51_AM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "also-true-for-humans"
    },
    {
      "url": "https://every.to/also-true-for-humans/7-22",
      "title": "Why AIs Need to Stop and Think Before They Answer",
      "author": "Michael Taylor",
      "author_url": "/@mike_2114",
      "publication_date": "July 22, 2024",
      "content": "Why AIs Need to Stop and Think Before They Answer\n\nHow chain of thought works to get better responses\n\nWhen humans make requests of their AI assistants, what matters isn’t merely what they ask but often how. That’s the central premise behind chain of thought prompting, a method for getting the most out of ChatGPT or another chatbot. In the latest installment of Also True for Humans, Michael Taylor’s column on working with AI tools like you would work with humans, he dives into how and why this method works, why we’re not all that different from our machine counterparts—and what the number of piano tuners in New York City has to do with any of this.—Kate Lee\n\n\n\n\n\nWhen I was writing this article, I worked with my editor to plan the outline and make sure I had a compelling pitch. So why do most people expect ChatGPT to “write a blog post on X” without taking the time to think?\n\nAI does a better job when it’s prompted to make a plan first—just like humans do. Most AI applications have one or more research and planning steps, a technique called chain of thought (CoT). It’s an order of operations for the model to reason through a problem before answering.\n\nWhen you’re getting mediocre results from AI, it’s often because you haven’t allowed the AI to plan sufficiently. Applying the chain of thought technique can result in an immediate boost in performance.\n\nLet’s look into the science behind chain of thought prompting and how to get AIs to think through their answers before responding. It’s one of the easiest ways you can improve your prompts to get more sophisticated results.\n\n\n\n\n\nBecome a paid subscriber to Every to learn about:",
      "word_count": 289,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3160/Screenshot_2024-07-22_at_10.16.51_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3376/thumbnail_Screenshot_2024-12-13_at_10.12.36_AM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "also-true-for-humans"
    },
    {
      "url": "https://every.to/also-true-for-humans/the-no-fluff-guide-to-ai-agents",
      "title": "The No-fluff Guide to AI Agents",
      "author": "Michael Taylor",
      "author_url": "/@mike_2114",
      "publication_date": "December 13, 2024",
      "content": "The No-fluff Guide to AI Agents\n\nThe next generation of AI is coming—here’s how they work\n\nIn Michael Taylor’s work as a prompt engineer, he’s found that many of the issues he encounters in managing AI tools—such as their inconsistency, tendency to make things up, and lack of creativity—are ones he used to struggle with when he ran a marketing agency. It’s all about giving these tools the right context to do the job, just like with humans. In the latest piece in his series Also True for Humans, about managing AIs like you'd manage people, Michael explores the inner workings of AI agents—the next generation of assistive AI technology—and what they need to succeed. He goes in-depth on the reason and act (ReAct) pattern, one of the first attempts to give large language models the tools they need to be truly helpful.—Kate Lee\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nI’m not naturally gifted at doing multiplication in my head, but armed with a calculator app on my phone, I can be faster and more accurate than someone who doesn’t have a calculator. Having access to tools can make such a difference to our own abilities that using a calculator on a test can be seen as “cheating.” But, of course, when you finish school and get a job, your employer expects you to use a calculator to do your work as efficiently as possible. There’s no time for doing math in your head, and errors can be costly in the real world.\n\nYou know what they say: Live an organized life so that your work can be creative and sprawling. That’s why we built Sparkle, an AI tool that cleans up desktops—and keeps them clean. Get a head start on 2025 with a clean slate.\n\n\n\n\n\nTeachers are concerned about students using ChatGPT to do their homework, but when those students graduate, their employers might expect them to be able to use AI to do their work. Using generative artificial intelligence has already been shown to improve workers’ productivity 40 percent, according to one estimate, and if the rate of progress holds, we can expect AI models to get 10 times better for the same cost year after year.\n\n\n\n\n\nThe rate of progress in AI has had an immediate impact on knowledge workers such as marketers, graphic designers, and software engineers, who work primarily with text or images that can be generated with AI technology. Less impacted are jobs that require interaction with the physical world, or knowledge workers whose jobs aren’t as accessible programmatically. For example, I used to pay people to manually pull advertising data and format it into weekly reports for our clients because (perhaps counter-intuitively) it was significantly cheaper than paying the software vendors that automate this task.\n\nAI agents are already being built that are capable of taking sophisticated action on your behalf without having to pay engineers to maintain expensive automations. Instead of paying a human to do manual data entry, imagine if I could give web-browsing access to an AI agent that could log into each advertising platform for me and put the relevant data into a spreadsheet, just like a human would. Most agents are at the prototype phase, as current LLMs aren't yet good enough at reasoning to operate at length without getting stuck. However, I've learned that with AI, anything that nearly works now might be fully functional—and feel like magic—in only six months, and could be ubiquitous in a year. The term “AI agents” is already surpassing “prompt engineering” in Google Search Trends, signaling a shift in the primary mechanism for getting better results from AI.\n\n\n\n\n\nThe prototypes of today won’t be prototypes for much longer. A new era of AI is coming. Let’s dive into how AI models use tools and the implications of your workplace being cohabited by AI agents.\n\n\n\n\n\nBecome a paid subscriber to Every to unlock this piece and learn about:\n\n\n\n",
      "word_count": 664,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3376/Screenshot_2024-12-13_at_10.12.36_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3211/thumbnail_Screenshot_2024-09-03_at_10.41.21_AM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "also-true-for-humans"
    },
    {
      "url": "https://every.to/also-true-for-humans/when-guessing-isn-t-good-enough",
      "title": "When Guessing Isn’t Good Enough",
      "author": "Michael Taylor",
      "author_url": "/@mike_2114",
      "publication_date": "November 19, 2024",
      "content": "When Guessing Isn’t Good Enough\n\nSolving AI hallucination with retrieval augmented generation\n\nIn Michael Taylor’s work as a prompt engineer, he’s found that many of the issues he encounters in managing AI tools—such as their inconsistency, tendency to make things up, and lack of creativity—are ones he struggled with with people. It’s all about giving these tools the right context to do the job, just like with humans. In the latest piece in his series Also True for Humans, Michael explores retrieval-augmented generation (RAG), in which you first search your documents to pass relevant context to the LLM to generate a more accurate answer.—Kate Lee\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nI thought it was Stephenie Meyer, author of the vampire romance series Twilight, but my friends disagreed. One thought it was Harry Potter writer J.K. Rowling, and another was convinced it was Arthur Conan Doyle, the author of the Sherlock Holmes books. There was no mobile internet in Cuba at the time, so we couldn’t look up the answer. Instead, we made plausible-sounding arguments for hours.\n\nWhen we got home to London, we looked up the answer on Wikipedia and learned the truth: While Meyer had been the best-selling author the past few years, first place belonged to the detective novelist Agatha Christie, with 2–4 billion copies sold. By contrast, Meyer has sold about 100 million. None of us were right, but our answers were within the realm of believability, if not possibility.\n\nChatGPT does the same thing: It gives plausible-sounding answers, or “hallucinations,” when it doesn’t have all the facts. In fact, everything ChatGPT tells you is made up. Large language models do not really know the answer to any question. They’re just giving you the answer that’s statistically most likely based on its training data. ChatGPT is often close enough, however, that many people feel comfortable using it without having to fact-check everything it says. (You should absolutely fact-check ChatGPT.)\n\nBut there’s a simple solution that artificial intelligence developers have built into their LLMs in order to solve the hallucination problem and ultimately make these systems more accurate: retrieval augmented generation, or RAG, where the LLM you’re using first does a vector search (more on that later) to find relevant information, which is then inserted into the prompt as context for the AI model to consider. If you can breathe better accuracy into AI, they can improve from complex probabilistic guesswork to something much more reliable and helpful.\n\nIn the AI gold rush, startups such as Pinecone, Glean, Chroma, Weaviate, and Qdrant raised hundreds of millions of dollars selling RAG technology to AI developers. It’s also being built directly into popular generative AI applications. OpenAI’s custom GPTs—the third-party versions of ChatGPT they host—can use RAG in order to make use of the documents that users upload, searching for relevant snippets to include as context in the prompt. Once paired with RAG, AI systems are essentially taking open-book exams when they communicate with you. The answer is somewhere in the book—on Google, in your PDFs, in your chatbot message history. They just have to look for it.\n\nUnsurprisingly, LLMs are better at finding an answer in a long document than they are at guessing the answers without context. With a little help, they don’t need to make something up, and you can get accurate answers based on sources of data that you trust. I’ll show you how we can make AI more trustworthy by teaching it to look up answers instead of guessing using RAG.\n\n\n\n\n\n\n\n\n\nWhen you write a lot about AI like we do, it’s hard not to see opportunities. We build tools for our team to become faster and better. When they work well, we bring them to our readers, too. We have a hunch: If you like reading Every, you’ll like what we’ve made.\n\nAI models don’t really see words. They use numbers to represent them. Think of numbers as a postal address or map coordinates, with concepts that are the most similar clustered closer together on a graph. When you upload documents to a RAG-enabled AI system, it will search to find relevant “chunks” of information and hand them over so the application can answer more accurately. To find the most relevant “chunks” in a document, it effectively plots them on a graph and looks for the ones that are closest to your prompt.\n\nImagine a simple AI model that has three variables: age, gender, and royalty. The three-dimensional space of the graph is called latent space—every word, phrase, or concept you query will have a location in this space. In the 3D graph below, find the point where the word woman is located. If gender is a spectrum, as you change that number from 10 to 0, you’ll get to where the man point is located on the graph. Alternatively, if you move along the age spectrum from man, you’ll get to boy, because a boy is just a young man. Finally, if you increase the, er, royalness of the boy, you get to prince, which is a royal boy.\n\n\n\n\n\nBecome a paid subscriber to Every to unlock this piece and learn about:\n\n\n\n",
      "word_count": 868,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3317/Cover_Image_Frame.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3160/thumbnail_Screenshot_2024-07-22_at_10.16.51_AM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "also-true-for-humans"
    },
    {
      "url": "https://every.to/chain-of-thought/gpt-3-is-the-best-journal-you-ve-ever-used",
      "title": "GPT-3 Is the Best Journal I’ve Ever Used",
      "author": "Dan Shipper",
      "author_url": "/@danshipper",
      "publication_date": "January 13, 2023",
      "content": "GPT-3 Is the Best Journal I’ve Ever Used\n\nMy slow and steady progression to living out the plot of the movie 'Her'\n\nDo you run a software company looking to reach an audience of early-adopters? Consider sponsoring our smart long-form essays on tech, AI, and productivity:\n\n\n\n\n\nFor the past few weeks, I’ve been using GPT-3 to help me with personal development. I wanted to see if it could help me understand issues in my life better, pull out patterns in my thinking, help me bring more gratitude into my life, and clarify my values.\n\nI’ve been journaling for 10 years, and I can attest that using AI is journaling on steroids.\n\nTo understand what it’s like, think of a continuum plotting levels of support you might get from different interactions:\n\n\n\n\n\nTalking to GPT-3 has a lot of the same benefits of journaling: it creates a written record, it never gets tired of listening to you talk, and it’s available day or night.\n\nIf you know how to use it correctly and you want to use it for this purpose, GPT-3 is pretty close, in a lot of ways, to being at the level of an empathic friend:\n\n\n\n\n\nIf you know how to use it right, you can even push it toward some of the support you’d get from a coach or therapist. It’s not a replacement for those things, but given its rate of improvement, I could see it being a highly effective adjunct to them over the next few years.\n\nPeople who have been using language models for much longer than I have seem to agree:\n\n\n\n@krismartens I'm afraid of seeming hyperbolic, but also don't want to lie or hide information. GPT-3 is really just an incredible therapist, and is able to uncover complex patterns in my thinking and distill clean narratives that helps me a lot. It's also a lot warmer than most therapists\n\nJuly 17th 2020, 4:55am EST\n\n\n\n(Nick is a researcher at OpenAI. He’s also into meditation and is generally a great follow on Twitter.)\n\nIt sounds wild and weird, but I think language models can have a productive, supportive role in any personal development practice. Here’s why I think it works.\n\nJournaling is already an effective personal development practice.\n\nIt can help you get your thoughts out of your head, rendering them less scary. It shows you patterns in your thinking, which increases your self-awareness and makes it easier for you to change.\n\nIt creates a record of your journey through life, which can tell you who you are at crucial moments. It can help you create a new narrative or storyline for life events so that you can make meaning out of them.\n\nIt can also guide your focus toward emotional states like gratitude, or directions you want your life to go in, rather than letting you get swept up in whatever is currently going on in your life.\n\nBut journaling has a few problems. For one, it’s sometimes hard to sit down and do it. It can be difficult to stare at a blank page and know what to write. For another, sometimes it feels a little silly—is summarizing my day really worth something?\n\nOnce you get over those hurdles, as a practice it tends to get stale. You don’t read through your old entries that often, so the act of writing down your thoughts and experiences doesn’t compound in the way that it should. The prompts you use often get old: one like, “What are you grateful for today?” might work for the first few weeks, but after a while you need something fresh in order for the question to feel genuine.\n\nYou want your journal to feel like an intimate friend that you can confide in—someone who’s seen you in different situations and can reflect back to you what’s important in crucial moments. You want your journal to be personal to you, and the act of journaling to feel fresh and full of hope and possibility every time you do.\n\nUnfortunately, paper isn’t great at those things. But GPT-3 is.\n\nJournaling in GPT-3 feels more like a conversation, so you don’t have to stare at a blank page or feel silly because you don’t know what to say. The way it reacts to you depends on what you say to it, so it’s much less likely to get stale or old. (Sometimes it does repeat itself, which is annoying but I think long-term solvable.) It can summarize things you’ve said to it in new language that helps you look at yourself in a different light and reframe situations more effectively.\n\nIn this way, GPT-3 is a mashup of journaling and more involved forms of support like talking to a friend. It becomes a guide through your mind—one that shows unconditional positive regard and acceptance for whatever you’re feeling. It asks thoughtful questions, and doesn’t judge. It’s around 24/7, it never gets tired or sick, and it’s not very expensive.\n\nLet me tell you about how I use it, what its limitations are, and where I think it might be going.\n\nI didn’t think of using GPT-3 in this way myself. I saw Nick Cammarata’s tweets about it over the years first. My initial reaction was a lot of skepticism mixed with some curiosity.\n\nAfter we launched Lex and I got more interested in AI, I remembered those tweets and decided to play around for myself.\n\nI started in the OpenAI playground—a text box where you input a prompt that tells GPT-3 how you want it to behave, and then interact with it:\n\n\n\n\n\nI had a bunch of ideas to start. I tried one from a Facebook PM, Mina Fahmi, whom I met at the AI hackathon I wrote about a few weeks ago. He suggested telling GPT-3 to take on a persona, and told me that he’d had great results asking it to be Socrates.\n\nI started experimenting with prompts like this:\n\n\n\n\n\nThe green messages are responses from GPT-3. I tried Socrates, the Buddha, Jesus, and a few others, and found I liked Socrates the best (apologies to my Christian and Buddhist readers). The GPT-3 version of him is effective at driving toward the root of an issue and helping you figure out small steps to take to resolve it.\n\nThere’s a long tradition in various religions of visualizing and interacting with a divine, compassionate figure as a way of getting support—and this was a surprisingly successful alternative route to a similar experience.\n\nAfter a while, though, I became a little bored of Socrates. I’m a verified therapy nerd, so the obvious next step was to try asking GPT-3 to do interactions based on various therapy modalities.\n\nI tried asking GPT-3 to become a bot that’s well-versed in Internal Family Systems—a style of therapy that emphasizes the idea that the self is composed of many different parts or sub-personalities, and that a lot of growth comes from learning to understand and integrate those parts. It turns out, GPT-3 isn’t bad at that:\n\n\n\n\n\n﻿I also tried asking it to be a psychoanalyst and a cognitive behavioral therapist, both of which were interesting and useful. I even asked it to do Jungian dream interpretation:\n\n\n\n\n\nAnother thing I tried is asking GPT-3 to help me increase my sense of gratitude and joy—like a better gratitude journal:\n\n\n\n\n\nYou’ll notice it starts by acting like a normal gratitude journal, asking me to list three things I’m grateful for. But once I respond, it probes about details of what you’re grateful for to get you past your stock answers and into the emotional experience of gratitude.\n\nOne of my favorite therapy modalities is ACT—acceptance and commitment therapy—because I love its focus on values. ACT emphasizes helping people understand what’s most important to them and uses that knowledge to help them navigate difficult emotions and experiences in their lives.\n\nValues work is challenging because sometimes it’s hard to connect your day-to-day experiences to your values. So I wanted to see if GPT-3 could help.\n\nThis is one of the experiments I tried:\n\n\n\n\n\nThis works well, and one of the cool things about it is how the prompt works. I took a sample therapy dialog from an ACT-focused values book that I love, Values in Therapy, and asked GPT-3 to generalize from that dialog to learn how to talk to me about values.\n\nIt worked—successfully guiding our conversation toward talking about what was most important to me. It’s not perfect, but it suggests interesting possibilities for things to try going forward.\n\nWhile I liked these early experiments, they had a few significant problems.\n\nFirst, the OpenAI playground isn’t designed to facilitate chats, so it’s hard to use. Second, it doesn’t record inputs between sessions, so I ended up having to re-explain myself every time I started a new session. Third, it sometimes gets repetitive and asks the same questions.\n\nThese are solvable, though. I know because I built a solution: a web app with a chatbot interface that remembers what I say in every session so I never have to repeat myself.\n\n\n\n\n\nThe bot lets me select a persona—like Socrates or an Internal Family Systems therapist—which corresponds to the prompts above. Then I can have a conversation with it. It will help me work through something I’m dealing with, or set goals, or bring my attention to something I’m grateful for. It can even output and save a summary of the session to help me notice patterns in my thinking over time.\n\nIt’s still early and there are a lot of problems to fix, but I find myself gravitating toward it every day. I feel like I’m building up a record of myself and my patterns over time, and the more I write in it, the more it compounds.\n\nI’ll be releasing the bot soon for paying Every members, so if you want access, make sure to subscribe.\n\nHere’s what I’ve learned so far through all of these experiments with GPT-3 as a journaling tool.\n\nThere is something innately appealing about  building a relationship with an empathetic friend that you can talk to any time. It’s comforting to know that it’s available, and it’s exciting to think about all of the different prompts you can experiment with to help it support you in the way you need.\n\nThere is also something weird about all of this. Spilling your guts to a robot somehow cheapens the experience because it doesn’t cost much for a robot to tell you it understands you.\n\nThis mix of feelings is reflected in this Twitter thread by Rob Morris, the founder of a peer-to-peer support app called Koko:\n\n\n\nWe provided mental health support to about 4,000 people — using GPT-3. Here’s what happened 👇\n\nJanuary 6th 2023, 2:50pm EST\n\n\n\nWhen people were using GPT-3 to help them provide support to peers, their responses were rated significantly more highly than responses that were generated by humans alone:\n\n\n\nMessages composed by AI (and supervised by humans) were rated significantly higher than those written by humans on their own (p < .001). Response times went down 50%, to well under a minute.\n\nJanuary 6th 2023, 2:50pm EST\n\n\n\nBut they had to stop using the GPT-3 integration because people felt like getting a response from GPT-3 wasn’t genuine and ruined the experience.\n\nThose feelings are understandable, but whether or not they ruin the experience depends on how the interaction is framed to you, and how familiar you are with these tools.\n\nI don’t think these objections will last over time for most people. It’s more likely a temporary result of contact with new technology. When you see a movie that you loved, does it cheapen the experience to know that you were touched by a set of pixels moving in the correct sequence over the course of a few hours? Obviously not, but if I had to bet, when movies were first introduced many people probably felt it was a cheaper version of a live performance experience.\n\nAs these kinds of bots get more common, and we learn to interact with them and depend on them for different parts of our lives, we’ll be less likely to feel that our interactions with them are cheap or stilted.\n\n(None of this, by the way, means that in-person interactions aren’t valuable anymore—just that there’s probably more room for bot interactions in your life than you might realize.)\n\nIf you're someone that's journaled for a long time, you'll find a lot of value in trying GPT-3 out as an alternative to your day-to-day practice. And if you've never journaled before this might be a good way to get started.\n\nI’ll be experimenting with this a lot more over the coming weeks and months, and I’ll be sharing everything I learn with you here. I’m excited for what’s next.",
      "word_count": 2136,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/2432/anotsher.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "chain-of-thought"
    },
    {
      "url": "https://every.to/chain-of-thought/the-knowledge-economy-is-over-welcome-to-the-allocation-economy",
      "title": "The Knowledge Economy Is Over. Welcome to the Allocation Economy.",
      "author": "Dan Shipper",
      "author_url": "/@danshipper",
      "publication_date": "January 19, 2024",
      "content": "The Knowledge Economy Is Over. Welcome to the Allocation Economy.\n\nIn the age of AI, every maker becomes a manager\n\nHey! Dan Shipper here. Registration is open for my new course, Maximize Your Mind With ChatGPT. It marries cutting-edge AI with the best of what psychology knows about developing your potential—so you can reach your goals in 2024.\n\nI’m teaching it with clinical psychologist Dr. Gena Gorlin, and it starts on February 5. Curious?\n\n\n\n\n\n\n\nTime isn’t as linear as you think. It has ripples and folds like smooth silk. It doubles back on itself, and if you know where to look, you can catch the future shimmering in the present.\n\n(This is what people don’t understand about visionaries: They don’t need to predict the future. They learn to snatch it out of the folds of time and wear it around their bodies like a flowing cloak.)\n\nI think I caught a tiny piece of the future recently, and I want to tell you about it.\n\nLast week I wrote about how ChatGPT changed my conception of intelligence and the way I see the world. I’ve started to see ChatGPT as a summarizer of human knowledge, and once I made that connection, I started to see summarizing everywhere: in the code I write (summaries of what’s on StackOverflow), and the emails I send (summaries of meetings I had), and the articles I write (summaries of books I read).\n\nSummarizing used to be a skill I needed to have, and a valuable one at that. But before it had been mostly invisible, bundled into an amorphous set of tasks that I’d called “intelligence”—things that only I and other humans could do. But now that I can use ChatGPT for summarizing, I’ve carved that task out of my skill set and handed it over to AI. Now, my intelligence has learned to be the thing that directs or edits summarizing, rather than doing the summarizing myself.\n\nAs Every’s Evan Armstrong argued several months ago, “AI is an abstraction layer over lower-level thinking.” That lower-level thinking is, largely, summarizing.\n\nIf I’m using ChatGPT in this way today, there’s a good chance this behavior—handing off summarizing to AI—is going to become widespread in the future. That could have a significant impact on the economy.\n\nThis is what I mean by catching the future in the present and the non-linearity of time. If we extrapolate my experience with ChatGPT, we can glean what the next few years of our work lives might look like.\n\nWe live in a knowledge economy. What you know—and your ability to bring it to bear in any given circumstance—is what creates economic value for you. This was primarily driven by the advent of personal computers and the internet, starting in the 1970s and accelerating through today.\n\nBut what happens when that very skill—knowing and utilizing the right knowledge at the right time—becomes something that computers can do faster and sometimes just as well as we can?\n\nWe’ll go from makers to managers, from doing the work to learning how to allocate resources—choosing which work to be done, deciding whether work is good enough, and editing it when it’s not.\n\nIt means a transition from a knowledge economy to an allocation economy. You won’t be judged on how much you know, but instead on how well you can allocate and manage the resources to get work done.\n\nThere’s already a class of people who are engaged in this kind of work every day: managers. But there are only about 1 million managers in the U.S., or about 12% of the workforce. They need to know things like how to evaluate talent, manage without micromanaging, and estimate how long a project will take. Individual contributors—the people in the rest of the economy, who do the actual work—don't need that skill today.\n\nBut in this new economy, the allocation economy, they will. Even junior employees will be expected to use AI, which will force them into the role of manager—model manager. Instead of managing humans, they’ll be allocating work to AI models and making sure the work gets done well. They’ll need many of the same skills as human managers of today do (though in slightly modified form).\n\nHere are a few qualities that managers of today need that individual contributors of tomorrow—model managers—will need as part of the allocation economy.\n\nToday's managers need to have a coherent vision of the work they want to accomplish. Managers of humans need to craft a vision that is articulate, specific, concise, and rooted in a clear purpose. Model managers will need that same ability.\n\nThe better articulated your vision is, the more likely the model is going to be to carry it out appropriately. As prompts become more specific and concise, the work done will improve. Language models might not, themselves, need a clear purpose, but model managers will likely have to identify a clear purpose for their own sake and engagement with the work.\n\nArticulating a concise, specific, and coherent vision is difficult. It’s a skill that is acquired over years of work. Much of it comes down to developing a taste for ideas and language. Luckily, that’s a place that language models can help as well.\n\nThe best managers know what they want and how to talk about it. The worst managers are the ones who say, “It’s not right,” but when asked, “Why?” can’t express the problem.\n\nModel managers will face the same issue. The better defined their taste, the better language models will be able to create something coherent for them. Luckily, language models are quite good at helping humans articulate and refine their taste. So it’s a skill that will probably become significantly more widely distributed in the future.\n\nIf you have clear taste and a coherent vision, the next thing you need to do is be able to evaluate who (or what) is capable of executing it.\n\nEvery manager knows that hiring is everything. If employees are doing the work, the quality of the output is going to be a direct reflection of their skills and abilities. Being able to adequately judge employees’ skills and delegate tasks to people who can carry them out is a significant part of what makes a good manager.\n\nModel managers of tomorrow will need to learn the same things. They’ll need to know which AI models to use for which tasks. They’ll need to be able to quickly evaluate new models that they’ve never used before to determine if they’re good enough. They’ll need to know how to break up complex tasks between different models suited to each piece of work in order to produce one work of the highest quality.\n\nEvaluation of models will be a skill in its own right. But there’s reason to believe it will be easier to evaluate models than it is humans, if only because the former are easier to test. A model is accessible day or night, it’s usually cheap, it never gets bored or complains, and it returns results instantly. So model managers of tomorrow will have an advantage in learning these skills, because management skills of today are gate-kept by the relative expense of giving someone a team of people to work with.\n\nOnce they’ve assembled the resources they need to get work done, they’ll face the next challenge: making sure the work is good.\n\nThe best managers know when and how to get into the details. Inexperienced managers make one of two mistakes. Some micromanage tasks to the point that they are doing the work for their employees, which doesn’t scale. Others delegate tasks to such a degree that they aren’t performed well, or are not done in a way that aligns with the organization’s goals.\n\nGood managers know when to get into the details, and when to let their reports take the ball and run. They know which questions to ask, when to check in, and when to let things be. They understand that just because something isn’t done how they would do it doesn’t mean it hasn’t been done well.\n\nThese are not problems that individual contributors in the knowledge economy have to deal with. But they are the exact kind of problems that model managers in the allocation economy will face.\n\nKnowing when and how to get into the details is a learnable skill—and luckily, language models will be built to intelligently check in during crucial periods where oversight is needed. So it won’t be completely on model managers to do this.\n\nThe big question is: Is all of this a good thing?\n\nA transition from a knowledge economy to an allocation economy is not likely to happen overnight. When we talk about doing “model management,” that’s going to look like replacing micro-skills—like summarizing meetings into emails—rather than entire tasks end to end, for a while, at least. Even if the capability is there to replace tasks, there are many parts of the economy that won’t catch up for a long time, if ever.\n\nI recently got my pants tailored in Cobble Hill, Brooklyn. When I pulled out my credit card to pay for it, the lady behind the counter pointed at a paper sign taped to the wall: “No credit cards.” I think we’ll find a similar pace of adoption for language models: There will be many places where they could be used to augment or replace human labor where they are not. These will be for many different reasons: inertia, regulation, risk, or brand.\n\nThis, I think, is a good thing. When it comes to change, the dose makes the poison. The economy is big and complex, and I think we’ll have time to adapt to these changes. And the slow handoff of human thinking to machine thinking is not new. Generative AI models are part of a long-running process.\n\nIn his 2013 book Average Is Over, economist Tyler Cowen wrote about a stratification in the economy driven by intelligent machines. He argued that there is a small, elite group of highly skilled workers who are able to work with computers that will reap large rewards—and that the rest of the economy may be left behind:\n\n“If you and your skills are a complement to the computer, your wage and labor market prospects are likely to be cheery. If your skills do not complement the computer, you may want to address that mismatch. Ever more people are starting to fall on one side of the divide or the other. That’s why average is over.”\n\nAt the time, he wasn’t writing about generative AI models. He was writing about iPhones and the internet. But generative AI models extend the same trend.\n\nPeople who are better equipped to use language models in their day-to-day lives will be at a significant advantage in the economy. There will be tremendous rewards for knowing how to allocate intelligence.\n\nToday, management is a skill that only a select few know because it is expensive to train managers: You need to give them a team of humans to practice on. But AI is cheap enough that tomorrow, everyone will have the chance to be a manager—and that will significantly increase the creative potential of every human being.\n\nIt will be on our society as a whole to make sure that, with the incredible new tools at our disposal, we bring the rest of the economy along for the ride.",
      "word_count": 1903,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/2922/allocation_economy(2).png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/2934/thumbnail_crypto_header.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "chain-of-thought"
    },
    {
      "url": "https://every.to/chain-of-thought/admitting-what-is-obvious",
      "title": "Admitting What Is Obvious",
      "author": "Dan Shipper",
      "author_url": "/@danshipper",
      "publication_date": "September 8, 2023",
      "content": "Admitting What Is Obvious\n\nI’m a writer—what are you?\n\nIgnoring what is obvious incurs a huge cost.\n\nIt requires you to go about your day numbing yourself to the reality of who you are and what you want—which is a waste of time for you and everyone around you.\n\nBy contrast, admitting what is obvious is freeing and motivating. But it’s terrifying to do it. Sometimes the most obvious truths about ourselves are hard to see because the consequences of those truths seem so dire.\n\nThis happened to me recently. I admitted a truth that was probably obvious to everyone around me, but not to myself: I’m a writer. This sounds so obvious that it feels like it is a joke. I write a weekly column at a newsletter that I started—of course I’m a writer.\n\nBut this is one of those truths for me. And I’m glad I can admit it.\n\nIf there are obvious truths like this for you, you should find them, and admit them, too.\n\nThe poet Robert Bly wrote that we all lug an invisible bag around with us everywhere we go. We’ve been filling it since childhood with the parts of ourselves that are true to us—to how we feel and what we want—but that aren’t acceptable to the people around us.\n\nIt starts with our parents: “don’t make noise during dinner,” or “in this family, we play baseball.” It continues with our teachers: “you’d be good at math if you only applied yourself.” Finally, it starts to come from peers in high school: “that’s nerdy,” or “you’ll never have a career doing that.”\n\nEach of these interactions causes us to put parts of ourselves in the bag. And the things we put in the bag are the obvious truths that we can’t admit, and that we try to ignore.\n\nBeing a writer is one of the things I tried to put in my invisible bag. For a long time, admitting that I am a writer and that I want to be a writer felt like it would force me to shed my identity as a founder, eliminate the possibility of building a consequential company, and seriously cap my potential career earnings.\n\nSo, I pretended to be a founder who also liked to write.\n\nThe first clue that I wanted to be a writer was that, after I sold my last business—a B2B software business—instead of going back into software, I started Every.\n\nEvery is a startup, so it lets me call myself founder. But on the inside, it also secretly lets me do the thing that I really wanted to do but couldn’t admit to myself or anyone else: be a writer.\n\nWhile I deeply enjoy almost every part of running a startup—coding, sales, marketing, managing, fundraising, etc.—writing is the thing that I’ve always loved the most.\n\nI knew this back in third grade when I wrote a 100-page novel in longhand on loose-leaf sheets of paper. But after writing that novel, I decided I needed more life experience to be a real writer, so I “retired.”\n\nIn fifth grade I read a biography of Bill Gates and became enamored with entrepreneurship, so I decided to start a Microsoft competitor. I called it Megasoft. I learned to code so I could build an operating system to compete with Bill—and even though the operating system never saw the light of day, it set me off on a path building software businesses.\n\nBoth of these parts of myself have always been intertwined in a braid. But now, I’ve decided to shift the emphasis. I’m not a founder who also likes to write. I’m a writer who also likes to build businesses.\n\nLiving in this truth—the truth of what is obvious—is freeing. It will make me the best writer I can be. And, I think—paradoxically—it will help me build better businesses.\n\nBillions of dollars in value are wasted every year by people doing the high-status thing they wish they felt compelled to do instead of the weird, low-status thing they actually want to do. Why is this value wasted?\n\nYou’re never going to be great at something you want to want. It’s always going to be a half-in, half-out kind of thing—instead of the all-in endeavor that greatness requires. Doing what you want to do, by contrast, lets you go all in.\n\nAs soon as I admitted to myself that I am a writer, it was easy for me to throw myself into it with wild abandon. Suddenly, I was sucking down great writing and furiously scribbling in my notebook. I made a list of skills I wanted to build and topics I wanted to cover. I realized how important it is for me to go deep on the future of AI and scientific discovery, AI’s power as a tool for creative expression, and its importance as a method for understanding ourselves. I recommitted to publishing this column every week. It felt like I didn’t have enough time in five lifetimes to do everything I wanted to do—and I feel like my writing is significantly better than it has ever been.\n\nWho’s going to win in that scenario? Will it be me, or someone who wants to write but can’t seem to bring themselves to sit down at the keyboard?\n\nOf course, doing this required me to grapple with a problem: how to square wanting to be a writer with wanting to build businesses. It was scary to want to be a writer because it meant giving up on being a founder. But as soon as I admitted the obvious, something else happened:\n\nI started to find heroes who had done exactly that.\n\nOnce I admitted what was obvious, I realized there are a lot of people who have done something like what I want to do.\n\nBill Simmons is one such example. He built The Ringer, a sports and pop culture website and podcast network, which he sold to Spotify for $250 million. Simmons was both the CEO of The Ringer and one of its main stars—The Bill Simmons Show was the marquee podcast on the network.\n\nHow’d he manage to square the circle between creative output and running the business? As far as I can tell, he stuck to what he’s good at: creating content, and spotting and developing talent. Then he recruited and maintained a core group of trusted operators around him who handled the rest of the business. He sets the vision, and they execute.\n\nOnce I found Bill Simmons I saw this dynamic at play in a thousand other places. Neuroscientist and philosopher Sam Harris mostly spends his time writing and recording podcasts, but he also founded Waking Up, a meditation app that helps his audience apply and practice the mindfulness skills he writes about. Sam doesn’t run the business day-to-day, though—he has a trusted general manager to handle that, so he can focus on thinking and creating. Other examples abound: Nate Silver, who started data journalism site FiveThirtyEight and is one of its main voices; Shane Parrish, who founded the popular blog Farnam Street; and Hank and John Green, the brothers, writers, and YouTubers who started both VidCon and creator merchandise company DFTBA; Gwyneth Paltrow who founded Goop.\n\nI had previously been blind to this way of operating because it’s so anathema to the usual tech ethos, which is to hire other people to do the creative work, rather than continue to do it yourself.\n\nBut it makes a lot of sense for a creator-run business to be structured in this way. The best thing a founder of any business can do is focus on what they are uniquely suited for—and hire people better than them to do the rest. In a creator-run business, the founder should focus on making the product.\n\nOnce I found this way of operating, I started to bend my world that way. I made a few key hires (to be announced soon!) and began to hand off some of my day-to-day operational responsibilities. I’m still intimately involved in every aspect of the business, but my day is significantly more focused around doing the best creative work I can for Every—and I expect  that to pay significant dividends for the business over time.\n\nIt’s truly the most satisfied, excited, and aligned I’ve ever felt running Every. Which brings me to my last point:\n\nHow could I have done this sooner?\n\nAdmitting the obvious is to take a scary leap. It is to make decisions that bring your life into alignment with what you truly want—rather than what you think you should want or what others want from you. It is to risk taking the low-status meandering path, instead of the high-status linear one.\n\nIt can be easy, in retrospect, for me to wish I had done this earlier. To think that it might be possible to white-knuckle my way through future admissions of this kind, to give up all of my internalized shoulds, and any temptation to be affected by the desires and pressures of the people around me. To want to leap that gap in a single bound, and to believe that I could if I tried hard enough.\n\nBut I’m not sure that’s possible. Sometimes the obvious truth is hidden from you for a reason, and it takes great care and lots of time to see it.\n\nSpiders weave webs across gaps that cannot be crossed by crawling or jumping. Instead, when a tiny spider wants to weave a web across a large distance, it produces a fine adhesive thread that it allows to catch and drift along the wind. It can feel by the sensitive vibrations passed along the thread when it catches and adheres on the other side of the gap. Then, it carefully walks across that first strand like a tightrope walker, laying another thread down as it goes.\n\nIt weaves back and forth like this—carefully, one step at a time—until a web is formed out of thin air.\n\nI think this is the way to admit the obvious. Loose a single thread in the direction of what you want. When it catches—follow it, and strengthen it. Eventually, you’ll be ready to cross the gap with confidence and spin a web of your own.",
      "word_count": 1713,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/2750/obv.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3553/thumbnail_03.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "chain-of-thought"
    },
    {
      "url": "https://every.to/chain-of-thought/gpt-4-is-a-reasoning-engine",
      "title": "GPT-4 Is a Reasoning Engine",
      "author": "Dan Shipper",
      "author_url": "/@danshipper",
      "publication_date": "March 31, 2023",
      "content": "GPT-4 Is a Reasoning Engine\n\nReason is only as good as the information we give it\n\nThis article is brought to you by Mindsera, an AI-powered journal that gives you personalized mentorship and feedback for improving your mindset, cognitive skills, mental health, and fitness.\n\n\n\n\n\nIn 1894, a Boston-based astronomer named Percivel Lowell found intelligent life on Mars.\n\nLooking through a telescope from his private observatory he observed dark straight lines running across the Martian surface. He believed these lines to be evidence of canals built by an advanced but struggling alien civilization trying to tap water from the polar ice caps.\n\nHe spent years making intricate drawings of these lines, and his findings captured public imagination at the time. But you’ve never heard of him because he turned out to be dead wrong.\n\nIn the 1960s, NASA's Mariner missions captured high-resolution images of Mars, revealing that these \"canals\" were nothing more than an optical illusion caused by the distribution of craters on the planet's surface. With the low resolution available to his telescope at the time, these craters looked to Lowell like straight lines which, through a chain of reasoning, he theorized to be canals built by intelligent life.\n\nLowell’s story shows that there are at least two important components to thinking: reasoning and knowledge. Knowledge without reasoning is inert—you can’t do anything with it. But reasoning without knowledge can turn into compelling, confident fabrication.\n\nInterestingly, this dichotomy isn’t limited to human cognition. It’s also a key thing that people fundamentally miss about AI:\n\nEven though our AI models were trained by reading the whole internet, that training mostly enhances their reasoning abilities not how much they know. And so, the performance of today’s AI models is constrained by their lack of knowledge.\n\nI saw Sam Altman speak at a small Sequoia event in SF last week, and he emphasized this exact point: GPT models are actually reasoning engines not knowledge databases.\n\nThis is crucial to understand because it predicts that advances in the usefulness of AI will come from advances in its ability to access the right knowledge at the right time—not just from advances in its reasoning powers.\n\nMindsera structures your thinking with journaling templates based on useful frameworks and mental models, so you can make better decisions, solve complex problems, and be more productive.\n\nOur innovative AI coaching helps you to achieve your goals by making mental models actionable. You get the power of a professional coach without paying over $250 per hour.\n\nMindsera smart analysis generates an original artwork based on your writing, measures your emotional state, reflects on your personality, and gives personalized suggestions to help you improve.\n\nBuild self-awareness, get clarity of thought, and succeed in an increasingly uncertain world.\n\n\n\n\n\nHere’s an example to illustrate this point. GPT-4 is the most advanced model on the market today. Its reasoning capabilities are so good that it can get a 5 on the AP Bio exam. But if I ask it who I am it says the following:\n\n\n\n\n\nThat’s close to being right except for one big problem…I’m the co-founder of a few companies, but neither of them are Superhuman or Reify.\n\nAI critics will be quick to say that this proves GPT-4 is nothing more than a stochastic parrot, and that its results should be dismissed offhand. But they’re wrong. Its performance improves dramatically the second it has access to the right information.\n\nFor example, I have access to a version of ChatGPT that can use web searches to ground its answers with what it finds on the internet.\n\nIn other words, instead of using its reasoning capabilities to come up with a theoretically plausible answer, it does web research to create a knowledge base for itself. It then analyzes the collected information and distills a more accurate answer:\n\n\n\n\n\n\n\nNow, that’s pretty good! The underlying model is the same—but the answer improves significantly because it has the right information to reason over.\n\nWhat’s going on here? GPT-4’s architecture is not public, but we can make some educated guesses based on previous models that have been released.\n\nWhen GPT-4 was trained, it was fed a large portion of the available material on the internet. Training transformed that data into a statistical model that is very good at, given a string of words, knowing which words should follow from it—this is called next token prediction.\n\nHowever, the kind of “knowledge” contained in this statistical model is fuzzy and inexplicit. The model doesn’t have any sort of long-term memory or way to look up the information it has seen—it only remembers what it encountered in its training set in the form of a statistical model.\n\nWhen it encounters my name it uses this model to make an educated guess about who I am. It draws a conclusion that’s in the ballpark of being right, but is completely wrong in its details because it doesn’t have any explicit way to look up the answer.\n\nBut when GPT-4 is hooked up to the internet (or anything that acts like a database) it doesn’t have to rely on its fuzzy statistical understanding. Instead, it can retrieve explicit facts like, “Dan Shipper is the co-founder of Every” and use that to create its answer.\n\nSo, what does this mean for the future? I think there are at least two interesting conclusions:\n\nLet’s take these one at a time.\n\nWhen it comes to knowledge you want to be able to store a lot of it, and you want to be able to find the right piece of knowledge at the right time. In AI this is typically done with a vector database.\n\nVector databases allow you to easily index and store large amounts of information, and then quickly query for similar pieces of information to give to your model when you need to. They’re so common in AI apps that it’s likely almost every demo you’ve tried over the last few months has included a vector database for some part of their functionality.\n\nIn fact, if you want to make an investment that indexes the success of companies building in AI as a whole, one smart move would be to invest in a vector database provider, or a basket of them. (Alternatives might be to invest in OpenAI, or a basket of large cap software companies like Microsoft and Google that build AI, or chipmakers like NVIDIA that build the GPUs that AIs run on.)\n\nSmarter investors than me seem to agree. Pinecone, the most popular vector database, just raised money at a $700m valuation. Smaller alternatives like Weaviate and Chroma aren’t far behind, and they’re also reportedly raising money at steep valuations.\n\nInterestingly, though, most of these vector databases were originally built before the large language model (LLM) craze. Vectors are incredibly important for all sorts of previous-generation machine learning algorithms like recommendation systems. As a result, the database tooling from providers like Pinecone isn’t purpose built for large language models like ChatGPT.\n\nWe’re already seeing newer alternatives springing up that wrap some business logic around the database layer to make it easier for AI developers to do common tasks. Some of these are developer libraries like Langchain and LlamaIndex. And some seem to be more fully featured developer tools like Metal and Baseplate. Just like Pinecone, they are also likely to raise a lot of money, or already have! AI’s advancement is a rain dance that calls forth capital from Patagonia vest wearing angels.\n\nI find this very exciting because it will make it a lot easier to make AI apps. There’s a tremendous amount of boilerplate code being written to take, say, a PDF or a webpage with interesting information on it, parse it, break it into chunks, store it, and retrieve it for use in AI apps. The more that can happen with just a line or two of code, the better.\n\nWhen I talk to people about vector databases—even people who have been following AI closely—they typically say, “What’s that?” I think, over time, that will change significantly as we start to understand how important it is for these models to have access to the knowledge that they contain.\n\nVector databases are how information gets stored and made available to AI applications. One place that I think they’ll get a lot of valuable information from is private, personal knowledgebases.\n\nPeople have been saying that data is the new oil for a long time. But I do think, in this case, if you’ve spent a lot of time collecting and curating your own personal set of notes, articles, books, and highlights it’ll be the equivalent of having a topped-off oil drum in your bedroom during an OPEC crisis.\n\nWhy? It’s expensive and time consuming to find information that’s relevant to the things you think about. Even if you give AI access to a search engine, so it can make queries to find the right information—it’ll cost you money and time.\n\nIf, instead, you’ve spent a lifetime gathering and curating  information that’s important to you, you can customize your AI experience so it’s more useful to you right off the bat.\n\nApps like Readwise Reader or Pocket or Instapaper that allow you to store articles you’ve read (or articles you want to read) are going to be a gold mine to the extent that they hook up to AI tools. They’ll be extra useful because they record the articles you explicitly bookmarked and read, this will make it easier for AI tools to know which pieces of information to weight in their responses.\n\nBut the use of personal knowledge databases will get weirder and more advanced than this.\n\nFor example, Rewind is a tool that sits on your computer and records everything you see and everything you type. It’s all stored locally for privacy purposes, and you can already hook it up to ChatGPT.\n\nIn one of their demos they show a user asking, “What did I do last week?” The AI is able to summarize all of the tasks they did on their computer:\n\n\n\n\n\nFor my part, I’ve installed Rewind, and I’ve been playing around with building little tools to save more of what I encounter online. I made a little app I call Tend that sits open on my browser all day, and I can feed it any articles with interesting information for indexing and storage. Later, I’ll build a little ChatGPT plugin to give me access to all the information I saved with it.\n\nWhen we talk about the future of AI, we tend to focus on its output. Given a prompt, it can think through a complex problem, compose an essay, or create a new scientific breakthrough without much human involvement.\n\nWe tend to underappreciate the significance of the input—what information we feed it to produce those results. Its answers are largely dependent on the information we make available to it for analysis. It’s only as powerful as its starting point.\n\nWe don’t pay enough attention to the limits of its knowledge—how much information is locked away,  inaccessible to these systems. We also forget how expensive (both in time and in compute) it is to crawl through information sources and find relevant facts. And finally, we underestimate the difficulty of surfacing relevant pieces of information for the model at the right time.\n\nBut solving these sorts of problems is just as fundamental as solving for the reasoning capabilities of the underlying models. I’m excited to see what people build.",
      "word_count": 1913,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/2544/reasoning.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/2938/thumbnail_header_pro.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/2934/thumbnail_crypto_header.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "chain-of-thought"
    },
    {
      "url": "https://every.to/chain-of-thought/using-chatgpt-custom-instructions-for-fun-and-profit",
      "title": "Using ChatGPT Custom Instructions for Fun and Profit",
      "author": "Dan Shipper",
      "author_url": "/@danshipper",
      "publication_date": "September 15, 2023",
      "content": "Using ChatGPT Custom Instructions for Fun and Profit\n\nHow to 10x ChatGPT with personalized answers\n\nThis essay is brought to you by Glean, the AI-powered search for your work. Imagine having Google and ChatGPT, equipped and optimized for your workplace, at your fingertips, that is the power of Glean.\n\n\n\n\n\nChatGPT Custom Instructions are mysterious and powerful. For the woefully (and shamefully) uninitiated, it’s a function of ChatGPT that allows you to give background information on who you are, and how you want ChatGPT to respond to you.\n\nThis is crazy awesome! The only problem: no one uses them. This is crazy terrible.\n\nUsing Custom Instructions properly can completely transform your experience with ChatGPT. Custom Instructions will help you turn ChatGPT into a personalized, always-on, super-smart coach and tutor that knows who you are, your strengths and weaknesses, and the people in your life, so it can help you make better decisions and achieve your goals. You won’t have to explain anything twice because it will already know enough context about you to help—and it will do so in ways that surprise and delight you.\n\nLet me give you an example.\n\nRecently, I was playing around with the idea of starting a new course for Every—and I wanted ChatGPT to help me decide whether to do it. I prompted it with one sentence: “i'm thinking about starting a new course. can you help me think it through?”\n\nI did this without Custom Instructions to start and got this back:\n\nBig fat F. It completely misunderstood the question—it thought I wanted to take a course and not build one—and the advice it gave me was decent but banal.\n\nEver felt overwhelmed trying to find information spread across numerous apps? Let Glean do the heavy lifting for you. It's an AI-powered search engine made for the workplace. Picture a fusion of Google and ChatGPT, specifically designed for your business's needs. With Glean, you gain access to intelligent, instantly responsive search features and a business-grade AI chatbot that swiftly navigates your company's knowledge base. Step into a new world of easy and secure information discovery with Glean.\n\n\n\n\n\nThen, I turned Custom Instructions on and gave it the same starting prompt. Here are a few of the responses (emphases are mine):\n\nThis is SO. FREAKING. COOL.\n\nChatGPT reeled off gem after gem. It knows about Every, the company I run. It knows who’s on my team at Every and asks me how they can help. It knows what kind of writing I like to do so it can help me integrate it into the course planning. And the kicker: it knows that I’m working on being a little less opportunistic—on not jumping on shiny new things, and staying focused on longer-term priorities. Because it knows this it can ask, “Are you sure this is a good idea given your tendencies, buster?”\n\nCustom Instructions are good enough that I’d go so far as to say it is a crime if you are not using them. It’s a theft of your talent, time, and potential. So I am laying the gauntlet down now:\n\nIf you are a subscriber to Every in 2023, and after reading this article, you’re still not using ChatGPT Custom Instructions, I am going to find you and whip you with a wet noodle until you do.\n\nWhy? It’s not that hard—and the benefits are enormous.\n\nIn this article, I’ll walk you through what ChatGPT Custom Instructions are and how to use them. I’ll share ideas for how to get the most out of them, and even share my custom instructions so you can steal them for yourself.\n\nReady? Let’s get going.\n\nYou can think of ChatGPT as a genius amnesiac. It’s a genius because during its training it read and ingested the entire internet. But it’s an amnesiac because, now that it is trained, it cannot form new memories. Every interaction is like Drew Barrymore in 50 First Dates: it has to learn who you are (and why it loves you) over and over again.\n\nBecause we live in the real world and not in a romantic comedy, this is annoying and time-consuming. You have to continually repeat information, and you won’t use ChatGPT to its full potential because it will miss ways to help you.\n\nFortunately, Custom Instructions fixes this. It doesn’t stop ChatGPT from being amnesiac, but it does mitigate it. It works like the dossier that politicians get before a meeting with an important donor: they read the file and know all of the important information they need, even if they’ve never met the donor before.\n\nWith Custom Instructions, every time you start a new chat, it rereads its dossier, learns who you are and how you want it to talk to you, and formulates a response.\n\nThe only problem is, unlike a politician, you have to write the dossier on yourself:\n\n\n\n\n\nThese blank text boxes are intimidating—so much so that I skipped out on using Custom Instructions for a while. I just couldn’t find a way in. Luckily, I’ve written this guide to help you with that.\n\nCustom Instructions is split into two categories: Biographical Info and Response Style. We’ll go through how to set up each in the following sections.\n\nThe first thing you’ll want to do is give ChatGPT your name and bio. I wrote mine like this:\n\nIf writing something like this is hard for you, just go to your LinkedIn profile and copy and paste it into ChatGPT. Ask it to summarize your LinkedIn in three sentences and presto—you’ll have a bio you can use.\n\nThe next thing you’ll want to inform Custom Instructions about are your current projects and goals. Giving ChatGPT this information will help it connect your daily conversations to your goals—and therefore keep your attention on them. It will also make connections that you might not ordinarily see.\n\nHere’s how I write about my goals:\n\nGiving Custom Instructions a sense of your personal preferences can help it make recommendations that are more tuned to who you are.\n\nHere’s what I tell it:\n\nIf you don’t know what you like, you can use ChatGPT to help you find out. Read my article on this topic for more.\n\nIt’s helpful to give Custom Instructions a sense for the people in your life on a day-to-day basis so that when you mention them during your chats, you don’t have to explain who they are over and over again. I do this for both my professional and personal relationships because I tend to chat with it about both.\n\nHere’s what I use:\n\nWe’re all working on ourselves. I’m working on being less agreeable and less opportunistic. Other people are working on being kinder, or more decisive, or more high agency. You can use Custom Instructions to help remind you of the areas in which you’d like to improve and tilt ChatGPT’s advice in that direction.\n\nHere’s what I use:\n\nYou can also tell it your Big Five personality type or your Meyers-Briggs type so that it can tailor its responses to you.\n\nSometimes there are significant aspects of your history (medical or otherwise) that are helpful for ChatGPT to know because it will change how it responds to you. For example, I have OCD, which should impact how it responds to me about questions that might touch the condition. So I tell it that:\n\nThere are many more inputs you can provide. Think about this: what kinds of things would ChatGPT need to know about you in order to help you make decisions, find ideas and content that resonates with you, and live the life you want to live?\n\nMany people have lists of principles, values, or mental models that they want brought to their attention as much as possible—these are good things to experiment with.\n\nOnce you’ve given Custom Instructions your biographical information, you can also set its response style. Response style is its voice—you can tell it how you want it to communicate with you, what you want it to say, and what you don’t want it to say.\n\nHere are a few ideas for Response Style.\n\nChatGPT is liable to try to answer a question in one go—but I want it to feel free to ask follow-up questions before giving a response. So I use this:\n\nIf you want ChatGPT to be more (or less) likely to help push you toward your goals or personal development objectives, you can use Response Style to give it instructions. For example, I want it to push me to be less agreeable and less opportunistic. So I tell it to do that:\n\nIf you want some ideas for personality characteristics for ChatGPT to help you mold, here are a few:\n\nChatGPT is excellent at making connections and references between seemingly unrelated topics. It can push your brain in new, unexpected, and exciting directions—if you tell it to.\n\nAI creator Swyx uses Custom Instructions to encourage ChatGPT to go off on side tangents and make pop culture references:\n\n\n\nunderrated trick to custom instructions - tell it to give you side tangents and pop culture references. Put that world model to work! LLMs are *really* good at making associations across domains. You can use them as *both* reasoning engines *and* \"serendipity engines\". caught a… https://t.co/NPK9cPHtbu https://t.co/4RanfWUBWV\n\nSeptember 3rd 2023, 3:37am EST\n\n\n\nIf you want to try this throw this in your Custom Instructions:\n\nI use this in my Custom Instructions, and it’s enjoyable and surprising. I recommend it.\n\nChatGPT can sometimes get annoying for safety purposes. It will, for example, always remind you that it’s an AI and not a doctor. This is useful for the average user, but not for me—I already know.\n\nSo you can ask it to turn that off. I learned this from a tweet from developer and course creator Joel Hooks who shared his (very extensive) Custom Instruction set:\n\n(There’s a lot more in Joel’s instruction set if you’re looking for more ideas.)\n\nThe set of things that you can use Custom Instructions for is, literally, endless. The only limit is your imagination and the 3,000 characters you get in order to write them.\n\nHopefully, there’s enough here to pull you out of your amnesiac ChatGPT dark ages and into the light of an LLM that actually knows who you are.\n\nIf you have your own Custom Instructions that have worked for you, please comment below or reply to this email with them. I’d love to see what you’ve discovered.\n\nHappy prompting.",
      "word_count": 1749,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/2758/happy_.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "chain-of-thought"
    },
    {
      "url": "https://every.to/context-window/spiraling-out-of-control",
      "title": "Spiraling Out of Control",
      "author": null,
      "author_url": null,
      "publication_date": "June 23, 2024",
      "content": "Spiraling Out of Control\n\nOur new AI tool, plus a step change in AI models\n\nLearn no-code and AI skills by committing to the 100DaysOfNoCode or 100DaysOfAI challenges.\n\nThese challenges provide a 30-minute bite-sized lesson straight to your inbox every day. It’s free, fun, and effective.\n\nStarting July 1, 2024, you’ll gain practical knowledge and hands-on experience. Don't miss this opportunity to enhance your skills and stay ahead in the tech world. Sign up now!\n\n\n\n\n\nHello, and happy Sunday! ICYMI, we released a new tool called Spiral, an AI prompt builder that automates repetitive creative work—think writing headlines and summaries, social media posts, client proposals, and the like. More than 2,000 users have already signed up, and Dan Shipper will explain how we built it in an upcoming piece. More details on how to use it and how you can access it are just below the jump. Let us know how you’re using it in the comments.\n\nOn to everything we published this week (hint: Evan Armstrong broke some news), along with our take on the latest tech and business news.—Kate Lee\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\"Introducing Spiral\" by Dan Shipper: We hate to break it to you, but a lot of your job is repetitive drudgery. It's the stuff you have to do to get your real work seen: turning an analysis into a slide, a podcast into a description, or a presentation into a client email. But what if you could automate 80 percent of that work? Meet Spiral, a powerful prompt builder we made that helps creators repurpose their content for different channels and attention spans in their unique style and voice. 🔏 Available now for paid Every subscribers, along with our AI writing app, Lex.\n\n\"Be Sincere—Not Serious\" by Michael Ashcroft/Expanding Awareness: Life is better when you don't take it too seriously. Approaching challenges with a sense of play and levity can help you navigate them more effectively than getting tense and worked up. Read this if you want to learn how to find more joy in your work and relationships by being sincere rather than serious.\n\n🎧 \"She Built an AI Product Manager Bringing in Six Figures—As A Side Hustle\" by Dan Shipper/’AI & I’: While working a demanding job as a chief product officer, Claire Vo built ChatPRD, an AI assistant that helps startups craft product strategies. It's now pulling in six figures in revenue. In this episode of AI & I, Claire shares how she used AI to build ChatPRD in record time, her predictions for the future of product management, and the creative ways she's using AI tools in her work and personal life. 🔏 Paid subscribers have access to the episode transcript.\n\n\"You Can't Math Your Way to Success\" by Evan Armstrong/Napkin Math: As Evan prepares for impending fatherhood, he's been making countless spreadsheets trying to figure out how to give his child the best possible life. But the exercise raised bigger questions for him: Can you mathematically figure out your way to success in anything? Read this if you want to learn why self-awareness and adaptability are the keys to success in art, startups, and parenting.\n\nIn response to Evan’s piece about the potential for achieving AGI by 2027:\n\n\"Some of the best, balanced, and most nuanced thinking on a topic that most authors represent from a tightly held perspective at either end of a belief spectrum.\"—An Every reader\n\nWant to chat? DM Dan or Evan on X.\n\nAnthropic’s new AI model is twice the speed, 1/5th the cost. I can’t think of a previous technology that has achieved this level of cost and performance improvements—and all in just one year! If the trend line continues for another five, we are living in an entirely different technological age. Along with Claude 3.5 Sonnet, the company released \"artifacts,\" a way to visualize the inner workings of the chatbot (for example, by showing you the code of what it’s making).\n\nAnthropic finally has a corporate strategy—it’s B2B SaaS. In the same post announcing the new model, the company stated,\n\nIn Rick and Morty, Rick makes an AI robot while eating breakfast. After the robot grabs Rick butter for his pancakes, the robot asks, “What is my purpose?” to which Rick replies, “You pass butter.” The robot, filled with self-awareness, looks forlornly at its hands and exclaims, “Oh my God.” I have to imagine that if Claude becomes self-aware and is told its job is to “centralize knowledge, documents, and ongoing work in one shared space,” it would have a similar reaction.\n\nIn the non-science-fiction reality in which we currently reside, this strategy actually makes sense. The output of an LLM is only as good as the prompt it is given and the data it can reference. Finding ways to embed the AI into your system is a viable strategy for these model providers. It will be fascinating to see with whom and how these SaaS partnerships are structured. My guess is that the company will start with the smaller players like Notion before trying to strike a deal with Salesforce or Hubspot.\n\n$0 to $35 million in annualized revenue in a year. When an AI startup strikes oil, the resulting well gushes with money. The latest is HeyGen, which produces generative AI videos in which people can make avatars of themselves that talk—think ad copy, internal training, etc. It’s raised $60 million in a round that values it at $500 million. This undoubtedly is a point solution, so I’m curious to see how the company tries to extend it. Do you add more AI offerings? Do you try to capture more traditional marketing SaaS spend? My bet is the former.\n\nNo product + no revenue = $2 billion valuation. Poolside.AI is in talks to raise over $400 million at a $2 billion-plus valuation. While these numbers are large, it is not worth trying to say that this is the valuation. Instead, view this as a call option on a wholly different world. If just one of these foundation model companies achieves its vision (a big if), a $2 billion valuation will look cheap. This isn’t yet a business—it's a high-potential science project.\n\nApple takes the Vision Pro out to pasture. Despite my steadfast love for the device, the Vision Pro headset has continued to undersell. In response, Apple has reportedly quit developing its next high-end version and is focusing on a cheaper one to release in late 2025. The AVP’s issue isn’t price—it’s that it doesn’t have enough capabilities and ecosystem features to attract the general populace. Neither of those will be fixed by making the device cheaper. The company should be doubling down on its ecosystem instead.—Evan Armstrong\n\nNot quite the dot-com bubble, but close. Speaking of spicy valuations, investors are paying a lot for big tech, but still not quite as much as they were back in 1999:\n\n\n\n\n\nMedian price-earnings ratio (i.e., profit multiple) of the S&P's top 10 stocks is nearly at the ZIRP peak . . . but it's still lower than the peak of the dot-com bubble. Investors are paying  approximately $30 for every $1 of profit, which is roughly a 3 percent yield. It’s a strange investment to make when a savings account can fetch close to 5 percent, especially when savings accounts are considerably less risky than stocks. But, as pricey as stocks are, they’re still not as pricey as they were when everyone was partying like it’s 1999. For now, Nvidia & co. keep delivering earnings growth, and if you’re looking for upside, it’s pretty much the only game in town.—Moses Sternstein\n\nWe asked teacher and coach Michael Ashcroft, who wrote about the value of sincerity over seriousness, to share one good read:\n\n🖇 \"ChatGPT Is Bullshit\" by Michael Townsen Hicks, James Humphries, and Joe Slater: “As large language models insinuate themselves more deeply into our daily lives, I find it useful to be reminded that our AI friends don't necessarily care about truth the way I do. Or perhaps they shine a light on a ‘skill’ I sometimes don't even realize I'm using: the subtle art of bullshitting.”\n\nSelf-fulfilling prophecies. People have been talking about the dangers of technology in one form or another for thousands of years. Icarus used his artificial wings to fly too close to the sun and died. The golem, a mythical creature created to protect a community, became uncontrollable and unleashed violent destruction. The moral is always the same: With great power comes great responsibility. I recently came across a more recent—and optimistic—prophecy by Indian philosopher and mystic J. Krishnamurti, who talked about superintelligence in 1981 to a group of college students in Madras. With some power of foresight, he predicted that intelligent computers would guide humanity down one of two paths: Either we’re sedated by endless entertainment, or we use technology as a way to turn inward and reaffirm what it means to be human. I lean toward the second path, because technology is just a mirror reflecting our deepest potential. Yes, the sun may burn. But it also illuminates.—Ashwin Sharma\n\nCloud deck: RIP legacy cloud—long live AI cloud. The investors at Bessemer Venture Partners do a deep dive on the five AI trends transforming the cloud economy, including the predictions, hot takes, and behind-the-scenes video conversations on the entrepreneurial and startup opportunities that lay ahead in the AI era.\n\nWhat if pillows could record and reproduce your dreams?\n\n\n\n\n\nThat’s all for this week! Be sure to follow Every on X at @every and on LinkedIn.\n\n\n\n",
      "word_count": 1599,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3137/Screenshot_2024-06-22_at_10.17.33_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3131/thumbnail_Screenshot_2024-06-15_at_12.14.39_PM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "context-window"
    },
    {
      "url": "https://every.to/context-window/we-do-be-thinking",
      "title": "Blue-sky Thinking",
      "author": null,
      "author_url": null,
      "publication_date": "June 30, 2024",
      "content": "Blue-sky Thinking\n\nPlus: Learn how to manipulate AI tools to get better results\n\nHello, and happy Sunday! Our team has been in certified Think Week™ mode, and we spent most of the week doing exactly as the name describes: reflecting on the work of the past quarter, and thinking about the most important questions in technology that we’re genuinely curious about and excited to tackle for the next one. One of the pieces that has most shaped our planning was Evan’s profile of artists collective MSCHF: We pick ideas and projects that push us to try to do the hardest thing we can. Creative excellence comes not from ease, but from effort, from caring. We aspire to deliver excellence for you, our readers.\n\nHere are the questions that we came up with:\n\nSo in Q3, expect bigger swings from us: more risks, more promises kept, and more of that great combination of software and writing that you love. Thanks for supporting our team—we’ll resume regular publishing on Monday, July 8.—Kate Lee\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n🔏  \"Emotion Prompting: Why AI Responds Well to Threats\" by Michael Taylor/Also True for Humans: What if we told you that SHOUTING AT YOUR AI COWORKER CAN BOOST ITS PERFORMANCE BY 10.9 PERCENT? It turns out that adding emotional appeals to prompts makes AI pay more attention and give better responses. Read Michael Taylor’s debut column if you want to learn how to manipulate your AI colleagues (ethically, of course) and become a better prompt engineer.\n\n🔏  \"How to Grade AI (And Why You Should)\" by Michael Taylor/Also True for Humans: AI tools are only as performative as we can measure. If you want to know which tool to use, you need to know how to run evaluations, or evals. Read this if you want to learn how to grade your AI like a pro, using programmatic, synthetic, and human evaluations to get the most out of your digital workforce.\n\n🔏  \"How to Become an Expert at Anything With AI\" by Michael Taylor/Also True for Humans: Want to become an expert overnight? AI is your new shortcut. Michael Taylor shows how to use ChatGPT and Claude to analyze patterns in successful work, like bestselling book titles and viral articles. Read this if you want to level up your skills fast and close the gap between novice and pro.\n\n\"When AI Gets More Capable, What Will Humans Do?\" by Dan Shipper/Chain of Thought: AI is getting better at mimicking human creativity, but that doesn't mean we're obsolete. Dan argues that the future of creative work will look less like sculpting and more like gardening. Read this to understand how to stay relevant in a world where AI can write 80 percent like you.\n\nWe asked prompt engineer and author Michael Taylor, who most recently wrote about emotionally prompting AI tools, for one good read:\n\n🖇 “Stop Building SaaS for SMBs—Buy Them Instead” by Ori Eldarov: “As a former agency owner, it's interesting to see people advocating for building applications other than SaaS. There's an opportunity for services businesses to use AI to earn software-level margins over the next few years.”\n\nWhat if cities had soundtracks?\n\n\n\n\n\nThat’s all for this week! Be sure to follow Every on X at @every and on LinkedIn.\n\n\n\n",
      "word_count": 556,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3143/S-Cover.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3131/thumbnail_Screenshot_2024-06-15_at_12.14.39_PM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "context-window"
    },
    {
      "url": "https://every.to/context-window/startup-signals-and-tech-hybrids",
      "title": "Your AI Research Assistant and Startup Signals",
      "author": null,
      "author_url": null,
      "publication_date": "July 14, 2024",
      "content": "Your AI Research Assistant and Startup Signals\n\nPlus: Book-writing tips for internet writers\n\nHello, and happy Sunday! It’s high summer in the United States, and much of the country (not to mention the rest of the world) is or will be under a heat dome. Evan and I have been sweating it out on the east coast, hoping our air conditioners hold up, while Dan has been in Rome (where ACs are comparatively less prevalent) for an Aspen Institute conference. If you want to feel a sense of hope while you pray for the humidity to drop, scroll down for a heartwarming story about refrigerant emissions (really!).\n\nOn to everything (else) we published this week, along with our take on the latest tech and business news.—Kate Lee\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n🔏 \"Why Talk to Customers When You Can Simulate Them?\" by Chris Silvestri: Ever wish you could read your customers' minds? AI might be the next best thing. Chris shows how to use large language models to create detailed customer personas, test marketing copy, and uncover hidden insights—all in hours instead of weeks. Read this if you want to turbocharge your market research and create messaging that truly resonates with your audience.\n\n\"Paramount's Dilemma: Content Isn't King—Distribution Is\" by Evan Armstrong/Napkin Math: The former Hollywood giant is getting an $8 billion lifeline, but it might not be enough. Paramount's new owners may think content is king, but history shows that distribution is the real crown jewel. Between block booking and launching TV networks, Paramount's past success came from controlling how—not just what—people watched. Read this for a fascinating look at how the internet broke a century-old business model and why even Top Gun: Maverick can't save Paramount from the attention economy.\n\n🎧  \"The AI-powered Era of Scientific Discovery Is Here\" by Dan Shipper/Chain of Thought: In this episode of AI & I, Dan dives deep into how large language models like BrainGPT are transforming neuroscience with professor Bradley Love. Dr. Love argues that AI could revolutionize how we approach scientific discovery, such as in predicting experimental outcomes or challenging our need for simple explanations. Listen to this if you want to understand how AI might reshape the future of science—and why that future might be less about elegant theories and more about powerful predictions. 🔏  The transcript of this episode is for paying subscribers.\n\n\"Searching for Signal\" by Evan Armstrong/Napkin Math: Have you ever had that gut feeling about a startup, even when the odds were stacked against it? It turns out that that irrational instinct might be your best compass. Evan tells the story of Clay, a $500 million company that succeeded because its founders trusted their intuition over cold, hard data. Read this if you want to learn why emotion, not just strategy, is crucial for startup success—and how to tap into that \"divine belief\" in your own work.\n\n\"The Business (and Social Good) of Destroying Old Air Conditioners\" by Jamie Wong: Jamie—an early Figma engineer-turned-investor—chronicles Louis Potok’s journey from data scientist to climate entrepreneur, tackling the unsexy problem of refrigerant disposal in Southeast Asia. Read this for a refreshing look at how following an idea down a rabbit hole can lead to meaningful climate action—and maybe make millions.\n\nAn AI startup—with actual revenue! One common complaint on the tech corners of X is that AI startups are all funding and fluff, with no actual customers. Hebbia, which enables you to attach LLMs to data rooms where investment info is stored and pull out facts from due diligence documents, is the violation of that asinine assumption. The technology makes it so private equity funds or private credit investors can decide whether they want to invest much more quickly. I’ve heard from multiple investors that it transformed their diligence process. The company just raised $130 million from Andreessen Horowitz at a $700 million valuation.\n\nWait, what the hell even is an AI startup? In 2002, every new software company was a “cloud company.” In 2024, every startup claims to be an “AI company.” But what does that mean? I’m increasingly convinced that unless you are explicitly in the business of training and selling LLMs, you are not an AI company. Take, for example, Captions, a video-editing application that automates parts of the editing workflow and can translate the accompanying audio into other languages. It just raised $60 million valuing it at $500 million. While it calls itself an AI company, I would argue that that is just the sizzle of the product—what it really does is make video editing easier.\n\nIt’s robot time. We’ve been chatting for a while about how VCs are deploying capital with the idea that robotics are about to dramatically improve using similar techniques as LLMs. (Do you believe this? If so, reach out to me at [email protected]—I’m working on an article analyzing the technology.) Skild AI is the latest example of a startup going after the AI-and-robots opportunity, raising $300 million from the most prominent firms of Sand Hill Road including Sequoia, Lightspeed, Coatue, and Jeff Bezos’s family office. Frankly, I love seeing this sort of thing get funded. Watching investors get more comfortable underwriting science risk is a welcome change from the 2010s.\n\nFarewell, OpenAI board, we hardly knew ye. Both Microsoft and Apple were on the OpenAI board for the length of time I could keep a woman interested in high school (roughly one month). They both left their seats recently over concerns over antitrust laws. I also have to believe that there is a growing recognition by Altman that these companies are frenemies, with emphasis on the latter part of the word. Both companies are training foundation models, too.\n\nVideo game stocks ripping. While most of the gaming industry has been gripped by layoffs, the Korean developer behind 2024’s Stellar Blade went public this week, with its stock up almost 50 percent. I’ve argued for a while that distribution, not content, is king. Here is a counterpoint. The company has no real distribution advantages, and its job is to just make great games, which it has done so far. My theory does allow for this kind of success, but you can make becoming 10 times bigger 10 times easier by owning distribution platforms versus making the stuff that resides on them.—Evan Armstrong\n\nOn the bubble. While it’s true that big tech is investing lots of money in AI without much to show for it (yet), they’ve done it before. As a share of revenue, current AI investments aren’t that crazy:\n\n\n\n\n\nFor both Google and Meta, current spending as a percentage of revenue is high, but it’s within the normal range of the past 10-15 years. Google (and Amazon and Microsoft) invested a lot in the cloud before they started selling it in meaningful amounts—Microsoft’s Azure took seven years to generate ChatGPT-levels of revenue. Ask people at Meta about the company’s big investments in the metaverse or stablecoins, and see how those worked out (spoiler: Meta is doing fine). So big money is being spent on AI, but these are big companies with a lot of money to spend. Will they have some egg on their face? They might, but they’ve been down this path before.—Moses Sternstein\n\nNat Eliason, author of the new memoir Crypto Confidential: Winning and Losing Millions in the New Frontier of Finance (which he initially chronicled on Every), shared his top three tips for internet writers who want to write a book:\n\nPractice fiction writing. It’s much harder to take a reader through a 300-page book than a 2,000-word article. You have to study storytelling, and the best way to learn how to write better stories is to write more of them. Studying and practicing fiction writing was by far the most helpful thing I did for making the book an exciting read.\n\nGet off the internet writing-dopamine hamster wheel. When you write for the internet, you rarely have to wait more than a few days, or even hours, to start getting feedback. Likes, shares, comments, emails—you might not realize how deeply your sense of accomplishment hinges on these signals. But writing a book is a long, slow, lonely process. Practice working on longer-term work now so the shock isn’t as severe.\n\nDo it before you’re ready. Writing a book feels like something you have to “be ready” for, but—like having kids or starting a business—there’s never a right time. You can only become ready by doing it. The two, three, four years it might take are going to pass anyway. It’s better to start sooner than keep putting it off.\n\nStory mining. The most common type of feedback I receive about my writing is, “A personal story would be really good here,” or its evil twin, “This piece is crying out for an anecdote.” Yes, a personal story would be good here. And so would stabbing me repeatedly with a rusty spoon dipped in lemon juice. Writing anecdotes is hard because I have to trawl my memory to find something relevant, and then I agonize over whether the story is good enough or if I've just wasted an hour of my life on a dead end. But the power of a good story in your writing is undeniable. It's the difference between dry facts floating in the void and information that sticks. To crowbar out my personal gems, I've stolen a technique from Mike Taylor, a prompt engineer and writer at Every. He uses ChatGPT to interview himself to find personal anecdotes that give his essays a punch. Not only does this make the writing process smoother, AI points you directly to the good stories in half the time—like having a GPS for your memories.—Ashwin Sharma\n\n\n\n\n\nEvan’s piece about Clay garnered a lot of feedback from entrepreneurs:\n\n“Just had something like this click for me in the last few days—getting into building React apps with Claude. The most important realization: This is so much fun, I can literally do this all day and not get tired of it.”—An AI founder\n\nWant to chat? DM Dan or Evan on X.\n\nWork with us at Every. We’re hiring a full-stack designer who can work across different products, projects, and initiatives. You should move fast, be scrappy, know AI, and most of all, love Every. The ideal candidate has 1-5 years of experience, and is excited to grow with us and turn ideas into reality. Since we're bootstrapped, compensation will scale as the business scales. If you’re interested, email Lucas Crespo at [email protected] with your portfolio, salary expectations, and why you’d like to join us.\n\nWeather Windows, a weather app UI that can be minimally displayed over glass.\n\n\n\n\n\nThat’s all for this week! Be sure to follow Every on X at @every and on LinkedIn.\n\n\n\n",
      "word_count": 1808,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3150/Sunday.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3370/thumbnail_Screenshot_2024-12-10_at_6.36.09_PM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3131/thumbnail_Screenshot_2024-06-15_at_12.14.39_PM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "context-window"
    },
    {
      "url": "https://every.to/context-window/ai-ip-and-the-anxiety-of-new-technology",
      "title": "AI, IP, and the Anxiety of New Technology",
      "author": null,
      "author_url": null,
      "publication_date": "August 25, 2024",
      "content": "AI, IP, and the Anxiety of New Technology\n\nPlus: Learn how to write with AI in 30 days\n\nHello, and happy Sunday! ICYMI, registration is open for our new course, How to Write With AI. Evan Armstrong will teach you how to do the best writing of your life using AI tools like ChatGPT, Claude, Spiral, and Lex—all in 30 days. Dan Shipper and Every’s new entrepreneur in residence Brandon Gell break the fourth wall and discuss how they created Spiral as well as our other AI tool, Sparkle, in a wide-ranging discussion about building an AI media and software company. Read on below.—Kate Lee\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\"How to Write With AI\" by Evan Armstrong: Ever dreamed of writing like a pro but felt stuck with a blank page? AI can get you there. Evan went from 25 subscribers to 75,000 using AI tools, and now he's spilling the secrets in a four-week course. Learn to use ChatGPT, Claude, Lex, and Spiral to supercharge your writing process. Early bird registration ends Tuesday, so register now.\n\n🎧 \"Building an AI Media and Software Empire\" by Dan Shipper/Chain of Thought: We’ve been heads down for years, quietly building Every into a new type of company. In this podcast, new entrepreneur in residence Brandon joins Every CEO Dan Shipper in discussing Every’s master plan. We’ve tried to make a \"creative playground\" that combines high-quality content, paid subscriptions, and AI-powered tools. Read this for a behind-the-scenes look at how we’re turning Every into a calm, profitable business that's part media company, part startup incubator. Subscribers have access to the full transcript.\n\n\"Why I Avoided AI—And How I Finally Embraced It\" by Rhea Purohit/Learning Curve: Even AI experts can struggle to use the tools they write about. In a new series, Rhea Purohit unpacks the psychological barriers that kept her from fully embracing AI in her work. From the comfort of familiar workflows to the uncertainty of new tech, she offers a relatable journey of overcoming AI anxiety. Read this for practical strategies to conquer your own tech hesitations and start reaping the benefits of AI in your daily life.\n\n\"The Mantra of This AI Age: Don't Repeat Yourself\" by Dan Shipper/Chain of Thought: Forget the doomsday predictions—AI isn't coming for your job. It's coming for your boring, repetitive tasks. Dan argues that current AI technology is like having 10,000 Ph.D.’s at your fingertips, ready to handle anything they've seen before. Read this to understand how AI will free you up to do more interesting work, and why noticing where you repeat yourself is the key to leveraging AI in your career.\n\n\"Copy Rights and Wrongs\" by Evan Armstrong/Napkin Math: Copyright laws weren't designed for robot Shakespeare, and now we're all scrambling to figure out who gets paid when the machines start churning out content. Read this to understand why the real issue might be less about legal jargon and more about cold, hard cash.\n\nThe biggest entertainment property in the world is probably Roblox. This is a company more people should be paying attention to. It has 380 million-plus users—twice as many players as Fortnite—but because it started as a children's game, it gets less attention. The power law reigns supreme.\n\nWalmart’s ad revenue is up 30 percent. We live in an attention economy, and perhaps the most valuable type of attention is the kind consumers have when browsing for toilet paper. Retailers are learning from Amazon’s ad business that if people come to your website, ads are a delightfully high-margin way to increase revenue. Expect every company that has a URL to eventually spin one up.\n\nGoogle gets a back-alley shakedown for $125 million. Google helped destroy the business models for local newspapers (bad), so information about vital community services has gone poof (very bad). In response, California lawmakers made Google pay $125 million over five years to local publishers. New business idea: Build a crappy product no one wants to pay for, and rather than make a better service, just have the government take profit from your competitor. Google is no more responsible for the internet's destruction of local news then Ford is responsible for the end of the buggy business.\n\nIntellectual property and its relationship to AI is far more complicated and important than most people realize. A key question is around tracking IP ownership and usage. Almost every AI company trains on copyrighted materials without permission from the owner under the defense of “fair use.” Whether that is true or not is up to the courts, but I went looking for companies trying to build a technological solution to a legislative problem. I found one called Story, a crypto company that puts IP on the blockchain that raised $80 million at a rumored $2.25 billion valuation. Because I have no idea what “IP on the blockchain” means, I asked founder Jason Zhao how they would stop AI companies from training on copyrighted content.\n\nQ: Most training data is scraped regardless of terms of service under the guise of fair use. Is Story aiming to solve that problem? Or is there some other way you are looking to protect the IP?\n\nA: Yes, this is the status quo. Story aims to address the issue of internet scraping in two ways: legal and technical. On the legal side, we've made it extremely easy to use our API to opt out of AI training, or to opt in but with specific economic terms associated in a programmatic, machine-readable way. For example, I can register my voice on Story and set terms for how AI could train on it, but if so, X percent of royalties would need to be shared. We're seeing precedent for jurisdictions such as the EU enforcing these opt-outs starting in 2025, but at the least, in other jurisdictions, we declare the creator's desired terms and make them far more explicit, and thus any violation more explicit as well. Reducing the friction for these declarations and making them machine-readable is a key step, and that's what Story does. On the technical side, we're partnering with platforms that help block scrapers, like tools such as Spawning. Just like SMTP required third-party spam filters to ultimately drive mass adoption, Story is a neutral protocol that partners with other technical solutions.”\n\nThe company won’t be putting the actual media on chain; instead, it “embeds IP-related metadata on chain, as well as the ability to execute and enforce the terms stipulated in that metadata.” Translation: The contracts and terms will be held on the chain, not the content itself. When I asked Zhao about whether anyone is actually using Story—a question that is too often neglected in startup-land—he replied with two: a “top foundation model company” and a collaborative art platform called Magma.—Evan Armstrong\n\nA 60 percent surge in startup failures is not a bad thing. The Financial Times published the following chart with this tweet: “The rate at which U.S. start-ups are going bust is more than seven times higher than in 2019, threatening millions of jobs and risking spillover to the wider economy.”\n\n\n\n\n\nSource: X.\n\nShowing the absolute number of startup failures without the denominator of total startups formed is a data hate crime. In 2021, the startup formation rate was the highest it had been in 14 years. A startup typically raises money every 18-36 months, so more startups funded in 2021-2022 would naturally result in more of them failing in 2024-2025. Carta, a platform for startups to manage their cap table, produced and published the dataset, which caused needless panic. The company also published this chart about DPI, or how much money venture capital firms have distributed back to their investors:\n\n\n\n\n\nSource: X.\n\nRoughly forty percent of the 2018 funds have not returned anything yet—i.e., they have yet to have a successful exit. This supposed failure is the industry working exactly as intended. The best companies take 10 years to develop. Many of the marquee companies of the last generation of startups (SpaceX, Stripe, Rippling, etc.) still haven’t gone public. As always, headlines are deceiving.—EA\n\nRhea Purohit, who wrote about overcoming her AI reluctance, shared one good read:\n\n🖇 \"Mental Strength in Judo, Mental Strength in Life\" by Cedric Chin: “Cedric left his life behind for four months to train for a national Judo tournament, and he wrote this when he returned. As adults, we rarely seek out discomfort—even when we know it might lead to a meaningful outcome—and Cedric’s essay is my reminder to do just that. It’s also why you might hear me mutter, ‘It’s a matter of will, not a matter of skill,’ under my breath when I find myself in a physically demanding situation. (Disclosure: I work with Cedric on some projects but didn’t work on this piece.)”\n\nWrite to remember. I consider myself a know-it-all who knows nothing: I read a lot but can’t recall specific facts and details. Worse, I'm left with a bunch of vague opinions, but zero recollection of the evidence or reasoning that led me to form them. That is, until I discovered Holden Karnofsky's brilliant essay on learning through writing. Karnofsky, the cofounder of charitable giving platform Givewell and director of AI strategy at Open Philanthropy, lays out a seven-step process for forming a coherent worldview with reasoned opinions. His method isn't rocket science, but it is surprisingly effective: You form your own premature hypothesis from the information you’re reading and ruthlessly list its weaknesses, and then switch sides. It’s not fun, because you’re forcing your brain to consider the “other side,” which we’re not hard wired to do, and you’re actively processing information rather than passively consuming it. But it works, because I'm getting better at remembering why I'm wrong.—Ashwin Sharma\n\nWhat if Duolingo made Furbies for language learning?\n\n\n\n\n\nThat’s all for this week! Be sure to follow Every on X at @every and on LinkedIn.\n\n\n\n",
      "word_count": 1659,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3201/Screenshot_2024-08-24_at_5.34.23_PM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3370/thumbnail_Screenshot_2024-12-10_at_6.36.09_PM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "context-window"
    },
    {
      "url": "https://every.to/context-window/what-actually-matters-and-what-doesn-t-for-deepseek",
      "title": "What Actually Matters (And What Doesn’t) For DeepSeek",
      "author": "Evan Armstrong",
      "author_url": "/@ItsUrBoyEvan",
      "publication_date": "January 28, 2025",
      "content": "What Actually Matters (And What Doesn’t) For DeepSeek\n\nAllow us to explain why your 401k is down\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nNews of DeepSeek’s R1 model, released last week, has sent shockwaves through the tech world. Like many of you, we at Every have been captivated by the Chinese startup’s inexpensive, high-performing model, and the innovations that were necessary to achieve it.\n\nAs for the implications? There’s a lot to reckon with, and we’re still only just figuring out what this new model can do. Investors mostly felt R1’s arrival on the scene wasn’t positive news for AI’s U.S.-based incumbents, and shares of Nvidia and other chip makers were hit particularly hard. Builders, meanwhile—including some of us here at Every—are pretty excited.\n\nBecause there’s so much to unpack, we’ve pulled together three of our writers to each tackle one aspect of the news that struck them, and where they see things going. Alex Duffy breaks down the innovations that led to R1 achieving a 90 percent cost reduction in performance compared with OpenAI’s o1 model. Entrepreneur in residence Edmar Ferreira discusses the immediate implications for people looking to build AI-based applications. Finally, Evan Armstrong talks about the markets’ (over-re)reactions.\n\nLet’s dive in.—Michael Reilly, managing editor\n\nMost large language models (LLMs) rely on reinforcement learning (RL) to refine how “helpful and harmless” they sound. Notoriously, OpenAI has used cheap labor in Kenya to label and filter toxic outputs, fine-tuning its models to produce more acceptable language.\n\nDeepSeek R1 took a different path: Instead of focusing on sounding right, it zeroes in on being right—especially in math, coding, and logic. Rather than learning from subjective human preferences, R1 follows reasoning-oriented RL that rewards the model only if its code compiles and passes tests or if its math solutions are indisputably correct. Because “correctness” is easier to define for these tasks, R1 can scale its training without needing armies of human data labelers. Surprisingly, even for tasks that are more subjective—like creative writing—this emphasis on logical consistency tends to deliver better results, too.\n\nR1’s leap in capability and efficiency wouldn’t be possible without its foundation model, DeepSeek-V3, which was released in December 2024. V3 itself is big—671 billion parameters (by comparison, GPT4-o is rumored to be 1.8 trillion, or three times as big)—yet it’s surprisingly cost-effective to run. That’s because V3 uses a mixture of experts (MoE) approach, where the model is divided into specialized sections, each of which functions as an “expert” in a certain domain. When a query comes in, only the expert section “lights up”—around 5 percent of the model, or 37 billion parameters. This significantly reduces the compute power needed. MoE gained traction in 2024 thanks to teams at companies like Mistral, xAI, and Databricks, which showed it can be easily integrated, scales well, and brings major efficiency gains.\n\nOn top of that, V3 embraced multi-token prediction (MTP). Rather than predicting text one word at a time and inspired by Meta’s FAIR (Fundamental AI Research) team’s ideas toward building \"Better & Faster Large Language Models via Multi-token Prediction,\" it predicts multiple words simultaneously. Finally, a trick called FP8 training helps V3 run even faster and cheaper by using “rounded” (lower-precision) numbers. This approach slashes compute costs, memory usage, and reliance on huge GPU clusters—an especially big deal in an era of hardware export controls.\n\nCrucially, thanks to R1's new distillation approach to maintaining performance with models of smaller sizes, these advanced reasoning skills don’t require a Google-sized infrastructure. DeepSeek’s distillation techniques let R1’s capabilities trickle down into smaller, more budget-friendly versions of the model. You can even run a distilled variant locally on your MacBook Pro with just one line of code. In conjunction with its open-source license, this efficiency has led many cloud providers, like Groq, to provide access to their own hosted version of the R1 model. Having options gives consumers more choices taking factors like speed, reliability, price, and privacy into account.\n\nPerhaps R1’s biggest breakthrough is the confirmation that you no longer need enormous data centers or thousands of labelers to push the limits of LLMs. If you can define what “correctness” means in your domain—whether it’s coding, finance, medical diagnostics, or creative writing—you can apply reasoning-oriented RL to train or fine-tune your own model. You pick the benchmarks; you control the objective “good.” Meanwhile, V3’s underlying architecture and cost-saving optimizations ensure you won’t break the bank. By decoupling “performance” from raw scale and shifting it toward well-defined standards of correctness, and being willing to share its innovations, DeepSeek R1 hands more power to researchers, entrepreneurs, and even hobbyists—anyone willing to experiment on how we train and evaluate AI.—Alex Duffy\n\n\n\n\n\n\n\n\n\nWhen you write a lot about AI like we do, it’s hard not to see opportunities. We build tools for our team to become faster and better. When they work well, we bring them to our readers, too. We have a hunch: If you like reading Every, you’ll like what we’ve made.\n\nTraining LLMs can be divided into two major phases: pre-training and post-training. The pre-training phase is an extremely expensive process that involves training a general model from a large corpus of data. Even in the case of DeepSeek, a single run of training costs $6 million, while it’s estimated that Meta’s Llama 3 model costs $120 million to train. DeepSeek’s decreased costs are a huge breakthrough, but they’re still too expensive for most organizations.\n\nMost companies outside of the big labs focus on post-training: We work on top of a \"pre-trained” model like Llama to train it to be good at our desired tasks. There has been a widely held belief that post-training language models just surface data from pre-training, which means that language models can only interpolate plans or reasoning patterns seen in pre-training. I think that is clearly debunked now. DeepSeek R1 shows that LLMs can learn new things directly from post-training with reinforcement learning (RL).\n\nDeepSeek R1 introduces revolutionary post-training techniques that can be applied across various open-source LLMs like LLama, making AI development more accessible and efficient, particularly for smaller organizations. Using reinforcement learning is like training a dog: You give it a reward every time it does the right thing. If you can automatically generate the reward, you can train the AI to do the task, even without providing it with many examples. The AI can learn from its own experience instead of only from human examples.\n\nTraditional LLM fine-tuning requires extensive labeled datasets, creating barriers for smaller teams. DeepSeek R1 RL techniques address this by enabling models to fine-tune on smaller, specialized datasets, which are easier for smaller teams to collect. This is especially valuable in domains like math, where outcomes can be automatically verified against known solutions or specifications.\n\nOrganizations with deep domain expertise can leverage these RL techniques by creating customized evaluation sets and training environments. For example, healthcare startups can design scenarios mimicking clinical decision-making, while financial institutions can develop reward functions based on risk-management outcomes.\n\nA key advantage of these RL advancements is their universal applicability across any open-source model. This flexibility allows organizations to future-proof their AI investments by using the best current models, and reusing the data and workflow to retrain when a better model comes up. For instance, a customer support AI could adopt newer foundational models while preserving its established reward systems for response quality.\n\nHowever, DeepSeek R1 has several limitations:\n\nDespite these challenges, DeepSeek R1 post-training RL techniques represent a significant advancement in AI development. By enhancing adaptability, emphasizing domain expertise, and ensuring universal applicability, they empower organizations to create more specialized and effective AI systems.\n\nThe technology particularly benefits startups and smaller teams, who can now compete more effectively in the AI space by focusing on their unique expertise rather than on data acquisition. Instead of collecting thousands of perfect examples, you just need to define what \"good\" looks like for your specific use case. As with training a dog, you don't need examples of every possible trick—you only need to reward the right behaviors. Startups can focus on their unique domain expertise and building great products, rather than spending months collecting and labeling training data. If you can automatically evaluate whether your AI is doing a good job at your specific task, you can train it to get better through trial and error, just like a human would learn.—Edmar Ferreira\n\nAssume you believe in artificial general intelligence (AGI). Also assume that you believe that DeepSeek’s technical innovations make it possible to get there. With those beliefs in mind, ask yourself: How many years and how many dollars until we achieve AGI?\n\nThe implications for R1 are less to do with the present usefulness of DeepSeek's work—which is on par with other models—and more to do with whether these techniques can be used to make AGI happen on our existing infrastructure.\n\nBig tech stocks were punished yesterday not because it proved their models weren’t useful, but because the inflated AI revenue expectations—and the data centers built to support those beliefs—were simply too aggressive in a world where DeepSeek-style models can offer inference at one-tenth the cost.\n\nThere is a world in which, with more intelligence more cheaply available, developers start clamoring for even more compute. This could very well be the case! However, the timing of data center utilization matters. Meta alone forecast spending roughly $65 billion on data centers just this year. Cloud hyperscalers like Microsoft or Amazon Web Services are forecasting similar levels of data center spend, while AI companies like OpenAI are setting up $100 billion data centers—and inference needs for these centers was just cut by 90 percent! Someday, somehow, these centers will hit 100 percent utilization rate, but the forecasted growth in training and inference costs on which these infrastructure projects were based has just been wildly upended.\n\nIn our previous work on bubbles, we happily noted that the infrastructure built out during a bubble eventually resulted in consumers benefiting in the long run. In the face of the DeepSeek news, similar arguments are being trotted out for big tech’s spendy ways. However, there are three reasons to cast doubt on that narrative:\n\nR1 does not spell the end of big tech. It speeds up timelines and likely forces some companies to reduce their data center build-outs (or at least justify them more thoroughly than they have up to this point).\n\nWhether yesterday’s market reaction of Nvidia’s 17 percent stock plunge is justified is unclear. Our team is still debating the implications and will undertake further experiments in which we employ some of these training models ourselves. Some of us are shorting Nvidia; others are buying. Sign up to receive the results of our tests.—Evan Armstrong\n\n\n\n\n\nAlex Duffy is the consulting lead and a staff writer at Every, where he writes about empowering people with AI tools and technology in Context Window. You can follow him on X at @theheroshep and on LinkedIn.\n\nEdmar Ferriera is an entrepreneur-in-residence at Every. Previously he founded and sold Rock Content, a leading content marketing platform. You can follow him on X at @edmarferreira and on LinkedIn.\n\nWe also build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Write something great with Lex. Deliver yourself from email with Cora.\n\nGet paid for sharing Every with your friends. Join our referral program.\n\n\n\n",
      "word_count": 1903,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3440/deepseek.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3137/thumbnail_Screenshot_2024-06-22_at_10.17.33_AM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "context-window"
    },
    {
      "url": "https://every.to/learning-curve/why-there-s-no-right-way-to-use-ai",
      "title": "Why There’s No ‘Right’ Way to Use AI",
      "author": "Rhea Purohit",
      "author_url": "/@rhea_5618",
      "publication_date": "January 17, 2025",
      "content": "Why There’s No ‘Right’ Way to Use AI\n\nSoftware has always had clear rules. AI forces you to write your own.\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\nIf you prefer to listen to rather than read our essays, we’re live on ElevenLabs’s ElevenReader app. Download the app and subscribe to our feed to listen to audio versions voiced by AI.\n\n\n\n\n\nI’ve been a writer here for over a year—and I thought everyone on the team was “good” at AI…while I wasn’t.\n\nWhat do I mean by “good”? It goes beyond technical knowledge of LLMs, like chain of thought or few-shot learning. Instead, they used AI with a natural fluency; an intuitive sense of its uses and limitations. I kept up with the zeitgeist and tried out new models, but I still fumbled to find that quiet competence.\n\nUntil the fog finally lifted when I spent a Saturday in November getting familiar with Excel functions. I realized that you can learn the “right” way to use conventional softwares like Excel, but generative AI is inherently different—it’s less about searching for the “right” way, and more about defining what that means for you.\n\nI live in Spain, and perhaps the only boring thing about that is dealing with bureaucratic immigration processes. In November, one of these regulations required me to calculate the exact number of days I’d spent outside the country in the last four years. Tedious stuff, indeed. As I thumbed through my passport for entry stamps and scoured my email for flight tickets, I logged the information in an Excel sheet. I used simple functions to calculate the number of days in each trip I’d taken and add them up at the end.\n\nI wouldn’t call myself an expert in Excel, but I got comfortable with the basics of the software quickly. It was easy. I figured out which formula I needed, typed it in, and if I made a mistake, Excel would helpfully throw up an error in that cell—I saw #NULL! or #NAME! and knew I’d gotten something wrong. (I was dealing with a relatively simple task, and there are certainly far more complicated functions within Excel that I haven’t begun to learn about.)\n\nWhen you input a formula correctly in Excel, you get the right answer. If there's an error, Excel points it out. This clear distinction between right and wrong made me feel confident. I was certain I was using the application correctly. The direct feedback loop goes beyond just Excel to most types of conventional software—and it struck me how different this was from using an LLM.\n\nI use Claude while I write sometimes, to brainstorm ideas for a lede, or for feedback on a piece. The chatbot always returns coherent, polished answers, even to prompts riddled with typos and garbled context. There’s no clear way to know if I’m using AI the “right” way. The beauty of LLMs is also their curse—there is no one, true way to get the most out of the technology. Add to that the possibility that the answers are objectively wrong because the models are prone to hallucinations. That nagging feeling I had about not being “good” at AI was about understanding the shades of gray it exists in.\n\n\n\n\n\nWhen you write a lot about AI like we do, it’s hard not to see opportunities. We build tools for our team to become faster and better. When they work well, we bring them to our readers, too. We have a hunch: If you like reading Every, you’ll like what we’ve made.\n\nA big part of conventional software’s value proposition lies in its predictability. The software we use to send emails, listen to podcasts, and read ebooks is so reliable that we don’t give it a second thought anymore; we just assume it’ll work. Identical input, identical output. After years of being exposed to apps like that, I had internalized that digital interactions are deterministic. There’s always a “right” way to use software, and you learn how to use it by figuring out what that is.\n\nGenerative AI turns this on its head.\n\nLLMs have a stochastic element: Output can vary with similar—or even identical—inputs. You can give ChatGPT an identical prompt and get different answers. Broadly, while conventional software follows fixed rules, LLMs operate probabilistically to produce output shaped by likelihood. LLMs can also generate responses dynamically: Each time you prompt it, the model can “decide” on slightly different approaches on how to process input.\n\nThe stochastic nature of these models is part of what makes AI so powerful, enabling the technology to solve open-ended problems in creative ways. It’s also why using AI can feel…unsettling at times. Unlike conventional software, which directs users down specific, learnable paths, AI is a wide open field. The onus is on users to define their own approach to using the technology. While this can be more rewarding, it’s also a fundamentally more challenging task. It requires a deep comfort with ambiguity and a commitment to relentless iteration.\n\nTo muddy the waters further, using AI is often assumed to be “easy” because the interface through which we interact with LLMs—chat—is very intuitive. As writer Simon Willison says in a 2024 review of LLMs that’s been doing the rounds, “A drum I’ve been banging for a while is that LLMs are power-user tools—they’re chainsaws disguised as kitchen knives.” It isn’t hard to talk to a chatbot, but integrating meaningfully into your life, both personal and professional, is a different matter.\n\nI no longer feel like an imposter at Every, and it’s because I’ve changed the way I approach AI.\n\nI stopped wondering if I’m using AI the “right” way; after all, given the stochastic nature of the technology, I’m not sure if one exists.\n\nInstead, I’ve been thinking about how to tilt the odds that the LLMs I use in my favor. The low-hanging fruit for me has been personalizing the models, by adding Custom Instructions in ChatGPT (yes, I own up to being one of the shamefully uninitiated) and Styles in Claude. This ensures that the AI’s responses match my needs and preferences more closely, without having to repeat the same instructions in every prompt. I’ve also gone from feeling overwhelmed and mildly nihilistic about prompt engineering techniques to trying them out.\n\nThis isn’t revolutionary advice—I’m far from the first person to suggest that customizing a LLM or using prompt engineering will improve its output—but I use these examples to illustrate the shift in my mindset. I went from expecting to learn how to use AI to defining my own relationship with the technology.\n\nThe distinction matters. When you're defining a relationship with technology, you're asserting agency. You're acknowledging that AI's potential isn't fixed or predetermined, but rather something you actively shape. You don’t have to find the “right” way, because it’s up to you to create it.\n\n\n\n\n\nWe also build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Write something great with Lex. Deliver yourself from email with Cora.\n\nGet paid for sharing Every with your friends. Join our referral program.\n\n\n\n",
      "word_count": 1195,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3399/roads.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3570/thumbnail_learning(2).png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "learning-curve"
    },
    {
      "url": "https://every.to/learning-curve/why-i-avoided-ai-and-how-i-finally-embraced-it",
      "title": "Why I Avoided AI—And How I Finally Embraced It",
      "author": "Rhea Purohit",
      "author_url": "/@rhea_5618",
      "publication_date": "August 19, 2024",
      "content": "Why I Avoided AI—And How I Finally Embraced It\n\nUsing a new technology can be hard. Here's what you can do about it.\n\nAs someone who writes about AI for a living, Rhea Purohit has a unique perspective on the challenges of incorporating these tools into our daily lives. In her inaugural piece for Learning Curve, a new monthly series on AI adoption, she explores the psychological barriers that have held her back from fully embracing AI tools—and how she's overcoming them. By breaking down her own hesitations and sharing concrete steps she's taking to integrate AI, Rhea offers a roadmap for anyone feeling left behind by the AI revolution. Her column will help you understand why even tech-savvy professionals can be slow to adopt new tools, and teach you practical strategies for overcoming your own AI anxiety.\n\nIn addition to today's column, last week we launched Sparkle, an AI organizing tool, and there’s more new stuff to come. If you’ve been waiting to subscribe to Every, now is your time. For the next 24 hours, become a paid subscriber for just $132 per year—a 33 percent discount—and get the best bundle of writing and software on the internet.—Kate Lee\n\n\n\n\n\n\n\n\n\nI write about AI for a living, but I struggle to use it myself.\n\nEach time the thought of using AI to research and write crosses my mind, it’s followed by a quiet reluctance. It never seems like the right time, and I honestly don’t know if it’ll be worth the effort.\n\nThis paradox has been weighing me down for a while, so I went on a mission to understand why it exists. Here’s what I’ve learned so far:\n\nI struggle to use AI because I don’t like the uncertainty that comes with using a new technology.  Once I realized that this paradox isn’t rooted in inauthenticity or incompetence, it freed me to find ways to change. And soon, I started running my own experiments with AI, like:\n\nBeing able to make sense of why I felt friction in integrating AI into my workflow is helping me get better at deriving value from it. If there’s a small, tinny voice at the back of your head, saying that you could be doing more with AI, perhaps my little epiphany can help you do the same.\n\nI started by thinking about what I do every day and how AI could help me with that. As a writer, I:\n\nSomething I write about often are insights from AI & I, Every’s podcast about how smart, creative thinkers use AI. I spend hours every week listening to how they’ve integrated these tools to become better versions of themselves.\n\nI’m acutely aware that LLMs can help me read, think, and write. AI carries the promise of doing great work in less time. It sounds like magic…but I still don’t use it as much as I should.\n\nMy hunch is that this is because I wrote for a living before AI became accessible. I know how to go from blank page to finished piece without using a LLM. I have workflows in place—reliable and efficient—to get the job done. They typically involve coffee, a Google document, a few stray research tabs, and many short walks. It’s familiar, comfortable, and—perhaps most importantly—I know it works.\n\nAI, on the other hand, feels like work. It’s like hiring your first employee. Yes, they will eventually make your life easier, but there’s a lot to be done before that happens—you have to think about what you want to delegate, find the right candidate, and onboard them into your organization. Something similar happens when you start using AI. You have to figure out what parts of your workflow you want to automate, choose the right tool for the task, and iterate on the input you intend to give it.\n\nAnd there’s the other thing: AI is an objectively new technology. We’re in the early days of experimenting with it, and right now, there is no one true way to use it. At least not yet. It has been known to generate different results depending on whether your prompt is in ALL caps, if you yell at it, and even what day of the week it is. There is emerging research on the best ways to use AI, but for the most part, it’s all up for grabs.\n\nIn other words:\n\nNow that I’ve identified the source of my friction, the uncertainty that AI brings to my workflow, I want to go deeper. I’d like to think I’m open to trying new things, so why am I drawn to things that are familiar to me?\n\nWell, it turns out that humans are wired to prefer the familiar to the uncertain. And researchers have found that this is even more pronounced if there’s an element of finality involved in the decision.\n\nHere’s a thought experiment.\n\nWhat if I told you that you could have a conversation with anyone right now? It could be your favorite author, the last speaker of a lost language, your two-year-old’s imaginary friend…you get the gist.\n\nThat sounds pretty exciting, right?\n\nBut what if I added just one more condition: This would be the last conversation you’d ever have.\n\nHas your answer changed? My guess is that you’d choose to talk to someone you know, love, and care for. I know I certainly would.\n\nAccording to a recent research paper, when humans are faced with a narrowing window of opportunity to enjoy an experience, their preferences shift from the shiny, new, and novel to the old, familiar, and comforting.\n\nThis speaks to the type of experiences we find meaning in. In the words of the researchers, “variety may be the ‘spice of life,’ but familiarity may be the spice of life’s endings.” The study was done in the context of how people choose between hedonic activities, or the things you do for a shot of pure, unadulterated enjoyment. But I think this applies to something that falls outside the definition of hedonism (or at least the traditional one!): work.\n\nWhen faced with a deadline (narrow window of opportunity), I have a tendency to choose tried-and-tested methods (old, familiar, and comforting) over a suspiciously helpful tool (shiny, new, and novel).\n\nThis tendency is bad because these tools are fragments of a future that is taking shape around us—and by ignoring them, I’m setting myself up to fall behind. But there is a bright side: I’m staring down the problem and understanding why it exists, which is the beginning of solving it. I need to be more comfortable with the uncertainty that AI brings with it. These are the three ways in which I’ve opened myself up to AI:\n\nLearning a new language as an adult is similar to weaving AI into familiar workflows. While learning a new language, you’re basically learning new ways to do familiar things. You’ve been to a grocery store many times, but suddenly, you have to find new words to ask when that fruit you like will be in season again. Similarly, when it comes to AI, you’re attempting to use new tools to do things that you’ve done many times before.\n\nI’ve been learning to speak Spanish for the past year, and the piece of advice that has helped me the most is: little by little (or, to quote my Spanish teacher, poco a poco). After a few months of language classes, it makes sense to be able to fluently order a dish in a restaurant. But it also makes sense to fumble while expressing complex thoughts or feelings. I try to remember this when I’m using AI. I’ve taken away the pressure of upending my workflow to integrate AI. While writing this piece, for example, I did not use an LLM to brainstorm an outline, generate a first draft, and get feedback on it from Dan Shipper and Kate Lee. But I did have Claude open in a tab, and I ended up asking the model to help me rephrase a few sentences I thought sounded awkward, and for feedback on a couple of paragraphs—and it was genuinely helpful! I’ve given myself permission to take it slow.\n\nCuriosity has the reputation of being something that you either have or you don’t. I don’t agree. I think it’s more fluid than that—a quality that ebbs and flows, one that you can guide and nurture.\n\nI started writing about technology because I was fascinated by what humans could achieve with a few lines of code, bits of silicon, and their imagination. Taking that to its logical conclusion, the drudgery in using AI shouldn’t bother me so much; I should be far more excited about experimenting with it. But the truth is that the realities of adult life can get in the way—and sometimes, I lose focus of what fascinated me about technology in the first place. In other words, my curiosity ebbs.\n\nTo counter this, I’ve started carving out time to nurture my curiosity. One of the items on my daily to-do list is reading something interesting on the internet, even if it has nothing to do with what I work on, especially if it has nothing to do with what I work on. And every Friday is dedicated to experimenting with an online tool I found cool that week. Sometimes that ends up being about AI: making a song about my dog Oscar, who I grew up with and now lives many miles away with my parents, or training a custom GPT to extract insights from a podcast transcript. I think curiosity has the potential to compound—and it’s worth developing a habit around it.\n\nHumans are social creatures, and for better or worse, we’re strongly motivated by the people around us and their habits. If the people around you are excited about AI, you’ll probably be nudged in a similar direction.\n\nI’m lucky enough to work with Every, where everyone is excited about finding ways to do great work with AI. So I see a lot of this unfold up close. Over the past few months, here’s what I’ve witnessed:\n\nIt’s subtle, intangible, and slow, but being exposed to all this experimentation around me primes me to run my own experiments, the ones with ChatGPT, Claude, and Spiral, that I spoke about earlier.\n\nWe live in a world where you can choose who you want to surround yourself with intellectually. The internet offers access to thinkers who can inspire and challenge us—lean into it.\n\nI’m not the most sophisticated user of AI—check out Dan’s writing for that perspective—but in learning how to open myself up to AI, I’ve integrated it into my life in surprising, useful ways. Writing this piece reminded me that so much of our skepticism around using new technologies is not practical, but deeply psychological. In this series, I’ll chip away at the latter and document my insights, in the hope that it will gently nudge you toward opening up to AI as well.\n\n\n\n\n\n\n\n",
      "word_count": 1833,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3194/Cover.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3551/thumbnail_Screenshot_2025-04-14_at_1(2).11.33_PM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3570/thumbnail_learning(2).png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "learning-curve"
    },
    {
      "url": "https://every.to/learning-curve/the-future-of-work-isn-t-about-doing-less-it-s-about-doing-better",
      "title": "The Future of Work Is About Doing Better—Not Less",
      "author": "Rhea Purohit",
      "author_url": "/@rhea_5618",
      "publication_date": "December 19, 2024",
      "content": "The Future of Work Is About Doing Better—Not Less\n\nAI won’t eliminate human effort. It’ll redirect it.\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nAlong with the future of artificial intelligence, I write about mid-century American bank robbers.\n\nI write scripts for a history podcast, and one would think that it’s the perfect task to outsource to LLMs. I’ve written many of these before, know exactly what’s expected, and am fairly confident I can articulate them in a prompt. I also have existing research so I can give the LLM reliable knowledge to draw from.\n\nBut when my partner asked me if I’m going to use AI to write them, my instinctive answer was: “No, I want to do a good job.”\n\nAfter some introspection, I realized that my reaction had nothing to do with AI’s capabilities. I was holding on to a quiet assumption: If AI makes writing easier, something important must be getting lost along the way. Reduced effort must mean reduced quality. Because of this irrational thought, I don’t use AI as much as I can—even though it would free me to focus on the aspects of writing I like more.\n\nThis relationship between effort and perceived value isn’t novel. It’s a human tendency that surfaces in surprising contexts: The American cake mix industry, of all things, grappled with a similar situation decades ago. When cake mix sales fell because their powdered product alienated consumers from the baking process, the industry found an elegant solution: Don’t reduce effort—redirect it.\n\nAs I dug into the psychology behind our relationship with effort, I saw a parallel in our attitudes to using AI for work. I believe the horizon of effort—the energy and attention we invest in our work—isn’t reducing, it’s shifting. This essay explores how I think we can thoughtfully redefine where we entrust our effort.\n\nYou’re not ready for 2025 if you haven’t figured out your AI strategy. Let us help you. We’re offering 33% off Every. This includes analyses from some of the best tech writers on the internet, courses like How to Write With AI, and a suite of AI tools—Spiral to automate repeat writing tasks, Lex to help you write better, and Sparkle to clean up your desktop. Join us and get a head start on 2025.\n\n\n\n\n\nGeneral Mills, the owner of the popular Betty Crocker brand, was one of the first companies to promise Americans a reliable, no-fuss way to bake a cake. Add water to the instant cake mix, give it a stir, pop it in the oven…and 30 minutes later you’d have a cake. A freshly baked one, at that. You’d have all the rewards of a homemade cake—admiring comments from guests, and a warm, sweet aroma in your kitchen—but none of the mess.\n\nAfter literally selling like hot cakes for half a decade, in the mid-1950s, America’s cake mix industry saw a slump in demand. General Mills was at a loss. The company hired consumer psychologist Ernest Dichter to find out why the mix had stopped selling. Dichter interviewed the target customer—American housewives—to conclude that they felt bad about using instant cake mix. He wrote, “This is typical of what the average housewife said: ‘Yes, I’m using a cake mix; it saves me a lot of trouble but I really shouldn’t.’”\n\nDichter’s advice was to give these women a bigger role in the cake-making process. For them to enjoy the fruits of a homemade cake, they needed to do more than just stir and add water.\n\nGeneral Mills took his words to heart—its cake mixes now demanded water, a good stir, and a fresh egg. The story goes that cracking an egg into the powdered mix changed everything. The boxes of deconstructed baked goodness started flying off the shelves, and all was well in cake mix land again.\n\nMany on the internet have challenged the specifics of this story. They argue that adding a fresh egg wasn’t just a marketing tactic, it actually made the cakes taste better (dried egg powder— which is what General Mills used previously—apparently tastes as bad as it sounds). The cake mix aficionados mostly agree that sales picked up because of another marketing tactic: redefining what making a homemade cake meant. General Mills downplayed the actual baking of the cake, putting more emphasis on how the cake looked. Cake decoration became the part of the process where bakers—armed with frosting sugar and sprinkles—could express themselves. Take this 1974 cake recipe. It has 18 steps—by step five, the cake mix is baked and ready, and the other 13 steps are about making it look pretty, using skewers, straws, and even a paint brush.\n\nWhether fresh eggs or frosting sugar saved the cake mix industry is up for debate, but what this story tells us about human nature is the same: Our relationship with effort is more complicated than we think. We assume that given a choice to do the same thing in two ways, we would choose the one which requires less effort. But that isn’t always true. Sometimes, we want to break the egg and decorate the cake ourselves, a phenomenon pop psychology calls the “Betty Crocker Effect.”\n\nThe assumption that humans make choices that need the least amount of effort has extended into the way we do business. Think of the option of paying a few dollars more to have a package delivered to your doorstep, saving you the walk to a nearby pick-up point. As a general principle, a product or service that requires consumers to expend less effort is valued more highly than one that demands more effort. This is baked into the way most AI consumer apps are marketed: with the promise that LLMs will help you achieve more while doing less.\n\nThe Betty Crocker Effect pokes a gaping hole in this theory. Consumers may not want products or services (like cake mix) to abstract away all the effort from the desired end result (a homemade cake). The Betty Crocker Effect is explained by psychological concepts like:\n\nAs someone looking for ways to develop a better relationship with AI, examining my relationship with effort prompted me to ask myself a couple of questions:\n\nWhen I perceive something to be good because I’ve put effort into it, this perception isn’t always based in objective reality. It’s subjective, fed by deep-rooted psychological tendencies. On the other hand, when it comes to the work I do professionally, I try my best to hold my writing to an objective standard of quality.\n\nI optimize for thought-provoking, clear, fun writing. As I integrate AI into my writing workflow, I want to develop the ability to evaluate my work based on merit, unencumbered by how much effort I put into it. If my writing meets the objective standards I’ve set for myself, I want to be mindful of not dismissing it just because AI made the process more efficient.\n\nLLMs have made the act of filling a page—or even hundreds of pages—with words accessible to anyone with a computer and a ChatGPT subscription. I’m a writer and I take pride in the work I do, so when just about anyone could, in theory, write, I admit to having moments where I felt like I was robbed of something special.\n\nI’m beginning to reframe this narrative for myself. If the cake mix sleuths are right about Betty Crocker sales going up because of an emphasis on cake decorating, I need to find my equivalent of cake decorating. When a skill becomes generally accessible—like baking cakes from scratch in the 1950s, or writing today—it pushes us to find new ways to make it distinctly our own—like cake decorating, or writing with personality.\n\nWhen technology makes it easier to do knowledge work, it doesn’t mean our contribution—the effort we put into our work—disappears. The direction of our effort simply shifts. It moves toward the aspects of our work that are more creative, that require strategic thinking, and of course, that we derive meaning from.\n\nWhat that means for me, as I spend the next week writing scripts for a history podcast, is choosing a bank heist that I think will be interesting to a wide audience (strategic thinking), getting into the mind of the bank robber and writing the cold open of the the podcast in first person (creativity), and finding just the right metaphors (something I enjoy doing).\n\nAI isn’t going to eliminate human effort. It’ll elevate our potential—by allowing us to focus on tasks that we find most rewarding and where our contribution is uniquely valued. The horizon of effort isn’t just shifting—it’s rising.\n\n\n\n\n\nWe also build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Write something great with Lex.\n\nGet paid for sharing Every with your friends. Join our referral program.\n\n\n\n",
      "word_count": 1478,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3382/Screenshot_2024-12-19_at_10.09.38_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3570/thumbnail_learning(2).png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "learning-curve"
    },
    {
      "url": "https://every.to/learning-curve/get-a-reality-check-on-ai",
      "title": "AI Isn’t Your God—But It Might Be Your Intern",
      "author": "Rhea Purohit",
      "author_url": "/@rhea_5618",
      "publication_date": "December 3, 2024",
      "content": "AI Isn’t Your God—But It Might Be Your Intern\n\nMake the most of AI by lowering your expectations\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nWe've been told that AI will either save or destroy humanity…yet here we are watching LLMs hallucinate, image generators struggle to draw realistic human hands, and AI coding agents get stuck in loops without supervision.\n\nThis gap—the one between the promise of AI and the present reality—isn’t about AI progress slowing down. It’s a product of how we’re fundamentally misunderstanding the technology.\n\nWe’ve cast AI in the role of a God-like entity, when we should be thinking of it more like an intern: an intern who is linguistically capable, sometimes makes decisions in ways we don’t quite understand, and perhaps most importantly—if we put in the time to work with them—has the potential to surprise us.\n\nWhen Ingenuity, NASA’s autonomous helicopter that operated on Mars from 2021 to 2024, took its last flight, the team behind it recorded a video to bid the craft farewell, with one of them describing it as “a plucky little helicopter that just defied everybody's expectations.” According to the first line on its Wikipedia page, the helicopter even had a nickname, Ginny. Humans have a somewhat irrational tendency to anthropomorphize technology—even the most scientifically oriented of us.\n\nAI has lent itself to being portrayed in science fiction as an overlord, benevolent at times and terrifying at others. It has the reputation of being an intangible, all-knowing, mysterious “thing”—a reputation that broadly fits many people’s perception of God, or other similar higher power they have faith in. I think we’ve come to believe this heightened narrative around AI because:\n\nThese blind spots in our thinking breed irrationally high expectations of AI—and an inevitable feeling of being underwhelmed by it. Understanding them more deeply brings us closer to the truth, so we can set realistic expectations of AI and develop more productive ways of working with the technology.\n\nWhat used to take hours with traditional scraping can now be done in seconds with FetchFox—the AI-powered web scraper that takes the raw text of a website, and uses AI to extract data you’re looking for.\n\nDescribe your desired data in plain English and watch FetchFox quickly get to work. It can help with things like building a list of leads, assembling research data, or scoping out a market segment.\n\nFetchfox is available as both a web app and Chrome extension. No coding required. 🙅‍♂️ Ready to try it for yourself?\n\n\n\n\n\nLanguage plays a big role in making our surroundings comprehensible to us, and our capability to use language to understand and make ourselves understood is one of the most remarkable manifestations of human intelligence. As a result, we instinctively measure the intelligence of other “things”—human and non-human—based on their linguistic capabilities.\n\nOur notions around what constitutes intelligence have strong ties to language, and I’ve noticed this play out in my own life: I attend Spanish language classes with five other students to whom I exclusively speak in Spanish, both in and out of the classroom. I often catch myself making small, secret judgments about each of their intellects based on how good their Spanish is, even though I know that they’re probably infinitely more articulate in their native languages.\n\nThis concept is reflected in the Turing Test, which we've historically used to evaluate if a machine is approaching intelligence. The test involves a human interrogator asking text-based questions of two hidden subjects—one human and one computer program—with the intent of determining which one is human. A number of different people play the role of interrogator and respondent, and if enough interrogators are fooled into thinking the computer program is human, it is said to exhibit intelligence.\n\nThe Turing Test was developed in 1949, but our inclination to regard language as a sign of intelligence can be traced back as early as 1726, when a simplified version of the Turing Test appeared in Jonathan Swift’s novel Gulliver's Travels. Gulliver was brought to the court of a king who suspected he was “a piece of clockwork…contrived by some ingenious artist” and had been taught him “a set of words” to make him “sell at a better price.” The king was only satisfied that Gulliver wasn’t a machine when he got rational answers to several questions put to him.\n\nLLMs, of course, can understand and speak natural language—and that explains our tendency to attribute intelligence to them. I’m continually surprised (and delighted) by Claude and ChatGPT’s ability to understand my inarticulate, typo-filled prompts—often describing it as “uncanny”—even though I’m rationally aware of the broad strokes of how LLMs actually work.\n\nWhether LLMs truly “understand” and “speak” to us is a more philosophical question. The Chinese room argument proposed by philosopher John Searle in 1980 is a thought experiment involving a person who follows instructions to manipulate Chinese symbols without understanding their meaning but, to an outsider, could appear to “understand” Chinese. The experiment makes a distinction between machines following rules to arrange words or symbols (syntactic ability) and truly understanding their meaning (semantic ability). Either way, our subjective experience of using LLMs is that their language capabilities are similar to ours. Consequently, we perceive their general intelligence to be at least comparable to our own.\n\nWe know that the underlying logic of LLMs is next-token prediction, a process where the model predicts the next word by choosing the one that’s most likely to follow based on patterns learned from their training data. But next-token prediction doesn’t fully explain questions like how the model internally represents and organizes knowledge, or how these representations influence its output. The precise inner workings of LLMs evade us.\n\nAnthropic has conducted research that maps examined neuron activations—the internal state of an LLM before it generates a response—and mapped patterns of them, called features, with real-world concepts. In Claude, for instance, Anthropic was able to identify the feature that represented the concept of the Golden Gate Bridge and released a temporary experimental model where this feature was amplified, leading the AI to reference the bridge more frequently, even in unrelated contexts. This early research is promising, but still developing. The sense that we don’t quite understand AI systems feeds a sense of mysticism around the technology, leading us to overestimate its capabilities.\n\nWhen we perceive AI as an intangible overlord—something bigger than us—we expect the technology to do the heavy lifting on any task we give it. We begin each interaction with an LLM under the assumption that it’s powerful enough to ace it with little to no effort on our end—it is, after all, more capable than us, right? This way of thinking is only compounded by the fact that most modern consumer technologies are predictable and easy to use.\n\nWe’ve grown used to technology that nearly always gets it right. When AI doesn’t live up to these expectations, our disappointment sours into the risk of abandoning the technology altogether.\n\nInstead, turn that on its head: Think of AI as an intern. Go in with the expectation that you will have to work with the technology for it to be valuable to you. Internalize that its first attempt may not be the best one, and be intentional about how much direction you give it—more for a specific deliverable, less for an open-ended brainstorm. Get into the habit of making notes about what you liked in the AI response and what you didn’t—articulating your feedback to the LLM goes a long way.\n\nJust like any good intern, AI’s greatest value lies in our willingness to engage with the technology—in the space between what it offers and what we can accomplish working together with it.\n\n\n\n\n\nRhea Purohit is a contributing writer for Every focused on research-driven storytelling in tech. You can follow her on X at @RheaPurohit1 and on LinkedIn, and Every on X at @every and on LinkedIn.\n\nWe also build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Write something great with Lex.\n\n\n\n",
      "word_count": 1347,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3331/femm.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3570/thumbnail_learning(2).png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "learning-curve"
    },
    {
      "url": "https://every.to/learning-curve/you-re-probably-using-ai-wrong",
      "title": "You’re Probably Using AI Wrong",
      "author": "Rhea Purohit",
      "author_url": "/@rhea_5618",
      "publication_date": "September 30, 2024",
      "content": "You’re Probably Using AI Wrong\n\nThe case for maximizing meaning, not efficiency\n\nThis essay is brought to you by Ana, your personal news AI assistant. Ana reimagines how you interact with the news—simplifying stories, cutting out the endless scroll, and answering your questions. Ready for a refreshing news experience? Get involved today and download Ana through TestFlight.\n\n\n\n\n\nMany of us approach AI with the expectation that it will make us more efficient. But what if that's not the best way to harness its potential? Rhea Purohit initially struggled to integrate AI into her workflow. In the latest installment of Learning Curve—her column about going from zero to one with AI—she shares how she learned to use AI not for productivity, but to amplify meaning in her work and life. Rhea’s journey offers a fresh perspective on our relationship with AI, complete with practical steps to identify what brings us meaning and how to use AI to enhance those areas.—Kate Lee\n\n\n\n\n\nI’m a writer. LLMs can generate coherent passages of text faster than me. Getting AI to write for me is arguably the most efficient way I could use it. But each time I prompted an LLM to do this, the writing was flat, bland, and impersonal, so much so that I didn’t think it was worth using, not even as a first draft.\n\nI kicked, screamed, tore a few strands of hair out. And then I realized that the problem wasn’t AI—it was me.\n\nMore specifically, my narrative around how AI fit into my work and life.\n\nMost consumer AI apps share a common promise: They help you do things faster, or with less effort. The resulting narrative frames AI’s primary role as boosting efficiency. Some people might find meaning in efficiency itself, but many others don’t, which can inadvertently discourage them from experimenting with AI.\n\nIf you, like me, are part of that second group, I have a solution for you: Reframe your narrative around AI. Stop using AI to be more efficient. Instead, use it to increase the meaning you derive from work and life.\n\nAs humans, we are drawn to activities that give us meaning. In some domains of life—like, say, mountaineering—this may seem obvious. As an example, take the Eiger, a 13,000-foot high peak in the Swiss Alps.\n\nThe north face of the Eiger—a vertical wall of ice and limestone—has earned the moniker Mordwand, German for “murder wall,” because of the number of people who have died trying to climb it.\n\nA third of the way up the jagged mountain, at around 9,000 feet, is a door.\n\nOn either side of this door is a different reality. Inside the Eiger, trains rumble through tunnels, plying passengers to tourist attractions. Outside, the door opens onto a narrow ledge where numb-fingered climbers pause for a moment of respite. (The two realities collide during emergencies, when stranded climbers need to be rescued.)\n\nTwo centuries ago, the only way to get to the top of the cloud-covered mountain would have been to scale it. Trains—an advance in locomotive technology—now provide an efficient alternative. Even so, you wouldn’t bother trying to convince a mountaineer to catch a train to the summit. Their decision to climb the Eiger has nothing to do with efficiency; it stems from the meaning they derive from the experience.\n\nHumans are drawn to activities that bring them meaning. This is common sense when it comes to mountaineering, but my hunch is that we lose sight of it when we try to use AI.\n\nImagine a news experience where you're in control—where you're not overwhelmed by headlines and can easily digest the news. That’s Ana. With fewer stories, FAQs for each piece, and the ability to ask questions, Ana offers a more interactive, insightful way to stay informed. Say goodbye to endless scrolling and get straight to the point with Ana. Try it for a week through TestFlight and see the difference.\n\n\n\n\n\nI like the process of choosing the words I commit to posterity on the internet. I don’t just like it, I cherish it. That’s why, when I outsourced this task to AI in an attempt to be more productive, I was left unimpressed, and gradually, I stopped trying to use LLMs altogether.\n\nI wanted to have a better relationship with this new technology, and the first step to developing that was rewriting my narrative around AI. I stopped thinking of LLMs as tools that would write for me. Instead, I started using them to help me with a part of writing I don’t enjoy: being stuck.\n\nIn drafts, I like to articulate my arguments with examples. However, I sometimes struggle to come up with good ones. Pre-AI, I would turn to my partner, explain the problem in a garbled frenzy, and expect him to brainstorm with me. What followed was an erratic, volatile process. At times, the approach worked like magic, but other times, when he was busy or unable to understand the required context, it would fail miserably.\n\nNow, I turn to Claude instead. LLMs are never busy, and they make do with the inarticulate context I include in my prompt—so when I struggle with finding an example, I paste the unfinished draft into Claude and leave a blank like this: “____” where I want the example to feature. Then, I prompt the model: “Fill in the blank in 10 different ways.” The output usually gives me fodder for new ideas. (And if it doesn’t, I just prompt it again!)\n\nI don’t use the words the model generates verbatim in my draft, just as I wouldn’t take something my partner says during one of our brainstorming conversations and quote it word-for-word. I treat the LLM as an ally in ideation, not a writer. It frees me to do the things that give me meaning (choose the right words) and work through what I don’t like (being stuck).\n\nBefore you can use AI to maximize the meaning in your work and life, you’ll need to be able to articulate what you draw meaning from.\n\nMeaning can be ascribed to anything that makes your life feel significant. It is, of course, deeply personal. Take the different “meanings” that people might derive from the Eiger:\n\nWhere do you find meaning in your work and life? Don’t feel bad if you don’t know just yet—meaning can be elusive, and this is how I approach finding it.\n\nWhat do you stand for? This question is a large one, which can make it intimidating to answer right off the bat. A simpler version would be: What experiences do you regularly prioritize? Examine your lifestyle as an adult, because it is often a tangible manifestation of your internal belief system. If you’re always learning new skills, you value personal growth; if a daily workout feels essential to you, you stand for health; if you prioritize dinners at home, you appreciate a strong family unit. Think about where you spend your resources—time, energy, and money—and you’ll have your answer.\n\nConsider the moments during your day that you feel most engaged, curious, and motivated. What were you doing at the time? How long did you do it for? What came before and after? Answering these questions can bring further clarity to what brings you meaning.\n\nThe more experiences you have, the better you will understand yourself. The best part is that there’s no downside to this process—a negative experience only indicates your dislike, which is useful information as you get deeper in your search.\n\n\n\n\n\n“I like to read” has been my go-to answer when I’m asked about my hobbies for over a decade. I reach for my Kindle on lazy afternoons, in waiting rooms, and when I can’t fall asleep. Books are a big part of my life, and in my search for meaning, I started paying more attention to the ones I enjoyed. The most compelling nonfiction book I’ve read is a compilation of interviews about 9/11. The level of detail in the stories drew me in, creating the illusion that I was experiencing that day with the people involved. This is a pattern across my reading habits: I’m more engaged by books with a narrow focus, that go deep on a single event, as opposed to those that discuss trends across long periods of time. Taking notice of this, I’ve learned that the finer details of a story bring me meaning.\n\nI asked Claude what this tells me about my workflow and the moments I find meaningful within it. As you go through these screenshots, you might notice that my responses are short and casual, like I was having a conversation with a friend. I find that I do exercises like this more often if I remove the pressure to craft elaborate prompts for the LLM.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHaving a conversation with an LLM is a great way to help you hone in on what brings you meaning. You can guide the AI by giving it guardrails, telling it to ask you one question at a time or to answer in one paragraph.\n\nI always have Claude open in a tab as I write, and I frequently switch between my Google document and the LLM. Reframing my narrative around AI opened up a world where technology became my partner in writing—not something I struggled to integrate into my workflow. I bet it could do the same for you. If you try this experiment with a language model, let me know how you found the experience in the comments.\n\n\n\n\n\n\n\n",
      "word_count": 1584,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3271/Cover_Imagewww_Frame.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3570/thumbnail_learning(2).png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3590/thumbnail_AI--human.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "learning-curve"
    },
    {
      "url": "https://every.to/napkin-math/the-ai-hardware-dilemma",
      "title": "The AI Hardware Dilemma",
      "author": "Evan Armstrong",
      "author_url": "/@ItsUrBoyEvan",
      "publication_date": "May 2, 2024",
      "content": "The AI Hardware Dilemma\n\nWhy new devices are flopping—and how they might succeed\n\nDon't miss out on special pricing for The Hidden Discipline for Every subscribers.\n\nThis eight-week mindfulness course is designed specifically for busy, high-achieving individuals looking to unlock the \"hidden discipline\" that can transform their lives. Through live sessions, daily practice, and expert guidance, you'll gain the tools to:\n\nEvery subscribers can enroll for just $799—a 20 percent savings—by using code “EVERY” at checkout.\n\nTake advantage of special pricing and unlock your full potential with The Hidden Discipline today.\n\nWant to sponsor Every? Click here.\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nOver the past few weeks, new AI-powered hardware has been released to less-than-kind receptions—the Humane Pin was lampooned and the Rabbit R1 was skewered. While some people enjoyed the devices, it is safe to say these were not the launches the companies had hoped for. At the same time, other startups have raised millions in venture capital to build new consumer hardware devices. Investors I know are actively looking to deploy money into the category, and Sam Altman and Jony Ive are in talks to raise up to a billion dollars for a consumer hardware device.\n\nThis disparity raises so many questions: Why are these new devices being received so poorly? What do founders and investors believe they’ll get by betting their careers on this difficult and clearly uphill battle? Will their bets actually work?\n\nTo figure out the answers, I’ve been in the weeds with founders, talking product roadmaps, capital strategies, and levels of excitement. Here’s what I learned.\n\nThe reasoning behind the rapid new launches and investor bets is simple. It’s AI.\n\nMany see AI as a technological paradigm shift akin to jumping from personal computers to mobile computing—and there is a chance that a new Apple could be built. With Palo Alto’s favorite fruit-centric company currently enjoying a $2.68 trillion market capitalization, people are feeling like Louis Armstrong did when he touched a trumpet for the first time (quite jazzed).\n\nI’ve previously argued the components of a hardware device can be broken down into three groups:\n\nNew consumer devices are emerging because AI allows you to use the sensors, silicon, and interfaces developed for smartphones in novel ways. AI can take the input of large amounts of ambient data, such as the audio from your conversations and your behavior as you use your computer. Then, AI can output unique insights based on that corpus of data—much more personalized, sensitive, and accurate than what regular software can do today. It can also leverage existing data for new actions, such as following voice commands more closely. Basically, it’ll listen to what you say and bring out smart stuff that you missed.\n\nWhile my description may be banal, the possibilities are exciting. Smartphones are dominant, but aren’t perfect. Consumer addiction is—at least in my estimation—largely due to the monetization of smartphone app stores and the form factor of the device. If AI can evolve our relationships with devices, it’s a meaningful change. An AI ambiently crunching data and performing tasks without the distraction of a screen is net good for humanity. And, as a happy capitalistic coincidence, it would probably make the inventor of said device the owner of several large yachts.\n\nSo if the promise is so wonderful, why is the category so challenging?\n\nThe answer is, once again, simple: The iPhone is too damn good.\n\nIf I asked you to visualize what the iPhone disrupted, you’d probably think of an image like this—a brick cell phone, a digital camera, a GPS.\n\n\n\n\n\nApple’s disruption happened because it brought the sensors in all these devices into one form factor. Since the iPhone had a powerful chip and a multi-touch screen interface, it became a catch-all device that does pretty much everything pretty well. Sure, it isn’t perfect—the Kindle exists—but the smartphone is so incredible because the interface is flexible enough that it can do a good enough job at essentially everything a consumer needs.\n\n\n\n\n\nApple has spent 18 years and hundreds of billions of dollars stuffing ever-better components into ever-more-powerful phones. Its market dominance has yielded a supply chain and manufacturing partners that a startup can’t hope to match.\n\nAn AI hardware company is in the unenviable position of having inferior sensors than Apple, generic silicon chips, and a grand total of zero developers in its ecosystem. It is very, very hard to compete with an iPhone when every piece of hardware you have access to is worse. So these companies have to try to innovate on the interface. My current favorite AI hardware device, the Meta Ray-Bans, eschew multi-touch glass in favor of voice activation. The R1 has a scroll wheel, and Humane uses a laser projector.\n\nWhen you’re playing with these odds, your best bet is to differentiate on the software—not the hardware. Which means that, basically, most consumer AI hardware should just be an app. One founder told me as much: “My company should probably just be an app, but hardware sounded more fun.” While this statement may be true, customers do not particularly care about how good of a time a CEO is having.\n\nAnd if AI is what has gotten the market so excited, it should be the competitive edge, too. Both Rabbit and Humane’s products have been reviewed so critically because while the hardware is beautiful, they are less powerful and generalizable than the smartphone. And in both devices, the redeeming factor of AI doesn’t actually work—large language models are not good enough yet to be virtual assistants. The hardware was rushed to market before the AI was ready. As popular reviewer Marques Brownlee, aka MKBHD, said:\n\n“This is the pinnacle of a trend that's been annoying for years: Delivering barely finished products to win a ‘race’ and then continuing to build them after charging full price. Games, phones, cars, now AI in a box.”\n\nBut if we wait for the AI to be “ready,” we’ll run into more problems. It is incredibly expensive and challenging to differentiate on the basis of AI models. Like I just wrote, open-source can now provide GPT-4-levels of performance, so startups have to train a model to do something no other open-source model can—adding scientific research to the many hurdles that they’re trying to conquer.\n\nTo be clear, I very much want these companies to succeed. As a red-blooded capitalist, I love competition. To compete with Apple, AI hardware companies have three paths:\n\nVenture-backed startups have an over 90 percent failure rate. These companies' struggles and long odds are a feature, not a bug. We should be cheering for every single founder trying something new. There is a viable path! But it requires something wholly new and different. Startups doing the same-old end up with the same-old result—failure.\n\n\n\n\n\n\n\n",
      "word_count": 1141,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3088/image2.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3272/thumbnail_Screenshot_2024-10-01_at_10.44.22_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3186/thumbnail_addiction_cover_.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "napkin-math"
    },
    {
      "url": "https://every.to/napkin-math/in-defense-of-the-unoptimized-life",
      "title": "In Defense of the Unoptimized Life",
      "author": "Evan Armstrong",
      "author_url": "/@ItsUrBoyEvan",
      "publication_date": "January 12, 2023",
      "content": "In Defense of the Unoptimized Life\n\nGive yourself the space to be inspired\n\nAt the start of the new year, I feel guilt-tripped by Twitter threads. Whenever I scroll some guy is telling me to optimize life so I can “be productive.” Thought leaders argue in the replies that overheating in saunas—wait, scratch that, it’s now freezing to death in ice baths—will unlock eternal life. Life coaches say that I must talk through every emotion in therapy, or actually, the better thing to do is to not talk at all, on a silent meditation retreat. Diets are a mess, too. Meat only! No, just snort kale juice! There is a relentless pursuit of optimization.\n\nSelf-improvement is great and productivity is wonderful, but something about this vein of thought feels off. When I try to follow this advice, I may temporarily get more stuff done, but it comes at the expense of my soul. I feel like an obsessive-compulsive lumberjack, hyper-focused on marginal improvements in my sawing technique—until one day, as I finish my labors, I realize I accidentally clear-cut the forest for the trees. The little things we do to make ourselves better may end up draining us dry.\n\nInstead, I would argue for the unoptimized life.\n\nMy argument for an unoptimized life is a little subtle, so give it room to breathe.\n\nWhen we focus too hard on being a little better every day, we destroy the ability to be inspired.\n\nWhen I first started writing online, I felt a lot of pressure to do things the “right” way: tweet the threads, create a newsletter “product,” etc. I studied people more successful than me and tried to emulate their style. The business results were fine, but I got burned out to the point where I had to take a few weeks off from writing anything at all.\n\nNow, I run this newsletter poorly. There is no rhyme or reason behind my topic selection; my tweets are riddled with spelling errors; the courses I teach are challenging to find. I don’t do podcast interviews, and just the thought of attending an event to “network” makes me break out in hives. If I schedule more than five or six meetings a week, I start canceling them, regardless of their importance. (Sorry if you’re one of the people I’ve canceled on and are just finding out the real reason right now). Despite that (or for the sake of my argument, because of it), my work was read over 1 million times last year.\n\nI’ve achieved this success because I’ve partnered with an exceptional team of writers at Every. Our collective effort has resulted in more than 66,000 subscribers and over $50,000 in subscription MRR. Yet my perspective is that we also don’t run a very optimized publication, either. We might be more successful if we stuck to a specific beat or made editorial compromises around sponsorships or subject matter, for one thing.\n\nBut my success has also happened because I’ve given myself space. I ignore all the extra things I’m “supposed to do” that I mentioned above so I can pursue something called “afflatus.” Afflatus is a Latin word that refers to a sudden rush or inspiration, seemingly from the divine or supernatural. Moments of afflatus are euphoric and intoxicating. When they occur and I create output, I always end up happier.\n\nI’m not advocating for a lifestyle of ease and no work. I work so, so hard to make this writing happen every week. There are always late nights and sacrifices. What I’m arguing for is the cultivation of a state of being to allow for afflatus to occur.\n\nMy wife shared a Kurt Vonnegut interview with me in which the author discusses going to buy some envelopes.\n\nWe are dancing animals, not quick-sync meeting animals.\n\nIt isn’t that I think my way of doing things occupies a moral high ground over those who care about being productive. My colleague Dan is someone who I admire both personally and professionally, and he has dedicated years of his life to the pursuit of organizing himself. The key difference is the thought and reasoning that goes into the changes you’re trying to make.\n\nI wouldn’t presume to tell you how to cultivate afflatus in your life. How you construct your life is your business. It could be that you need to take an ice bath (I actually enjoy daily cold showers). At Every, we have already published articles outlining how to try to live your values.\n\nBut we get so caught up in the daily grind, in the pursuit of the next step of the ladder, that we miss the point of being. I think the default state of life is that we will get filled up with small things. Whether small productivity improvements or minor inconveniences, it doesn’t matter. Either take away our chance to focus on something more.\n\nIn David Foster Wallace’s commencement address, “This is Water,” he stated, “The really important kind of freedom involves attention and awareness and discipline [emphasis added], and being able truly to care about other people and to sacrifice for them over and over in myriad petty, unsexy ways every day. That is real freedom. That is being educated, and understanding how to think. The alternative is unconsciousness, the default setting, the rat race, the constant gnawing sense of having had, and lost, some infinite thing.”\n\nYou can be productive with 100 meetings a week or zero. Who am I to say? What matters is the ethos and thought with which you approach all of life’s activities. We love the idea of productivity hacks because it is so seductive to think that you are just one adjustment away from achieving outrageous success. But that’s not the case. The only way is hard work and giving yourself the space to do it.\n\nThere is a term in Greek closely related to Latin’s afflatus: enthousiasmos, which refers to being possessed by a god or spirit in a state of religious or creative ecstasy. To work in the technology industry is to dally in godhood. Our daily task is to play with the stuff of creation. We fly as Hermes with our rocket ships, know as Athena with our large language models, hold power like Zeus with our nuclear reactors. With work that is so important and so sacred, it feels silly to waste time on marginal gains. I would argue for the unoptimized life because it is the one that gives us the space to do and be more.\n\n\n\n",
      "word_count": 1092,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/2431/thinkrodiner.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "napkin-math"
    },
    {
      "url": "https://every.to/napkin-math/the-case-against-sam-altman",
      "title": "The Case Against Sam Altman",
      "author": "Evan Armstrong",
      "author_url": "/@ItsUrBoyEvan",
      "publication_date": "November 21, 2023",
      "content": "The Case Against Sam Altman\n\nThe board is bad at their job, but they may not be crazy\n\nWhen Adam Neumann lost his job running WeWork, the startup then valued at nearly $50 billion, there were two sins that always struck me as particularly grievous. The first was that he was having WeWork lease out buildings that he owned (e.g., he was profiting from the supply) and the second was that he sold the trademark for “We” to WeWork for $5.9 million (a bit of a stretch, but it could be characterized as him profiting off the platform).\n\nWhen Sam Altman lost his job running OpenAI, the startup valued at over $50 billion, there were many sins that struck me as particularly grievous. The first was that he was looking to raise billions to start his own chip company that could sell to OpenAI (e.g., profiting from the supply), and the second was that he was separately raising billions to build a hardware device that OpenAI models would be housed on (e.g., profiting off the platform). To further muddy the waters, OpenAI’s main partner, Microsoft, buys power from a company in which Altman is a major shareholder. OpenAI’s in-house VC fund has led a Series A round in a company in which Altman is also a major shareholder. Altman owns shares in some of the buzziest tech companies in the world, including Stripe, Instacart, and Humane. Many, if not all, of those companies are using the tech that OpenAI is selling.\n\nThis is enough conflicts of interest to make a corporate lawyer's brain smush in on itself like a dying sun. It is a ludicrous amount of mis-aligned incentives.\n\nNow, the Neumann-Altman comparison isn’t exactly a fair one. WeWork is worth a grand total of zilch, while OpenAI was about to close a $86 billion tender offer before this weekend’s debacle. A bankrupt real estate company can’t really be compared to a company that regularly releases products that are straight out of science fiction. But the fact that my conflict-of-interest parallel is so easy to make should cause everyone to pause in their full-throated defense of Altman.\n\nAny board, non-profit or not, could consider all this equity mish-mash a fireable offense. At the risk of being heavy-handed with this analogy, before this weekend’s events, Altman was looking to both make the uranium and build the power plant for his nuclear reactor company. It is a level of profiteering that I find disquieting. You can make an argument that Altman is uniquely qualified to lead all these companies, but he should be doing so in a way where he isn’t the one primarily benefiting. A clearer structure would be setting up an AI holding company for the chips, models, and hardware so that all the investors in OpenAI could benefit. As it is, I feel uncomfortable that the company’s employees and investors have helped jump-start an industry that Altman is attempting to corner.\n\nActually, maybe the nuclear analogy is right. When Altman helped found OpenAI, the team was explicitly worried about what would happen if a non-moralistic organization were to discover artificial general intelligence. After all, an AGI would be a technology as powerful and impactful as nuclear weapons are today.\n\nTo combat this, they explicitly made unusual corporate governance choices. From the founding blog post: “OpenAI is a non-profit artificial intelligence research company. Our goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. Since our research is free from financial obligations, we can better focus on a positive human impact.”\n\nSo they set up a board with the power to fire the CEO if he went off-mission. In June of this year, Altman himself called that a positive quality of the organization! That Altman got canned is a feature, not a bug, of the organization he designed. A fundamental part of the job of a CEO is to manage their own board. Altman himself was the one who pushed the professional investors off his board earlier this year. If he didn’t want to get fired by them, he should’ve built it more carefully and managed it more closely.\n\nIf the board felt that the CEO had multiple conflicts of interest, was straying from the original vision of the organization, and was doing so at an organization that if managed incorrectly could kill the entire human race, then hell yeah, that dude should’ve been canned yesterday.\n\nIt's important to mention that the board has not said anything publicly. The only things we do know about what led to their decision seem flimsy at best. My reaction, and that of the public, would be different if the board had actually, you know, given a substantive reason. There may be legal reasons in the company’s bylaws for them not doing so, but they have fumbled the PR battle so incredibly badly that the time for worrying about that is long past. But I still sort of see this as Altman’s fault! Why did he allow people who would run a process like this on his board in the first place? He should’ve staffed it with people competent enough to fire him correctly.\n\nTo his credit, Altman has done an incredible job of building a team that adores him, and a public persona that the media and general public likewise idolizes. He has built one of the fastest-growing, most successful consumer technology companies ever, seemingly from sheer force of will. As of this writing, more than 700 of the 770 employees at OpenAI have signed a letter saying they will follow Altman to Microsoft should he choose to join Satya Nadella in Redmond. My Twitter feed is chock-full of praise and adoration from people Altman has helped over the years. Tech is united behind him.\n\nI do not want to take away from the fact OpenAI has changed the world, and it has done so under his leadership. To my eye, Altman has done an exemplary job of leading his team. But—and this is a crucial but—he has failed at the explicit task that he laid out for himself when he helped create the company.\n\nIronically, he could’ve learned from Elon Musk on how to do this. Musk has long staffed his boards with cronies (and/or his brother), allowing him to get away with murder. At Twitter, one of  Musk’s first moves was to fire the entire board and make himself its sole member. And look, this is, like, a horrible thing for shareholders. I personally believe that shareholders deserve representation and protection at the board level, but if you’re a CEO, you probably care more about job security.\n\nI am in the camp that Altman is likely innocent, and it was a dumb board gone rogue. But there are legitimate questions to be had about Altman’s behavior. Attempting to achieve AGI is a momentous enough task that it likely requires a unique governance structure. But it also requires a CEO who is focused, honest, and committed. Altman’s investing has not left that impression with me, and perhaps the board felt the same. We will see how it all shakes out over the next few weeks, but based on public information, I think there is a case to be made for dismissal.\n\n",
      "word_count": 1226,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/2852/sam.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3272/thumbnail_Screenshot_2024-10-01_at_10.44.22_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3186/thumbnail_addiction_cover_.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "napkin-math"
    },
    {
      "url": "https://every.to/napkin-math/what-are-ai-agents-and-who-profits-from-them",
      "title": "What Are AI Agents—And Who Profits From Them?",
      "author": "Evan Armstrong",
      "author_url": "/@ItsUrBoyEvan",
      "publication_date": "March 28, 2024",
      "content": "What Are AI Agents—And Who Profits From Them?\n\nThe newest wave of AI research is changing everything\n\nMost races have a prize pool. The New York City  marathon winner gets $100,000. 2023’s F1 winner took home a $140 million pot.\n\nThe winner of the race I’m going to describe will earn billions. Maybe tens of billions. They’ll bend the arc of the universe. They’ll materially increase GDP.\n\nThis is the race toward the AI agent. Agents are the next step in the AI race and the focus of every major tech company, research lab, and leading AI startup.\n\nI’ve spent months talking with founders, investors, and scientists, trying to understand what this technology is and who the players are. Today, I’m going to share my findings. I’ll cover:\n\nLet’s get into it.\n\nAn AI agent is a type of model architecture that enables a new kind of workflow.\n\nThe AI we started with formulates an answer and returns it. Ask it something simple, like “Does an umbrella block the rain?” and GPT-4 returns the answer, “Of course it does, you dumbass.” The large language model is able to answer the question without relying on external data by using internal data and executes on the prompt without a plan. It's a straightforward line connecting input and output. And every time you want a new output, you have to provide a prompt.\n\nAgentic workflows are loops—they can run many times in a row without needing a human involved for each step in the task. A language model will make a plan based on your prompt, utilize tools like a web browser to execute on that plan, ask itself if that answer is right, and close the loop by getting back to you with that answer. If you ask, “What is the weather in Boston for the next seven days, and will I need to pack an umbrella?” the agentic workflow would form a plan, use a web browsing tool to check the weather, and use its existing corpus of knowledge to know that if it is raining, you would need an umbrella. Then, it would check if its answers are right and, finally, say, “It’ll be raining (like it always does in Boston, you dumbass) so yes, pack an umbrella.”\n\nWhat makes agentic workflows so powerful is that because there are multiple steps to accomplish the task, you can optimize each step to be more performative. Perhaps it is faster and/or cheaper to have one model do the planning, while smaller, more specialized models do each sub-task contained within the plan—or maybe you can build specialized tools to incorporate into the workflow. You get the idea.\n\nBut agentic workflows are an architecture, not a product. It gets even more complicated when you incorporate agents into products that customers will buy.\n\nThe only thing that matters in startups is solving customers’ problems. Agentic workflows are only useful as a product if they solve problems better than existing models. The tricky thing is that no one knows how to make AI agents a consistently better product right now. The pieces are all there, but no one has figured out how to put them all together.\n\nThis moment is strongly reminiscent of the early 1980s of personal computing, when Apple, Hewlett-Packard, and IBM were duking it out. They all had similar ideas about the user interface (the use of a mouse, the need to display applications, etc.), but the details of implementation were closely guarded secrets. These companies competed on the quality of their technical components and how each of those components fit together to solve customer problems.\n\nCompanies that make AI agents are also competing on both individual component quality and how these components are combined. In broad strokes, think of these arenas of competitive intensity scattered across five components:\n\n\n\n\n\nThere are infinite varieties of combinations of these components. Unlike with previous generations of software companies, investors and founders are underwriting science risk as well as product risk. In the 2000s era of SaaS, we knew the cloud worked, and we knew how to make software on it. The only question was if you could make a product that used the cloud in a way that benefited customers. With agents—both tooling and models—we haven’t completely figured out the science of making it work, let alone the product.\n\nThat is a mouthful, so let me repeat myself as simply as possible.\n\nThis shit does not currently work, but investors are betting it can. Many assume we are just one or two scientific advancements away in models or tooling to make agents available at scale.\n\nWell, actually, agents do, kinda, work—but only about 10 percent of the time. For context, a much-celebrated startup called Cognition Labs was able to solve 14 percent of “real-world GitHub issues found in open-source projects.” Not great, but, much better than its peers.\n\n\n\n\n\nInvestors are betting that founders can make both the technology consistently work and the product that uses the tech correctly. There are some low-level agent workflows with GPT-4 or other LLMs that you can do with ChatGPT (like my weather example from earlier), but AI agents are nowhere close to taking over all existing knowledge worker labor. It’s the inverse SaaS problem: The value is obvious, the ability to deliver a product dubious. In SaaS, the opposite is true: The value is typically non-obvious, and companies compete on their ability to sell products.\n\nBear in mind that all five of these components are just to make the thing turn on! Once companies can use AI agents to solve a problem for users, they then have to compete against each other—and LLMs, and all the other software tools. Speed, cost, and reliability are the important factors. AI agents need to be significantly cheaper—and equally, if not more reliable—than human labor to fully replace existing solutions.\n\nThis raises another question: How do you evaluate the damn things? As we’ve previously argued, evals to compare AI products are fundamentally broken. We barely have the language to discuss artificial intelligence, let alone the type of rigor required to compare products.\n\nWhat we do have is capital—and we can look at where it is going to understand how the markets think value will accrue.\n\nOne of the great tragedies of AI agents is that the products are being built in secret. From 2015-2020, there was a strong culture of publishing research papers on AI, so scientific progress was shared. Now that billions are on the line, that has changed. We are stuck doing guesswork based on funding.\n\nThere are two main types of AI agent companies:\n\n1. Model-first startups: These companies are betting that the model component is the most important part of the tech stack, and there are large gains to be had in improving LLMs. They’ve raised large amounts of capital to subsidize the cost of building these models. Here are the leaders:\n\nThe fundamental question that these startups are trying to answer is what type of model is right. Is it a super-powerful model like GPT-5? Is it a user-action model like Adept? Is it a reasoning- and code-first model like Imbue and Magic? No one knows! And that's the fun part.\n\n2. Workflow applications: These companies use existing models and are betting that the other components (like glue and UI) will end up being the most important.\n\nWe can put these companies on a spectrum: On the left-hand side is “vertical task automation,” and on the right is “horizontal selling of AI agents.” A vertical work application automates a variety of tasks within one industry—think AI agents for legal, like Harvey ($80 million-plus raised). In the middle are AI agents geared toward one specific task, such as software engineering.  Cognition Labs ($20 million-plus raised) focuses on performing one large task—writing code—that cuts across many industries. On the far right are companies that sell AI agents as a service. You pay to access AI agents that can do a variety of horizontal tasks, like calendering, note-taking, or PDF summary. Lindy ($50 million raised), which offers a tool that has dozens of AI agents, is an example of this kind of company. There are many of these players, and arguably, every software company could be an AI agent company.\n\n\n\n\n\nNone of the workflow automation companies have trained their own models—they use open-source or other private providers. When I chatted with Lindy CEO Flo Crivello about his company’s decision to not train a model, he told me:\n\nThe more reliant a task is on a large and private dataset, the more likely it is that a workflow application will be dominant instead of a model. The best software companies function as a system of record, a repository for the most important data (customer IDs, product analytics, or credit card numbers), and they’ll be able to offer superior products. However, if the dataset is small—say, just a spreadsheet—it’s easy to drop that into a model-first company’s environment. Have a spreadsheet problem? Upload it to ChatGPT. If it turns out that models are a long-term differentiator, it may be easier for the first category of providers to build workflow software than vice versa.\n\nWhichever bet investors are making on components, there is one meta-risk that hangs as a dark and vengeful god over the entire industry: scaling laws.\n\nOne of the miracles of the modern age is Moore’s law: the observation that the number of transistors on a chip doubles approximately every two years, leading to an exponential increase in computing power and efficiency. Our computers have become ever more powerful for nearly 60 years.\n\nWhat people forget is that, as these chips grew more powerful, the cost of data processing became dramatically cheaper.\n\nA similar phenomenon appears to be happening in large language models. The cost-per-unit of intelligence is heading markedly down. For example, Anthropic’s Claude 3’s Haiku model is one-quarter of the cost of OpenAI’s GPT-4 Turbo while simultaneously surpassing GPT-4 on user-rated benchmarks of intelligence. At a certain point, the models will become so all-powerful and intelligent that tools, data, UI, and glue will become moot. There is an inverse relationship between the levels of supplemental code and intelligence in the model: The more code, the dumber the model can be; the less code, the smarter the model must be.\n\nAs for when (if?) we reach the point where all the other components besides models are pointless, it is anyone’s guess. If you believe the scaling hypothesis—that the bigger the models get, the closer we get to superhuman intelligence—then there is a clear path to get there.\n\nOne final word of caution: As you look at these companies’ demos, it is easy to be skeptical and dismissive. The error rates are high, and like I said earlier, they don’t really work. But AI is an industry of compounding improvement curves. Early reports of GPT-5 are that it is “materially better” and is being explicitly prepared for the use case of AI agents. Last year Anthropic told its investors it was preparing to create a model 10 times better than GPT-4. If it holds to its timeline, that model should be finished this year.\n\nIf these forecasts hold up, there will be an abundance of spooky-smart, spooky-cheap intelligence. Agents are the next thing, and they are coming sooner than you think. Get ready.\n\n\n\n\n\nEvan Armstrong is the lead writer for Every, where he writes the Napkin Math column. You can follow him on X at @itsurboyevan and on LinkedIn, and Every on X at @every and on LinkedIn.",
      "word_count": 1926,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3020/agent_head.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3230/thumbnail_Screenshot_2024-09-19_at_9.20.23_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3330/thumbnail_RAMPCOVER.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "napkin-math"
    },
    {
      "url": "https://every.to/napkin-math/the-cost-of-greatness",
      "title": "The Cost of Greatness",
      "author": "Evan Armstrong",
      "author_url": "/@ItsUrBoyEvan",
      "publication_date": "June 1, 2023",
      "content": "The Cost of Greatness\n\nWhat will be the blood sacrifice on your altar of ambition?\n\nI can’t tell you how bad I want it. Some days I wake up aflame. There is electricity crackling down my knuckles, an urgent rhythm pounded into the keys as I type. A river of creation flows out of me as I revel in the act of making. Other days, I mostly eat pretzels. I meander from task to task, completely content with being dead center of the bell curve.\n\nI can’t even tell you what “it” is. Some days I want to be the tech writer. Matt Levine will tremble. Ben Thompson’s email list will be torn asunder. I will be read and admired and praised. Other days I wake up disgusted by what yesterday’s Evan did.\n\nWhy did I write till 1 in the morning rather than spending time with my wife? I want to be great, yes, but I also want to be a great husband and son. There is a reason why lots of creatives struggle with addiction, or why many investors I know are on their third spouse. Money and power never come cheap. The only great I should want is a great life.\n\nPerhaps you have felt similar confusion. You also want to be great. (Hopefully you’re saner than me and want to be great at something other than writing.) But still, you listen to that siren song of more.\n\nAs life forces priorities to shift, so does your personal definition of what constitutes great. There is a tension; the longer you remain committed to a single cause of greatness, the more incapable you become of being good enough at everything else.\n\nThis terrible cost is most obvious in the people who have ascended to the heights of our society. The HBO series Succession, which recently ended, showed it beautifully—for those unfamiliar, it follows Logan Roy and his four kids as they jockey to inherit the multibillion-dollar media empire Logan created.\n\n(Beware, spoilers ahead.)\n\nFor me, the climax of the series is the penultimate episode—the funeral of Logan Roy. There, each of the children wrestle with their grief. The youngest son, Roman, collapses mid-eulogy with remorse. The eldest son, Connor, gets sidelined as he has been his whole life. But Kendall, the heir apparent, gives a speech that, my oh my, did something to me. Kendall was abused, degraded, and humiliated by his father. Logan beat Roman, committed Connor’s mother to an asylum, was misogynistic toward his daughter, Shiv, and was generally an evil, vile man. Despite all that, the company he built was great. In the eulogy he gives, Kendall grapples with his father’s legacy:\n\n“My father was a brute. He was. He was tough. But, also, he built and he acted. And there are many people out there who will always tell you no. And there are a thousand reasons, there always are a thousand reasons to not act. But he was never one of those. He had a vitality, a force...that could hurt...and it did. But my God, the sheer, the...the... I mean, look at it. The lives, and the livings, and the things that he made…I mean, great geysers of life he willed. Of buildings he made stand. Of ships, steel hulls. Amusements, newspapers, shows, and films, and life. Bloody, complicated life. He made life happen. He made me and my three siblings. And yes, he had a terrible force to him. And a fierce ambition that could push you to the side.\n\nBut it was only that...that human thing. The will to be, and to be seen, and to do. And now people might want to tend and prune the memory of him to denigrate that force. That magnificent, awful force of him, but my God, I hope it's in me.” (emphasis added)\n\nFrom the moment I first watched this speech, I have had the phrase “my God, I hope it’s in me” rattle through me. Despite Logan’s litany of sins, despite the abuse he heaped upon his children, Kendall hoped to inherit his father’s greatness.\n\nA similar speech will be given at the eventual funerals of our current ruling elites. At Bill Gates' service they will not mention the Jeffrey Epstein connections, only the work his charity did. Mark Zuckerberg’s service will be attended by men festooned with medals, but there will be little mention of his partial responsibility for the genocide in Myanmar. Murdoch, Musk, Jobs—all of these powerful and great people who reshape our world. Maybe these individuals' greatness outweighs their personal complications, but still, they did not ascend without significant costs.\n\nIn my own life, my father was an inverse Logan. He was steadily climbing at Fortune 150  corporations, but after missing one too many of my baseball games, he left. He spent the rest of his career taking good, secure jobs that let him be home in time for dinner. He is and was an incredible dad, but he never ascended to the greatness that was promised in his former career. To him, that trade-off was worth it. Being a great family man is what mattered.\n\nOn a recent fishing trip to the Florida Everglades, as we drifted among the gnarled groves of mangrove trees, I asked my dad what his biggest career regret was. His answer surprised me: “I wish I had started my own company.” He always felt like he had the ability to follow in the family tradition (my grandfather was a 4th-grade dropout who built his own business) but never did. He sacrificed that ambition so he could provide a good, consistent life for me and my mom. I love him for his willingness to be a great dad.\n\nMy God, I hope that desire is in me. When the time comes for me to choose, I pray I’m able to pick my family like my father did. I hope I do not walk the path of Logan.\n\nBut I am afraid I will. I am afraid because in both Kendall and my dad I find inspiration. Despite all the evidence I’ve seen in my own life, I still somehow delude myself that I can have it all.\n\nThere is even more to be afraid of. There is a fear that committing myself to the cause of greatness, to being all that I think I can be, will turn me into something I now dislike. Because greatness is so malleable, I worry that “being great” eventually destroys who I am.\n\nIn the world of content, the pursuit of greatness manifests as those folks who prostitute themselves to traffic, who helplessly careen from trend to trend, desperate in their desire for virality. In startups, the same can be said of those who shift from Web3 to AI to bootstrapping to whatever will be trendy in a month.\n\nGreatness is not measurable. It is not quantifiable. I’m not even sure it is definable. But still we desire it. Be aware, it is a devourer resting within us. What we choose to feed it determines what kind of great we will be.",
      "word_count": 1184,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/2630/ambition_altar.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3230/thumbnail_Screenshot_2024-09-19_at_9.20.23_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3330/thumbnail_RAMPCOVER.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "napkin-math"
    },
    {
      "url": "https://every.to/on-every/every-s-master-plan",
      "title": "Every’s Master Plan",
      "author": "Dan Shipper",
      "author_url": "/@danshipper",
      "publication_date": "July 19, 2024",
      "content": "Every’s Master Plan\n\nWriting our way to a big business\n\nHave you started using AI as your personal assistant?\n\nThis free guide from HubSpot unveils the power of delegating tasks to artificial intelligence, freeing up your time for what truly matters. From automating mundane chores to streamlining complex processes, this guide empowers you to work smarter, not harder.\n\nDive into the world of AI delegation and supercharge your efficiency. Download the free guide and revolutionize the way you work.\n\n\n\n\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nWe’re exploring the frontier of what a creator-run business can be and can look like. It’s something new: a business that has writing and creative work at its core, and builds software and other kinds of products as an outgrowth of that. It doesn’t look like a traditional venture-backed startup, nor does it look like a typical small media business. It’s ambitious, and fun, and off the beaten path of business.\n\nIt’s also working.\n\nWe’ve been putting out writing that I'm insanely proud of. We’ve also released two new software products: Spiral, which just passed 3,000 users this week, and Sparkle, which is in closed beta. We’re growing revenue rapidly—our monthly recurring revenue is up almost 8 percent over the last 45 days, and our overall cash flow is up significantly as well.\n\nPersonally, I feel like I’m doing the best writing of my life. I get to wake up every day, play with AI, think about the future, and craft what I find into words. I’ve been writing on the internet for more than 10 years, but I feel like I just reached an unexpectedly high level: Last week I was in Rome hosting a panel on AI and creativity at the Aspen Institute Italia, two months ago I went to Seattle to interview Microsoft CTO Kevin Scott, and next week I’m flying to Brazil to keynote the largest AI conference in Latin America. I’ve never buzzed with so many ideas before.\n\nThere are many reasons for this success that have nothing to do with me. The biggest reason, obviously, is you: our readers. Nothing we do could happen without your support and attention.\n\nAnother reason is AI. The creative output—writing, code, design—that we can generate as a small organization is stunning. It feels like we’re sprinting in the sun when previously, we’d been running under water.\n\nA third reason is the people who have chosen to work at Every. Our editor in chief Kate, our entrepreneur in residence Brandon, our lead writer Evan, our creative lead Lucas, our engineers Avishek and Andrey—and a whole host of others—are the key factors. It is the ultimate privilege to get to work with so many talented, kind, and hard-working people every day.\n\nBut to the extent that companies reflect their founders—and that creative work reflects the state of mind of the creator—some of the acceleration has to do with me: I’m different, and that’s made Every different, and my writing different as well.\n\nI want to reflect a bit on why—and how—because I think we’re defining a new path for what a business can look like in 2024 in the age of AI. And hopefully, sharing our story will help you find and follow your own path, too.\n\nThis essay is brought to you by HubSpot, your automation partner. Discover the power of AI as your personal assistant with our free guide. Learn how to delegate tasks to artificial intelligence and reclaim your time for what truly matters. From automating daily chores to optimizing complex processes, this guide is your key to a smarter, more efficient workflow.\n\n\n\n\n\nEvery has been around for four years, and it’s been through lots of ups and downs. But about a year ago things started to get difficult in a way that felt uniquely hard to me.\n\nTraffic started to decrease, primarily because Elon Musk’s takeover of X changed the algorithm and the platform stopped being as large a source of page views for our articles. In addition, almost a year after the release of ChatGPT, the immediate sugar rush of AI hype had started to wear off, so the bar became higher for us to create writing that went viral. We needed to go deeper with our writing.\n\nAs if that wasn’t enough, my Every cofounder Nathan, who was also one of our top writers, left to run Lex, the Every-incubated AI writing app. We had a big set of shoes to fill in our editorial mix.\n\nOur monthly revenue started to shrink. We had raised a little bit of money in 2020, but we mostly run the business at a break-even level. Declining revenue had the possibility to compound in a negative feedback loop: We would have less revenue to invest back into the business, so the shrinking would accelerate until, well...💀\n\nBehind the scenes, I had to figure out how I wanted to run Every as a newly solo founder. I had to decide what I wanted my role, and Every, to be—and why. In retrospect, it was a new founding moment for the company. We had to replant the flag of what we stood for and why we were even doing this in the first place.\n\nThere are a series of key decisions that led from where we were a year ago to where we are today. They’ve contributed tremendously to our success. I want to talk about them, in chronological order.\n\nIn October 2022, we launched Lex. It immediately took off and began to grow virally. I started to pay serious attention to the then-nascent AI boom. ChatGPT hadn’t been launched yet, but there was something brewing that I knew was important.\n\nThe AI boom had the flavor of a few others I’d participated in before. In high school, I started building mobile apps shortly before the iPhone came out. In college, while everyone was obsessed with building social apps, I built a B2B SaaS company just before that category started to take off as the paradigmatic path to startup success. After college, I became obsessed with note-taking apps as Notion was getting started, an obsession that lasted through the tools-for-thought gold rush that made Roam popular in 2020.\n\nThough I’d been right early in previous booms, I felt like I’d always been too cautious. I was half-in and half-out. I’m usually a on-the-one-hand-but-on-the-other-hand guy.\n\nI keep a short document of principles I try to live by, and in 2020 I’d written this:\n\n\n\n\n\nGiven the above, you might be surprised to learn that until about a year ago I didn’t primarily think of myself as a writer. I thought of myself as a founder who liked to write. About a year ago, I decided to flip that: I started to think of myself as a writer who also builds things.\n\nThis was hard for me to admit. For a long time, my identity as a founder had crowded out that as a writer. Writing felt too luxurious, maybe a little shameful, and definitely not as respectable or remunerative as founding a company.\n\nOnce I admitted that I wanted to be a writer to myself—and then to others around me—something interesting happened. The world started to bend around the decision in a way that was incredibly positive.\n\nI used ChatGPT to find role models who had tread this path before me. While I had feared that no one else had successfully combined being a writer with building a valuable business, I learned that I was wrong. Sam Harris, Bill Simmons, Kevin Espiritu, and several other creators had done exactly this—and well.\n\nI hired Kate Lee as our editor in chief from Stripe Press, and our professionalism, quality, consistency, and attention to detail immediately shot up. We signed our lead writer Evan Armstrong to a new contract, ensuring we’d have his voice and ideas in our editorial mix multiple times a week. I stopped treating writing as a luxury that I only got to do when everything else in the business was going well, and instead started to view it as the core process by which everything else in the business worked. My writing started to gain a bigger readership than it ever had before.\n\nThere’s a tremendous friction that arises when you don’t allow yourself to do what you really want to do with your life. You make a lot of halfway decisions to negotiate your competing priorities: what you want, and what you want to want.\n\nI’m running full speed ahead at Every, faster than I ever have before. And that’s only been possible by becoming honest about what I want.\n\nAfter many years of struggling, I finally figured out the right treatments for my obsessive-compulsive disorder (OCD).\n\nOCD is thought of as a sort of cute, neurotic form of being a neat freak, but it’s much different—and worse—than its caricature. The World Health Organization includes it on its list of the top 20 causes of illness-related disability worldwide.\n\nFor me, it had been debilitating: My thoughts constantly swirled around fears that I knew were irrational but I couldn’t stop thinking about. It took me many years of therapy to even know I had OCD, and a few more years to get the right treatment. (Unfortunately, this is a surprisingly common story.)\n\nAbout 12 months ago, I got into the right treatment (exposure and response prevention with an OCD specialist) and started taking the antidepressant drug Zoloft. It has completely transformed my life. I’m calmer, my mind no longer races as much, and I can more easily differentiate between fears that I need to take seriously and those that are irrelevant.\n\nNot only has the medication significantly reduced my symptoms so that OCD doesn’t run my life anymore, it’s also changed my sense of self. I’m not fundamentally different; I still have the same personality, interests, tastes, loves, and fears. But it’s allowed me to evolve in ways that I hadn’t previously been able to: I’m more confident and less conflict-averse, and it’s easier for me to take risks and make mistakes.\n\nI’m sad and angry that it took me so long to find the right treatment. But I’m also filled with hope that treatments like this exist and can work.\n\n(Obviously, Zoloft is not for everyone. Asking whether it works is kind of like asking whether paint works to make art. On average, paint makes random smears. For some people, it makes Starry Night.)\n\n\n\n\n\nThe deprioritization of link-sharing in X came with a new algorithmic priority: the promotion of posts containing videos. Daddy Elon taketh away, Daddy Elon giveth. When Evan noted this, we began having serious discussions about creating video podcasts to take advantage of the shift.\n\nThat’s how my show, AI & I (previously called How Do You Use ChatGPT?)—about how the smartest people in the world use AI in their work and lives—came to be. In its eight or so months of existence, it’s generated 740,000 video views on X, 223,000 YouTube views, and 90,000 plays on Spotify. It’s also been insanely fun: I love interviewing people, a habit I’d dropped since shelving my original Every column, Superorganizers.\n\nWhile I can’t say this for sure, I think the podcast has made my writing more resonant—it’s certainly grown my audience tremendously, which has led to more traffic for Every. It helps people put a face to the byline—the writing supports the podcast, the podcast supports the writing, and they both support everything else in a virtuous cycle. It’s also been creatively rewarding to work on it with Every’s creative lead, Lucas Crespo, who acts as the producer. It would not be nearly as popular or interesting without his constant attention and care.\n\nA few months ago I got an email from my longtime friend Brandon Gell with the subject line, “Long time no talk—considering my next move.” He’d just sold his insurance tech startup Clyde and was toying around with starting a studio to incubate software products. He wanted to know if I was interested in doing that as part of Every.\n\nI was. We’d incubated software products, like Lex, before, and because audience growth had gotten harder, I was thinking about ways to increase our revenue from the valuable subscribers we already had. Brandon joined as our first entrepreneur in residence shortly thereafter.\n\nWithin just a few months, we launched Spiral publicly, released a beta version of Sparkle, and spun up a few other initiatives that we’ll be able to announce soon. Brandon is a force of nature.\n\nThis week, when we were discussing what the last few months have been like as compared to our expectations, we realized it’s gone almost exactly like we planned—which almost never happens in startups.\n\nIt’s a fun time to be building on the internet.\n\nA few weeks ago, I shared Every’s master plan with the team. It looks like this:\n\n\n\n\n\nOur core activity, at the bottom of the pyramid, is to produce writing and other forms of content that reach millions of people. We monetize the audience with our Every subscription—a bundle of content, software, discounts on products, community events, and more for tens of thousands of people. At the top of the pyramid, we offer higher-ticket items like courses, consulting, and advising for small numbers of people in our audience who can afford to pay for our expertise.\n\nWe then take the cash we generate and funnel it into producing more great writing. Hopefully, this will allow us to build Every into a creative playground for smart people to make the best work of their lives.\n\nI am confident that this is a viable way to build a business with writing and creativity as its core—one that also becomes large and valuable.\n\nHere I need to take a step back: I’ve been writing about my conviction that we’re building at the frontier of business. We’re doing something new, but I want to make clear why and how that happened. It’s not because we’re trying to do something new. I didn’t step back and come up with a perfectly rational vision of the future because I wanted to feel special. (I’ve tried, and it doesn’t work very well.)\n\nInstead, I stopped trying to fit myself and Every into an old model of what a founder, software startup, or media company needs to look like. Those are all old ideas, from an older context. They can be useful when needed. But they’re dry and dead.\n\nI’ve just tried to be honest about who I am, what I want, and what I believe to be true about the little piece of the world we’re trying to build in. Newness comes as an automatic outgrowth of that. It doesn’t require trying—only honesty.\n\nEmerson wrote, “Every man’s condition is a solution in hieroglyphic to those inquiries he would put. He acts it as life, before he apprehends it as truth.”\n\nYou sail into uncharted waters because you’re actually looking at reality instead of seeing what you’ve been told to see. You've lifted your eyes from old maps and started reading the stars and currents around you.\n\nWhen you review your progress, you’ve ended up somewhere new—but at the time, all you were doing was solving problems as they appeared.\n\nWe’ll keep reading the currents as they come along. Thanks for joining us on this journey so far. We couldn’t have done it without you.\n\n\n\n\n\n\n\n",
      "word_count": 2573,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3158/Screenshot_2024-07-19_at_11.23.05_AM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "on-every"
    },
    {
      "url": "https://every.to/on-every/introducing-spiral",
      "title": "Introducing Spiral",
      "author": "Dan Shipper",
      "author_url": "/@danshipper",
      "publication_date": "June 18, 2024",
      "content": "Introducing Spiral\n\nA powerful prompt builder that automates 80 percent of repetitive writing, thinking, and decision-making tasks\n\nTLDR: Today, we’re introducing Spiral, a powerful prompt builder that automates 80 percent of repetitive writing, thinking, and decision-making tasks. Watch a video walkthrough here. It’s available today along with our AI writing app, Lex, as part of a paid Every subscription:\n\n\n\n\n\n\n\n\n\nWe built a new AI product!\n\nIt’s called Spiral, and it’s a powerful prompt builder that automates 80 percent of repetitive writing, thinking, and decision-making tasks.\n\n\n\n\n\nSpiral makes it easy to repurpose any existing text content for different channels and attention spans:\n\nSpiral is also being used daily by other ambitious creators, like Lenny Rachitsky from Lenny’s Newsletter, Sam Koppelman from Hunterbrook, and Ben Tossell from Ben’s Bites—and they’re loving it.\n\nAli Abdaal has been using it for his 5.6 million-subscriber YouTube channel, and here’s what he had to say about it:\n\n“Spiral is awesome! It drastically speeds up the time it takes to convert videos, voice notes, and podcasts into first drafts of written content.”\n\nWe find that Spiral gets users to 80 percent on the repeat tasks they do every day, so they can spend more time on the creative work that matters.\n\nIt’s still early, but we have a feeling we’re on to something promising. Here’s the daily active user graph for the beta:\n\n\n\n\n\nSource: Clerk.\n\nWant to try it?\n\nSpiral is available right now for paid Every subscribers. If you’re not yet a subscriber, you can try Spiral for free.\n\n\n\n\n\nCurious to hear more? Keep reading.\n\nThere’s a lot of hidden drudgery in creative work.\n\nThere’s the core creative act: writing an essay, recording a podcast, building a new software feature, creating a presentation for a client.\n\nAnd then there’s the drudgery you have to do to make sure your work gets seen: turning your essay into an X post, writing the description for your podcast, creating release notes for your software feature, and writing an email pitch to book a meeting with the client.\n\nAll of this drudgery has a similar form: It takes your core creative work and compresses it into different sizes and formats for different mediums, attention spans, and audiences.\n\nBut while it might be drudgery, it’s important drudgery. More people are going to interact with your X post than your essay. More people are going to read the description of your new feature than use it. The quality of your compression matters a lot.\n\nAt Every, we produce a lot of creative work that we want to reach as many people as possible. But the repetitive drudgery was taking up a lot of our time.\n\nThen, in April, I realized that Claude is incredibly good at this kind of writing. I found that if I had a repetitive task and lots of examples of it done well, I could get 80 percent of the way there using the right prompt. Claude picked out the important ideas and compressed them into a new format in my style and voice. I didn’t have to start with a blank page anymore. I could start at already pretty good and spend most of my time making it excellent.\n\n(This was doubly surprising to me because most language models are trash writers. Claude 3 Opus is the first good one—and it’s really good.)\n\nThere was only one problem: Constructing the right prompt was time consuming and finicky. And it was hard to share with anyone else.\n\nSo that’s what Spiral does: It lets you build and share powerful prompts that automate away 80 percent of repetitive writing, thinking, and decision-making tasks.\n\nLet’s talk about how it works.\n\nI’ll give you a real example I use Spiral for every week: generating tweets for episodes of my AI & I podcast.\n\nFor a podcast I recorded with New York Times best-selling author Seth Stephens-Davidowitz, I needed to write a tweet to promote it. Normally, this would take a few hours. I’d have to rewatch the episode, think about what was interesting about it, and try and retry to frame it in tweet format. Or Rhea, an Every writer who often helps me write podcast descriptions, would have to do the same thing.\n\nInstead, I grabbed the transcript and pasted it into a Spiral I made to convert podcast transcripts to tweets:\n\n\n\n\n\nThen, I hit “Generate multiple.” Out popped five tweet ideas:\n\n\n\n\n\nI picked one, edited it, and ended up with this tweet in my style and voice:\n\n\n\nNYT best-selling author Seth-Stephens Davidowitz (@SethS_D) wrote a book in just 30 days—with @ChatGPTapp.Seth is a data scientist, economist, and author of Everybody Lies and Don’t Trust Your Gut. He’s worked at Google, lectured at Wharton, and consulted for Fortune 500… https://t.co/AVueruIjvL\n\nApril 10th 2024, 7:11am EST\n\n\n\nSpiral took a painful, long, repetitive process and turned it into something that took only a few minutes.\n\nAt Every, our library of Spirals helps our team do everything from writing proposals, to finding headlines, to coming up with summaries of our articles:\n\n\n\n\n\nWe’re also releasing a collection of public Spirals that anyone can use (and add to) so that the tool will get better and better over time—for free.\n\nWant to learn how to build Spirals yourself? See our entrepreneur in residence Brandon’s videos on X.\n\nThis isn’t our first time building an AI writing app.\n\nAlmost two years ago we incubated Lex, an AI document editor built by Every co-founder Nathan Baschez. We later spun it out, and Nathan raised a seed round. Since then, Lex has been shipping amazing features—like AI-based checks for passive voice, cliches, and more— at the forefront of human-AI creativity.\n\nWe think Spiral is a natural companion for Lex. Once you’ve done your core creative work in Lex, you can automate translating that work into different formats using Spiral. Best of all, the two are available as part of a bundle:\n\nWhen you sign up for a paid Every plan, you’ll get access to Spiral, Lex, and our daily writing on business and technology for just $20 per month:\n\n\n\n\n\nWe think it’s the best bundle of writing and software on the internet. And it’s only going to get better from here.\n\nSpiral was built in less than two months by an incredibly talented team inside of Every, led by our entrepreneur in residence Brandon Gell. Over time, we’ll be releasing more products like this to make your subscription even more valuable.\n\nOur core mission is to build an institution for business and technology writing. Spiral is the next step in that journey.\n\nWe have so much more to come. Stay tuned!\n\n\n\n\n\n\n\n\n\nDan Shipper is the cofounder and CEO of Every, where he writes the Chain of Thought column and hosts the podcast AI & I. You can follow him on X at @danshipper and on LinkedIn, and Every on X at @every and on LinkedIn.",
      "word_count": 1147,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3133/T_-_Cover.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3383/thumbnail_Screenshot_2024-12-20_at_12.43.17_PM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3586/thumbnail_Screenshot_2025-05-21_at_11.49.03_AM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "on-every"
    },
    {
      "url": "https://every.to/on-every/kate-lee-joins-every-as-editor-in-chief",
      "title": "Kate Lee Joins Every as Editor-in-Chief",
      "author": "Dan Shipper",
      "author_url": "/@danshipper",
      "publication_date": "October 30, 2023",
      "content": "Kate Lee Joins Every as Editor-in-Chief\n\nA note on the future of Every\n\nTo celebrate our new editor-in-chief we're offering subscriptions for 25% off your first year. If you’ve been considering becoming a paid subscriber, now is a great time to do it:\n\n\n\n\n\nTLDR: Kate Lee has joined Every as editor-in-chief and general manager of the newsletter. Kate was previously the publisher of Stripe Press and head of content at Medium. We’re ecstatic to have her aboard. You can read coverage of Kate’s arrival on Semafor.\n\nKate is going to help us make Every your go-to place for high-quality business and technology writing on the internet. She’ll bring in new writers, create new columns and series, and take Every to the next stage of our growth. Below is a bit more about what you can expect from us over the coming weeks and months, as we work to bring you the best new ideas on startups, AI, personal development, and more.\n\nThe most important thing I’ve learned in 3.5 years of running Every is this:\n\nIf you want to know what someone is going to make in the future, look at what they’ve already made. If you love what they’ve already made, it’s a good bet you’re going to love what they’ll make next.\n\nThat’s why I am so excited to bring Kate aboard at Every. I love Stripe Press. I love the writing about business and technology that they produce. I love the way they talk to builders and the beautiful aesthetic of their books—they open up our imagination, inspiring us to solve seemingly intractable problems and make great things.\n\nKate helped build Stripe Press as its publisher, and I know she can bring its magic to Every. She has the rarest combination: a love of editorial and a love of technology. She has incredible taste in people and in ideas. And she’s fun to work with to boot.\n\nWe started Every because, by and large, business and tech writing on the internet isn't very good. It’s either not relevant to builders, or it’s content marketing disguised as insight. We want to change that: we aim to produce high-quality writing that inspires curious, ambitious builders like you to dream new dreams—and to achieve them.\n\nMore importantly, in an age of solo internet writers, we’ve aimed to do this together—rather than alone. I think Kate is the perfect person to help me, Evan, and the rest of our writers create an institution dedicated to this work.\n\nWelcome, Kate. I’m excited to make a little dent in the internet together.\n\nBecome a paid Every subscriber and get one actionable essay a day on AI, tech, and personal development.\n\nTrusted by 90,000+ founders, operators, and investors:\n\n\n\n\n\nI’ve always believed in the power of writing to clarify your thinking, spread great ideas, and connect with others.\n\nEvery is the embodiment of those ideals. We believe in the power of technology and business writing to inspire others to build new things, see the world in a new way, and feel less alone. We want to produce really good technology writing that's grounded in rigor and fun to read. And founders, investors, operators, and other technologists all have insights to share—we want to bring the best of them to our readers.\n\nIt’s a particularly exciting time to join Every because of its evolution from a creator collective to a multi-faceted media company that builds technology products and offers courses. As editor-in-chief and general manager of the newsletter, I’m excited to help grow the business and dive into editorial work—publishing more and better writing, new editorial initiatives, and new formats. And we’ll continue to offer more courses like Dan’s chatbot course and incubate new products like Lex.\n\nThe marriage of writing and technology has been the through line of my career—first as a literary agent, working with writers who came to prominence because of the internet, then as the first head of content at Medium. It was there that I saw that writing by technology practitioners spoke to an audience that was hungry for first-hand knowledge from their peers. A startup founder reflected on their hard-won lessons when their company failed. A designer showcased the wireframes of a prominent social app feature used by millions. A product manager explained how they shipped a new tool; an engineer published snippets of their code; a venture capitalist shared their investing thesis.\n\nThat experiential knowledge came in handy at Stripe Press, Stripe’s publishing imprint, where I most recently served as publisher. We aimed to publish books that galvanized others to build—providing entrepreneurial inspiration, tackling seemingly insurmountable problems, and helping founders with the nuts and bolts of starting and growing companies. And we made those books with the highest levels of quality and craftsmanship—just like everything else that Stripe produced.\n\nIt was while I was at Stripe Press that I first met the Every team. They had just launched, and I reached out to them to learn more about what they were doing and how we might collaborate. When I had the opportunity to work with them, first as an advisor and then as an editor-at-large, it was a natural fit. The chance to join Dan and Evan full time to help grow and shape the business was one that I couldn’t pass up.\n\nIf you’re already a subscriber, we’re excited that you’re here. And if not, we hope you’ll join us.\n\n\n\nIf you’re interested in writing for us, we’d love to hear from you.\n\nWe’re looking for writers with direct experience in technology—perhaps you’re a founder, or you’ve worked at a startup or in big tech. You’re deeply curious about technology and how it works, and how it can be used to better yourself, and you think Paul Graham’s early essays are inspiring.\n\nYou don’t have to have written professionally before, but you do need to have written on the internet about business, technology, and/or startups—whether that’s Tweets, ghostwriting, or anything in between.\n\nIf this is you, please send us some information about yourself. We look forward to hearing from you.\n\n\n\n",
      "word_count": 1012,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/2830/Artboard_1.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "on-every"
    },
    {
      "url": "https://every.to/on-every/introducing-ai-i",
      "title": "Introducing ‘AI & I’",
      "author": "Dan Shipper",
      "author_url": "/@danshipper",
      "publication_date": "May 29, 2024",
      "content": "Introducing ‘AI & I’\n\nHow to use AI to think, create, and relate\n\nTLDR: We’re renaming my show, How Do You Use ChatGPT?, to AI & I. It’s a different name but the same great show. Watch the trailer on YouTube or Spotify, and if you haven’t seen or listened to it yet, check out past episodes on YouTube or Spotify. And stay tuned for a new episode next week with bestselling author Steven Berlin Johnson.\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nAI is the best test of what would happen if we all got magical powers.\n\nMost of us would ignore them.\n\nExcept some people are learning to harness these powers. They’re using AI to code, to think, to write, to build businesses, to make art, to learn anything they want to learn. But how are they doing this?\n\nThat’s what I’ve been documenting every week for the last six months in my show, How Do You Use ChatGPT? I’ve talked to 20-plus guests, including LinkedIn co-founder Reid Hoffman, economist Tyler Cowen, a16z’s Steph Smith, and the New York Times’s Kevin Roose. They screen-shared with me through their actual ChatGPT chats so we could see how they’re using it in their work and in their lives.\n\nIt’s been a wild ride. The show has been played almost 70,000 times on Spotify and has received almost 200,000 views on YouTube. It’s now consistently a top 50 technology podcast in the U.S. And I’ve learned more about AI—and about myself—than I thought I ever would.\n\nI’ve loved the name How Do You Use ChatGPT? It’s specific. It makes a legible promise to listeners. But it’s also a little limiting. ChatGPT is the AI product I’m most excited about—and that I use most often—but our guests often end up showing much more than just ChatGPT. I wanted to find a name that reflects how the show has expanded as it has evolved and grown over the last few months.\n\nSo, today, I’m excited to announce that we’ve renamed it to AI & I.\n\nEverything about the show is the same—except it has a new name.\n\nIt’s an interview show where I talk to the smartest people in the world about how they use ChatGPT and other AI tools in their daily lives. We go through actionable strategies for using it as a tool to think, write, create, make decisions, and more. The show itself becomes a live exploration between the guest and me. AI always surprises us, and we learn new things about AI, ourselves, and the world as we explore it together.\n\nWe’re releasing our first episode under the AI & I banner next week—my conversation with bestselling author Steven Berlin Johnson. Our guests for upcoming episodes include Notion founder Ivan Zhao, writer Packy McCormick, and investor Yohei Nakajima.\n\nThis is your invitation to join us for a weekly rendezvous with the future.\n\n\n\n\n\nWatch the trailer for AI & I on YouTube or Spotify.\n\n\n\n",
      "word_count": 501,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3113/AI__I_Cover.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3586/thumbnail_Screenshot_2025-05-21_at_11.49.03_AM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "on-every"
    },
    {
      "url": "https://every.to/on-every/introducing-extendable-articles",
      "title": "Introducing Extendable Articles",
      "author": "Dan Shipper",
      "author_url": "/@danshipper",
      "publication_date": "December 3, 2024",
      "content": "Introducing Extendable Articles\n\nA new type of media that uses AI to expand your perspective\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nToday, we’re launching a new essay format on Every: Extendable Articles.\n\nExtendable Articles include a chat bot that lets you talk to the content that you’re reading. But there’s a twist:\n\nIn an Extendable Article, we make available all of the source material—original interview recordings and transcripts, YouTube videos, news stories, articles, and more—that the writer used to put the piece together. So you don’t just get the writer’s perspective—you can chat with all of the information they used to inform it.\n\nIt looks like this:\n\n\n\n\n\nWhen you ask a question, it will return a detailed answer:\n\n\n\n\n\n\n\n\n\nYou can even browse a list of all of the sources used to create the article and watch the original interviews conducted by the writer on YouTube:\n\nYou’re probably creating more than ever before—writing essays, recording podcasts, promoting your work on social media. We want to make it easier for you to move fast. Use Spiral, our tool to automate 80 percent of the repeat work that comes after creating—social media posts, YouTube descriptions, newsletter blurbs, and more.\n\n\n\n\n\n\n\n\n\nAnd we think the time for this is now.\n\nThe internet allows publications like ours to include unlimited context alongside a narrative without disrupting its flow—and at no extra cost. AI can make this context discoverable and meaningful.\n\nIf you’re curious, you can try Extendable Articles right now in the deep dive we just published on Ramp, “The Religion of Ramp,” by Evan Armstrong. We’ve included all of the interviews Evan did with Ramp’s team, as well as the articles and videos he used as background research.\n\n\n\n\n\nIf you’re interested in the back story, here’s a little bit more about why we did it.\n\nWhen you write, you always have to leave something important out.\n\nStories are created by subtraction. They start as an endless ocean of facts and ideas. The writer’s task is to find and follow the currents of narrative in this ocean, and channel them into a story. This is a good thing: Not everyone needs to explore the ocean, but we should all know what’s out there.\n\nBut the subtraction process that creates a story has a downside: It can never be entirely objective. Decisions have to be made about what to include and what to cut. And, invariably, there is a debate about what those decisions should be.\n\nRightly or wrongly, people don’t trust those decisions right now. Accusations of bias in the media run rampant from all sides, but there’s no easy solution because omission is an inevitable part of narrative.\n\nI’ve felt this acutely while running Every. I’ve spent countless hours debating with Evan and Kate, and other writers and editors on the team, about how to write stories, and what to include and what to cut. We’re not trying to be objective—people read Every because our writers come with their own perspectives. But we always try to be fair-minded, nuanced, and curious, and that’s a standard that’s incredibly difficult to get right every time.\n\nWe’ve made mistakes, and I think every other media organization and writer would say the same.\n\nEighteen months ago, I realized that technology was changing this equation. Before, research and storytelling were always inextricably bundled together. But because AI can now tell stories, pure research—without an accompanying story—can be useful raw material for any end user.\n\nI wrote this:\n\nI thought it might be possible for any publication to incorporate a chat experience to help readers get more out of their content:\n\nAt the time I wrote this, AI was still not good enough to make this a reality. Context windows weren’t large enough, and the experience just wasn’t going to be reliably good. But that’s changed over the last year.\n\nSo we decided to build it.\n\nWith Extendable Articles, we can publish stories that have a valuable perspective on the world—and you can form your own opinions from the research we’ve done.\n\nOf course, this doesn’t solve every problem. For example, much of what forms a writer’s worldview isn’t source material for a particular piece—it may come from books or conversations over many years—and it’s difficult to include those kinds of sources in a format like this.\n\nBut we think it’s an important step in the right direction. And this is just the beginning.\n\nSo try it out. Read the perspective in the main story, and explore the transcripts and articles that formed it in their entirety. Let us know what you discover—we’re as curious as you are.\n\nAt Every we’re obsessed with what comes next, and we know that’s what you care about, too.\n\nWe hope Extendable Articles become one more tool to see what’s beyond the horizon—together.\n\n\n\n\n\n\n\n\n\nWe also build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Write something great with Lex.\n\n\n\n",
      "word_count": 830,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3334/extendablemedia.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3586/thumbnail_Screenshot_2025-05-21_at_11.49.03_AM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "on-every"
    },
    {
      "url": "https://every.to/source-code/a-new-way-to-read",
      "title": "A New Way to Read",
      "author": "Naveen Naidu Mummana",
      "author_url": "/@naveen_6804",
      "publication_date": "February 10, 2025",
      "content": "A New Way to Read\n\nI built an AI tool that has fundamentally changed how I read\n\nTLDR: Today we’re sharing the latest experiment from Every Studio: Kairos, an AI-powered reading companion that helps you read more deeply, understand complicated concepts, and questions you on your comprehension. Kairos is built by our entrepreneur in residence (and the author of this piece) Naveen Naidu Mummana. Try it out on TestFlight and let us know what you think.—Brandon Gell\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nSomething odd happens when you read with AI. You start having conversations with books.\n\nI discovered this accidentally while reading on my iPad. I kept toggling between my ebook and ChatGPT, copying passages to ask questions. At first this felt like a hack—a messy workaround because reading apps haven't caught up to AI. But then I realized I was stumbling onto something more interesting: a fundamentally new way to read.\n\nHaving wrapped up my first experiment as an Every entrepreneur in residence, and with a little inspiration from an X post by computer scientist Andrej Karpathy, I decided to build a piece of software for myself: an AI-native reading tool I’m calling Kairos that would solve my own book-reading problems. Now, I’m testing how far I can push the reading experience when AI is built in from the ground up.\n\nReading hasn't changed much since Gutenberg. Sure, we've moved from paper to pixels, but we still primarily consume text linearly, making highlights and notes just as readers did centuries ago. Digital reading platforms have mostly focused on distribution—making books more accessible through devices and online libraries. But the core activity of understanding what we read remains largely unchanged.\n\nThis seems especially strange given how much other forms of learning have evolved. We expect students to engage in discussion, not just listen to lectures. We know active learning beats passive consumption. Yet reading remains mostly solitary and one-directional.\n\nAI changes this equation. Instead of just absorbing text, you can probe it. When you encounter a difficult passage, you can ask for clarification. When an idea reminds you of something else you've read, you can explore the connection. The text becomes a starting point for investigation rather than just information to absorb.\n\n\n\n\n\nWhen you write a lot about AI like we do, it’s hard not to see opportunities. We build tools for our team to become faster and better. When they work well, we bring them to our readers, too. We have a hunch: If you like reading Every, you’ll like what we’ve made.\n\nAs I experimented with AI-assisted reading, I found myself asking a fundamental question: What does it mean to read well? The more I toggled between text and AI, the more I realized I needed a framework to understand how this technology was changing not just how we read, but the very nature of reading itself.\n\nThis search led me to Mortimer Adler, a philosopher and educator best known for his work on the Great Books movement, a project aimed at defining the essential works of Western civilization. In 1940, Adler published How to Read a Book, a guide to deeper reading that has remained influential for decades. His argument was simple: Most people read passively, skimming for information without truly engaging with the text. He outlined four levels of reading, each representing a more sophisticated way of understanding and interacting with books:\n\nAdler's framework provides a perfect lens to understand how AI can transform reading. To explore this, I built Kairos with an interface that feels familiar—similar to Apple Books—but with a crucial addition: an AI companion that's always ready to engage. The reading interface remains clean and focused, with a discrete AI button in the bottom left corner that opens up new possibilities for interaction. Tap it, and you'll find options to chat with Kairos, catch up on previous sections, or access chapter summaries—all while maintaining the full context of what you're reading.\n\nThe result feels less like traditional reading and more like having a knowledgeable friend reading alongside you. This friend never gets tired of your questions, has read practically everything, and can instantly recall relevant details from other books. It's the kind of reading experience previously available only to those with access to expert tutors or extensive personal libraries.\n\nLet me walk you through how this works, using each of Adler’s reading levels as a guide.\n\n\n\n\n\nSource: All screenshots courtesy of the author.\n\nAdler defines elementary reading as the most basic level of comprehension—understanding the words on the page and following along with the text. It’s the foundation for all deeper engagement, but when readers hit dense or jargon-heavy passages, comprehension can break down.\n\nTo test AI's capabilities at the elementary level, I experimented with Marcus Aurelius' Meditations—a philosophical text notorious for its dense passages and complex ideas. Take, for instance, a famous passage from Book 2, where Aurelius writes that he'll encounter \"men who are meddling, ungrateful, insolent, dishonest...\" When I asked Kairos to explain this in modern terms, it transformed the passage into something surprisingly relatable:\n\n\"Before I step out the door, I mentally prepare for a day filled with internet trolls, office drama, and that one coworker who just can't stop oversharing on Slack. In other words, don't be surprised if today's reality feels like a never-ending episode of a reality show—but keep your cool anyway.\"\n\nWhat struck me was how the AI didn't just translate the words—it bridged the 2,000-year gap between Aurelius’ world and ours. Suddenly, the Roman emperor's morning self-talk felt as familiar as our own pre-coffee pep talks before facing a day of endless emails and social media debates. This kind of translation made the philosophical insights not just understandable, but immediately applicable to modern life.\n\n\n\n\n\nInspectional reading, according to Adler, is all about efficiency—skimming a book to get a sense of its structure, argument, and main ideas. The goal isn’t to absorb everything but to determine whether (and how) to engage more deeply.\n\nTo test AI's inspectional capabilities, I experimented with two different reading scenarios. First, while reading The Nvidia Way by Tae Kim over several weeks, I discovered how having a catch-up feature could instantly refresh my memory of previous chapters. This proved invaluable for maintaining continuity and context—much like having a friend quickly recap what you missed in a TV series before watching the next episode.\n\nEven more revealing was my experience with the book Why Greatness Cannot Be Planned, by Kenneth O. Stanley and Joel Lehman. Using a feature I added that provides chapter-by-chapter summaries, I could first grasp the book's central thesis before diving into individual chapters. This top-down approach—understanding the main theme before exploring its components—helped me better absorb and retain the author's ideas. The AI summaries created a mental scaffold that made the detailed reading more meaningful and coherent.\n\n\n\n\n\nAnalytical reading is about asking questions—breaking down an author’s argument, identifying assumptions, and engaging critically with the material. Adler sees this as the level where readers stop being passive consumers and start actively interrogating ideas.\n\nTo test AI's analytical capabilities, I explored how Kairos could deepen my understanding of business narratives. While reading The Nvidia Way, I discovered that each chapter conclusion opened up opportunities for profound analytical discussions. At one point, Kairos posed a particularly thought-provoking question: \"Can a company truly prevent internal complacency, or is organizational entropy inevitable as business grows?\"\n\nWhat made this interaction powerful wasn't just the question itself, but how it transformed what could have been a simple corporate biography into a source of deeper business insights. The AI helped me extract practical lessons from Nvidia's experience, pushing me to think beyond the narrative to understand broader principles of innovation and corporate adaptation.\n\nThis approach fundamentally changed my reading habits. Instead of passively consuming information, I found myself regularly engaging in meaningful dialogue about the text. The AI doesn't just ask questions—it helps readers develop the habit of questioning, encouraging the kind of critical thinking that Adler saw as essential to true analytical reading.\n\n\n\n\n\nSyntopical reading is Adler’s highest level—the ability to compare multiple books, extract common themes, and develop original insights. It’s how scholars synthesize knowledge across disciplines.\n\nTo test AI's syntopical capabilities, I explored how seemingly modern ideas often have deep historical roots. While reading Why Greatness Cannot Be Planned, I was struck by its counterintuitive thesis about achievement and goal-setting. Through conversations with Kairos, I discovered fascinating parallels between the book's central argument and ancient Hindu philosophy.\n\nFor instance, when the authors assert that \"sometimes the best way to achieve something great is to stop trying to achieve a particular great thing,\" I asked Kairos to explore similar ideas in Hindu texts. The AI immediately drew a compelling connection to the Bhagavad Gita's famous teaching: \"You have a right to perform your prescribed duties, but you are not entitled to the fruits of your action.\" This parallel wasn't just interesting—it helped me internalize the book's message by showing how this wisdom has resonated across cultures and millennia.\n\nWhat made this particularly valuable was how it transformed a contemporary argument into part of a much longer conversation about human achievement and purpose. AI didn't just find surface-level similarities; it helped illuminate how different traditions and thinkers have wrestled with similar ideas through different frameworks. Traditional reading often means relying on memory or manual research to make such connections, but AI removes that friction. By highlighting passages and asking comparative questions, Kairos turns books into participants in an ongoing intellectual dialogue, bridging gaps between ideas across time, cultures, and disciplines.\n\nMy experience with Kairos hints at something broader about how AI will change intellectual work. The pattern we see with reading—where AI transforms a traditionally solitary activity into a dynamic conversation—likely applies to other forms of learning and creation. The key isn't just making things faster or more accessible, but enabling new forms of engagement.\n\nCritics worry that reading with AI will make people lazy—that we'll become dependent on AI instead of developing our own understanding. But this misses the point. Having a conversation about a text requires active engagement. You need to formulate questions, evaluate responses, and synthesize new understanding. It's the opposite of passive consumption. AI has the potential to make it much easier to achieve this deeper level of engagement.\n\nThe real challenge in the age of AI, then, isn't figuring out how to prevent people from using it so that some sort of pure, idealized reading experience is preserved. It's building tools that support this new paradigm effectively. Current e-readers are designed around the old model of solitary consumption. We need reading platforms that embrace the conversational nature of AI-assisted reading while respecting things like copyright and privacy.\n\nSome might argue this isn't really reading anymore. But that's like saying having a discussion about a book isn't reading. The goal remains the same: understanding and engaging with ideas. AI just gives us new tools for doing so.\n\nCenturies ago, the printing press democratized access to books. Digital technology has democratized distribution. AI might finally democratize the kind of deep engagement with texts that scholars and philosophers have practiced for centuries. That seems like progress worth pursuing.\n\n\n\n\n\nIf you're curious to explore this new reading paradigm, try Kairos on TestFlight and let us know what you think. Fair warning: This is very much a proof-of-concept with plenty of rough edges and missing features—think of it as a glimpse into the future of reading rather than a polished product. While I can't guarantee long-term support or regular updates, I hope it sparks your imagination about how AI might transform our relationship with books.\n\n\n\n\n\nWe also build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Write something great with Lex. Deliver yourself from email with Cora.\n\nGet paid for sharing Every with your friends. Join our referral program.\n\n\n\n",
      "word_count": 1992,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3456/Artboard_2.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3390/thumbnail_Screenshot_2025-01-08_at_10.19.28_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3538/thumbnail_Screenshot_2025-04-01_at_11(2).06.41_AM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "source-code"
    },
    {
      "url": "https://every.to/source-code/a-time-machine-for-your-email",
      "title": "A Time Machine for Your Email",
      "author": "Brandon Gell",
      "author_url": "/@brandon_5263",
      "publication_date": "January 14, 2025",
      "content": "A Time Machine for Your Email\n\nOur email app Cora isn’t an email client—it’s a productivity tool\n\nTLDR: Join the waitlist for our new email app, Cora. Was this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\n\n\n\n\nMy work day is defined by two key events, at 8 a.m. and 3 p.m.\n\nThat’s when Cora delivers my brief—a personalized newsletter filled with the important, but not urgent, information I receive throughout the day. The time in between? Productivity bliss (and sleep and fun).\n\nCora is Every’s newest product. It’s an email client that turns your inbox into a story using AI. We’ve been working on it for six months. We initially decided to experiment with using AI for email after we created our prompt builder Spiral—which automates 80 percent of repeat writing tasks, in your voice and personality—and realized how well AI could mimic a person’s writing style.\n\nIn Cora’s first iteration, it focused on a different problem—one of email efficiency—and it drafted responses for you. It vectorizes thousands of your emails to understand who you talk to, about what, in what style and tone. And it’s really good at this: Cora drafts more than 50 percent of my emails now.\n\n\n\n\n\nAn important part of drafting responses well is learning what emails actually need a response. Once we built the tooling to determine what necessitates a response and what doesn't, we realized something we couldn’t ignore: 90 percent of our emails are notifications. They are distractions. They don’t need to be read right away, or even at all, yet they’re side-by-side with critical messages. And despite the communication patterns that exist within all of our inboxes, email is still an endless, chronological, non-hierarchical to-do list that everyone but yourself gets to control.\n\n\n\n\n\nWhen you write a lot about AI like we do, it’s hard not to see opportunities. We build tools for our team to become faster and better. When they work well, we bring them to our readers, too. We have a hunch: If you like reading Every, you’ll like what we’ve made.\n\nI used to pride myself on being an inbox-zero kind of guy. If I had five minutes between meetings or 10 minutes to spare waiting for the subway, I’d hammer out emails and clear my inbox. I was the CEO of a startup, and that’s what CEOs do—they’re always productive. But it wasn’t until we built Cora that I discovered the truth: I wasn’t being productive and managing my inbox—I was drowning in it. I wasn’t cultivating a garden; I was endlessly pulling weeds from it that others had tossed in.\n\nHere’s Cora in a nutshell:\n\n\n\n\n\nThe beauty of Cora is that it doesn’t stop me from dealing with my email—in fact, it’s the opposite.\n\nIt enables me to immediately address urgent messages that require a response and  gives me a head start by drafting responses. At the same time, it archives everything non-urgent that may distract me, like emails that don’t need responses, newsletters, comments, calendar notifications, and so much more. It then organizes these emails into a brief that I can review twice a day, at 10 times the speed I normally would.\n\nThe result: I hardly look at my email over the course of my day—yet I’m faster to respond to those that matter, more informed about those that don’t, and more focused on execution outside of my inbox.\n\nThe chart below shows a subset of the users who have begun using Cora. The left-hand column is how many briefs they’ve received, the middle is how many they’ve opened, and the one on the right is the percentage. This tells me three things:\n\n\n\n\n\nMy instinct is that users are enjoying Cora because it’s not an “AI email assistant” (we ban that language here). It’s an entire email methodology—some mixture of time blocking and inbox zero—that you are forced to use. It’s an opinionated way of managing your email inbox that has freed me from the mentality that maintaining inbox zero equals high-impact productivity.\n\nMy job at Every is to inspire, organize, and push the general managers of our products and our entrepreneurs in residence to do great work. Cora is certainly that, and with everyone on the team using it, we all have a bit more time in our days to deliver on that promise.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe also build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Write something great with Lex.\n\nGet paid for sharing Every with your friends. Join our referral program.\n\n\n\n",
      "word_count": 762,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3395/timemachine_.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3598/thumbnail_rochest(2).png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3390/thumbnail_Screenshot_2025-01-08_at_10.19.28_AM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "source-code"
    },
    {
      "url": "https://every.to/source-code/selfish-software",
      "title": "Selfish Software",
      "author": "Edmar Ferreira",
      "author_url": "/@edmar",
      "publication_date": "January 27, 2025",
      "content": "Selfish Software\n\nMaking software can be fun again if you build for the user you’re most eager to please—yourself\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nI’d like to introduce a concept I call “selfish software.”\n\nSelfish software refers to writing code for yourself without any external customers in mind. This practice might sound niche or individualistic, but there’s no need for it to be.\n\nThink about building software today. Workflows are contorted to match rigid systems. Pre-built solutions are preferred over new ones, and compromises in functionality are common. There’s a way that things “should” work, and it’s easier to follow these rules than to break them.\n\nBut this approach is backwards. Software should conform, not the other way around.\n\nConforming has rarely led to great outcomes. Some of the most significant breakthroughs have come from flexibility, addressing personal pain points, and having fun. Linus Torvalds, the founder of two cornerstones of modern computing—operating system Linux and version control system Git, both open-sourced—started the former at age 21 in college as a way to procrastinate from school work. It was “just a hobby, [it] won’t be big and professional,” he said. It’s a lesson for all of us: If you conform too much, you can lose your creativity and come up with boring solutions.\n\nI learned this lesson the hard way. After I sold my first company four years ago, I found myself in an odd position. Having grown Rock Content to become the content marketing leader in Latin America, I had achieved financial freedom to do what I wanted for the rest of my life—yet I'd lost my drive to create.\n\nI grew up in a poor family, and felt lucky when I fell in love with engineering and learned that there was a way to do what I loved while making money. The first time I programmed my own game as a kid, I felt like a wizard. Code was like magic, but better—it was real. Coding became the most powerful organizing principle of my life. I was obsessed with it.\n\nBut once I sold Rock Content, I found that it had stripped away the very thing that had made me successful—the joy of building. I started to focus too much on the market. Whenever I had a new idea, I’d think about potential customers instead of building the things I wanted to. This dry, paint-by-the-numbers approach eroded all the joy I’d once had of building software.\n\nSo I started writing code just for myself. I became a builder of selfish software. I had a long list of exciting ideas that I’d been putting off for more profitable ones. When I joined Every as an entrepreneur in residence, I challenged myself to complete nine experiments in three months. I completed eight projects—I had a baby during this period, which slowed me down—and felt the joy return. Three of those projects are a simulation for AI characters, a new type of personal knowledge management system, and a system to automatically keep content up to date. I was back in building mode. And because building is a part of my identity, I felt like I was becoming myself again.\n\nWhen you create selfish software, there’s nowhere to hide. You can’t gloss over a clunky interface or excuse an awkward feature. The feedback loop is immediate and brutally honest, because your audience is just yourself. You’re forced to refine every detail until it works. Once you have something that genuinely solves your own problems, you may be surprised by how many others it helps—even if you haven’t developed a grand plan for profit. But the profit isn’t the point. The point is the fun, creativity, and excitement you’ve had along the way. And it’s easier than ever with AI.\n\n\n\n\n\nWhen you write a lot about AI like we do, it’s hard not to see opportunities. We build tools for our team to become faster and better. When they work well, we bring them to our readers, too. We have a hunch: If you like reading Every, you’ll like what we’ve made.\n\nIt can be challenging to jump into selfish software after being accustomed to searching for customers and making projects for profit. I had to rewrite my own workflows and to rethink how I approached work. Here are a few steps I took to get started:\n\nI had to train myself to stop thinking about other people’s needs while building, and to stop asking the question: “Who else would use this?” I like to turn off notifications, close unrelated tabs, and set aside what I like to call “playtime” to give my creative instincts the space they need to surface without the interference of market-driven thinking.\n\nReflect on your daily annoyances. Notice those moments when you think to yourself, “I wish I had a tool for this.” Keep a journal or notes app handy to log every micro-frustration. Start with tasks or processes you repeat often. If you build a tool to handle something you face regularly, you’ll experience immediate relief every time you use it.\n\nModern AI tools and code generators make it easy to spin up short-lived solutions without the lengthy effort of creating a fully polished product. Whether you need a quick script to parse data or transform a file format, building these little helpers flexes your problem-solving skills and helps you fail quickly and cheaply. You’ll learn what works and what doesn’t in a fraction of the time it would take with a traditional development cycle.\n\nOnce you’re comfortable with disposable projects, move into more personal software—custom software for your personal needs. Your ongoing use will be a good guide to improving it.\n\nKeep iterating in real time—tweak features, polish interfaces, and add anything that brings you delight, even if it seems too quirky or “unprofessional.” It can help to document your logic along the way. Even simple notes will keep you from forgetting important details after a few weeks of not touching the code.\n\nTry ideas that might seem out of place at a larger company and remind yourself that there’s no boss or investor breathing down your neck. With that pressure gone, you can follow your curiosity wherever it leads. Ask yourself: “What would make this even cooler for me?” Then do it. This sense of exploration is exactly what often leads to innovative ideas. For instance, I'm currently working on a new project that originated from a failed one. I had created a system to generate motivational ads targeted at myself, but I didn't like the output of any LLM models. I’ve needed to go deep on preference optimization so that the model outputs would improve, and, in the process, I’ve developed an idea for a new preference optimization fine-tuning scheme.\n\nSelfish software doesn’t need to remain personal—if you’d like it to scale, you can. People with the same challenges might be eager to adopt your solution. You can refine the interface or add better documentation if you decide to open it up to a wider audience, but that’s optional. Sometimes your selfish software remains just for you, and sometimes it becomes the seed of something larger. Both outcomes are entirely valid and part of the beauty of this approach.\n\nHere are the AI tools in my personal tech stack that have made it easy to build selfish software:\n\nSelfish software is not about ignoring user needs altogether; it’s about restoring the joy of building by making yourself the user you’re most eager to please. This approach leads to software that’s a perfect fit for your own workflow, often resulting in insights and breakthroughs that generic, one-size-fits-all solutions miss.\n\nTake Stardew Valley, one of the most successful indie games of all time. Eric Barone spent four years creating the game by himself, learning to code, make pixel art, and compose music along the way. He wasn't trying to follow market trends or create the next big hit; he simply wanted to make the farming game he personally wanted to play, one that would improve upon the mechanics of Harvest Moon, his favorite childhood game. The result? A game that has sold over 41 million copies, generated more than $500 million in revenue, and brought joy to players worldwide. Stories like these teach us a valuable lesson: If you conform too much, you risk losing your creativity and coming up with boring solutions.\n\nBuilding for yourself has never been more accessible—or more fun. Give it a shot. Whether your project remains a personal hobby or blossoms into the next big thing, you’ll have created something truly valuable: software that actually serves the unique needs of its user—you.\n\n\n\n\n\nWe also build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Write something great with Lex. Deliver yourself from email with Cora.\n\nGet paid for sharing Every with your friends. Join our referral program.\n\n\n\n",
      "word_count": 1492,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3439/selfish_software.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3598/thumbnail_rochest(2).png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3390/thumbnail_Screenshot_2025-01-08_at_10.19.28_AM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "source-code"
    },
    {
      "url": "https://every.to/source-code/why-building-in-ai-is-nothing-like-making-conventional-software",
      "title": "Why Building in AI Is Nothing Like Making Conventional Software",
      "author": "Edmar Ferreira",
      "author_url": "/@edmar",
      "publication_date": "October 29, 2024",
      "content": "Why Building in AI Is Nothing Like Making Conventional Software\n\nIntroducing Source Code, your backstage pass to Every Studio\n\nThere’s a fundamental loop underneath everything we do at Every: Write -> build -> repeat. Building exposes you to aspects of the world that were previously hidden. Writing helps you to find a precise, concise way of expressing what you know and why. This loop isn’t necessarily linear—sometimes we start with building and move to writing, sometimes we start with writing instead—but it does lead to, we think, a particularly effective way of creating new things.\n\nThat’s why, today, we’re launching Source Code, a new column where we bring you into our product studio as we tinker with what comes next. This first piece, by Every entrepreneur in residence Edmar Ferreira, is an incredible articulation of building products in AI, why the key risk of new AI products is feasibility, and how to deal with it through fast experimentation. Sign up to be the first to try our products as an Every Early Adopter.—Dan Shipper\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nBut it didn’t work—so I asked myself: How is building in AI different from building in conventional software?\n\nI joined Every Studio with an ambitious goal: to build nine products in three months—one project every 10 days. My first project, Mindtune, is an AI-driven alternative to traditional adtech and social media algorithms. My hypothesis is that people are fed up with the formulaic, impersonal content in their social media feeds, and that AI offers an opportunity to deliver a more relevant, personalized experience.\n\nI started Mindtune with demand validation because this is where traditional software projects tend to fall apart. You build landing pages, talk to potential customers, analyze competitors—and only then do you invest resources in building out the product. Founders have been following this template for so long that it’s like a reflex. We don’t necessarily stop to ask ourselves, is building this thing even possible?\n\nBuilding with AI requires us to break our habits and approach building in a different way. AI products bring with them a unique set of risks, and if you don’t understand them, you’re bound to make mistakes.\n\nAs I was building Mindtune, I identified three risk profiles that helped me see exactly what kind of risk I was taking on—and, more importantly, what would determine whether it succeeded. I’ll dive in to each of the risks, how they relate to each other, and how AI disrupts the traditional startup “risk chain.” My hope is that founders and builders can save themselves a few wrong turns in the idea maze by better understanding where the risks in their idea lie—and how best to defuse them.\n\n\n\n\n\nWhen you write a lot about AI like we do, it’s hard not to see opportunities. We build tools for our team to become faster and better. When they work well, we bring them to our readers, too. We have a hunch: If you like reading Every, you’ll like what we’ve made.\n\nThere are three types of risks involved in any startup: feasibility, value, and viability.\n\nThe way these three types of risk interact is critical. Think of them as a chain: Feasibility → value → viability. If your product isn’t technically feasible, the other two risks don’t matter. If it’s feasible but not valuable, you’re stuck again. And even if users love your product, you still have to figure out how to make money from it.\n\n\n\n\n\nSource: Excalidraw/Author’s illustration.\n\nThese three risks don’t just arise in sequence; the magnitude of each risk changes depending on the type of product you are building.\n\nIn traditional software, feasibility risk is often low. Building the first version of Facebook didn’t involve any groundbreaking technological leaps. Mark Zuckerberg coded it from his Harvard dorm room. The real challenge was in the value and viability risks: Would people use it, and could it become a profitable business?\n\nBy contrast, there’s deep tech—projects like gene therapies, fusion reactors, and automated general intelligence that are bringing whole new technologies to market. There’s a clear demand and business model for these kinds of innovations (for instance, a drug for an existing disease), so the value and viability risks are low. The risk is feasibility: Deep tech startups take the risk of building something that they are not 100 percent sure is possible.\n\nI set out thinking that Mindtune would behave much like a software product, with low feasibility risk and greater hurdles at the value and viability stages. But as I learned, AI introduces unique challenges in both feasibility and valuability that demand a new approach.\n\nFor one thing, the risk profiles are not the same. There are two main categories of AI startups: what I call deep AI startups and applied AI startups.\n\nMindtune is an applied AI product: It leverages existing AI models to deliver the desired result of a more personalized social media feed. I was confident that the value was there—that users would welcome a different social media experience—and that the business model had been validated by existing products. But the more I thought about it, the more I realized I had missed an important step: thinking through the feasibility of the technology. I had assumed that, because I could engineer the AI model to deliver a result, that was the same as getting the right result consistently. I underestimated the feasibility risk of building in AI, even applied AI.\n\nTraditional software is fundamentally deterministic: The code produces predictable outputs if the logic and parameters are set correctly.\n\nGenerative AI has an inherent stochastic dimension: Results aren’t always consistent, and output quality can fluctuate based on the input data and nuances in the model itself. It requires constant testing to determine if the results are reliable and valuable enough for users. As a result, traditional engineering intuition doesn’t fully apply.\n\nOver time, you start to build a sense of what an AI model can or cannot do, but those instincts are less calibrated than they would be with traditional software. Even highly experienced AI engineers encounter unexpected results. The technical feasibility risk is greater than that of traditional software because models can surprise you—both positively and negatively—during testing. But it’s not as daunting as it is in deep tech, where fundamental scientific breakthroughs might be required to move forward. Instead, the risk of generative AI sits somewhere between software and deep tech—feasible but unpredictable.\n\nBecause of this unpredictability, working with generative AI requires a much more experimental approach. In traditional software, a well-built first version may need minor tweaks—a change to button placement here, clearer copy there—rather than a complete overhaul. With generative AI, however, that first version might require continuous “tuning”—adjusting prompts, incorporating additional data, tweaking parameters—to improve its reliability and user value. And each adjustment can slightly shift the outcomes, so the cycle of iteration and testing is essential for getting the desired results.\n\nWith Mindtune, I started building the software experience—wireframes, logins, etc.—before testing the models (GPT-4o, Claude 3.5 Sonnet, Gemini Pro 1.5, and Llama 3.2) to see if they were capable of generating good enough content for the personal ads. That was a mistake: When I finally did evaluate the quality of the models’ output, they returned inconsistent results. I should have done the latter before I worried about the software components because it’s the quality of the underlying model, not the software that sits on top of it, that ultimately determines the project’s feasibility.\n\nThis iterative process also demands an intuitive sense of when to stop or pivot. There’s a delicate balance between pushing a model’s capabilities and recognizing when it’s hit a limit. Sometimes, despite repeated tweaks, the output may never reach an acceptable quality, and you should cut bait. Alternatively, you might sense that a few more iterations could produce the results you’re aiming for.\n\nHowever, there’s nuance at this stage, too. Sometimes, the lack of feasibility in applied AI is a sign that the project isn’t worth pursuing. At others, you may be confident that the value is there despite the feasibility being low—so you shouldn’t abandon the project, but pivot. You may start out thinking you’re building an applied AI project and realize that what you’re actually building is deep AI, and that in order to make the project feasible, you must go into research mode and build your own model. Your feasibility risk increases, but the project may be even more valuable, and therefore more worth pursuing.\n\nWhatever you build, you need to understand the risk profile, but it is especially crucial for AI. If you know the nature of the risk you’re taking, you can figure out where to prioritize your resources and energy. It also forces you to ask the right questions at each stage: Can we build this? Will people use it? And only then, once those checkpoints are cleared: Can we build a sustainable business around it?\n\nAI startups, whether applied or deep, operate on a different level of complexity than traditional software products. They require a deeper understanding of how risks interlock and a willingness to navigate uncharted territory. Many developers assume that using generative AI APIs eliminates technical risk—that they’re creating “just another wrapper.” But that’s deceptive. Even when using existing models, there’s a significant level of experimentation involved.\n\nUnderestimating this technical risk can lead to wasted time and resources. It’s easy to think that since the heavy lifting is done by the AI model, you can focus solely on market demand and business models. But in reality, ensuring that the AI performs as needed is a substantial part of the challenge. Achieving reliable and valuable outcomes requires more than just hooking up an API; it demands continuous tweaking, testing, and a deep understanding of the model’s behavior. For my next project, I’ll start here.\n\n\n\n\n\nEdmar Ferriera is an entrepreneur in residence at Every. He is the founder of EverWrite, an AI SEO and content marketing leader in Latin America. You can follow him on X at @edmarferreira and on Linkedin, and Every on X at @every and on LinkedIn.\n\nWe also build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Write something great with Lex.\n\n\n\n",
      "word_count": 1717,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3295/yellowwizard.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3390/thumbnail_Screenshot_2025-01-08_at_10.19.28_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3538/thumbnail_Screenshot_2025-04-01_at_11(2).06.41_AM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "source-code"
    },
    {
      "url": "https://every.to/source-code/freeform-a-new-experiment-from-every-studio",
      "title": "Freeform: A New Experiment From Every Studio",
      "author": "Cassius Kiani",
      "author_url": "/@cassius",
      "publication_date": "January 8, 2025",
      "content": "Freeform: A New Experiment From Every Studio\n\nReflect on 2024 with our AI-powered tool for creating smarter, more adaptive forms\n\nTLDR: Today we’re sharing the latest experiment from Every Studio: Freeform, an AI-powered tool for creating smarter, more adaptive forms built by entrepreneur in residence Cassius Kiani. Try it out yourself with a 2024 reflection and let us know what you think.—Brandon Gell\n\n\n\n\n\n\n\n\n\nMy second reaction was, “Why?”\n\nFacebook grew into a trillion-dollar business because it tapped into a universal need for human connection. It wasn’t about deep technology—it was about bringing people together. Even features that faced backlash, like the News Feed, were designed to strengthen that sense of connection, making it easier to see what friends were up to in real time. Meta has some shiny new tools—AI avatars, the metaverse—but it feels like they’re searching for excuses to use them for their own sake, rather than to delight and connect real people.\n\nAn easy way to frame this situation is that they’re swapping problems for possibilities. It’s like designing a house that pushes boundaries in architecture but is only occupied by ghosts. And I say this as someone who has swapped problems for possibilities before.\n\nI worked with the team that created the first-ever decentralized autonomous organization (DAO), because I was nerd-sniped by the blockchain’s promise for decentralized governance. It felt like the future—democratic systems tied to mutual upside. But what did I learn? People didn’t want governance; they wanted accountability. When things went wrong, they didn’t want to be in charge—they wanted someone to blame. The most common question we heard was, “Who’s running this?” When the answer was, “You, the DAO holders,” the excitement faded fast.\n\n\n\n\n\nWhen you write a lot about AI like we do, it’s hard not to see opportunities. We build tools for our team to become faster and better. When they work well, we bring them to our readers, too. We have a hunch: If you like reading Every, you’ll like what we’ve made.\n\nI made similar mistakes while building a new product in legal tech. I thought inefficient law firms were desperate for innovation. But lawyers weren’t looking for ways to save time; they were looking for ways to bill for more hours. Every time we found a clever way to save them a few million dollars by reducing labor costs or reducing how long certain tasks would take, we were met with, “...and how will we bill a client for this?”\n\nI now realize there’s a gap between what people say, what they do, and what they want. And maybe this is where Meta’s AI avatars will prove me wrong—because quite often, you have to build before you really learn what people want.\n\nI learned this lesson most clearly while working in healthcare. Patients, I discovered, often just want to feel heard. Sometimes, that feeling is more important than the treatment itself. When patients felt heard, they were more likely to stick to their treatment plans, which led to better outcomes.\n\nOne of the ways we worked to improve communication was by rethinking patient forms. Traditional forms frustrate everyone. Patients have no idea what they’re being asked or how the information is relevant to their treatments. Doctors often feel that patients don’t give enough information or misinterpret the intent behind the question. The result? Insufficient information, misaligned care, and less trust in treatment plans.\n\nThere was a tension that AI could help resolve—not by automating for the sake of it, but by improving the experience for both patients and doctors. Imagine forms that adapt in real time, asking smarter questions based on a patient’s answers. Patients would feel understood, doctors would get actionable insights, and both sides would win.\n\nMy hunch is that this communication gap exists across forms in general. In most contexts, forms are critical connection points between people and systems, yet they’re often static and impersonal. We design forms like we design crockery: We assume it’s fine for it all to be the same. But really, forms should be more like meaningful conversations, rather than watching a recorded lecture.\n\nThat’s why I’m working on Freeform, an AI-powered tool I’m building to experiment with creating adaptive, dynamic forms. No two Freeforms will ever be the same. The questions adapt in real time based on your answers, diving deeper into interesting insights or stepping back when engagement fades. It’s more like a great conversation—guided by structure but full of unexpected turns, where everyone comes out better for it.\n\nFreeform is my attempt to focus on problems rather than possibilities. If it works, it could be a blueprint for better tools that help people better connect with systems (and each other). But as always, I’ll only know if I’ve found a real problem once it’s out into the real world.\n\nIf you’re curious, give Freeform a spin with our Every Archetype experiment, which will guide you through a reflection of 2024 to discover your archetype for the year. It’ll help me learn whether this is something other people actually want, or just another shiny distraction.\n\nParting wisdom? Solve problems rather than possibilities. Get that right, and tools will follow.\n\n\n\n\n\n\n\n\n\nThanks to Katie Parrott for editorial support.\n\nCassius Kiani is an entrepreneur in residence at Every. He cofounded the nonprofit Pledges and health tech company Mora Medical.\n\nTo read more essays like this, subscribe to Every, and follow us on X at @every and on LinkedIn.\n\nWe also build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Write something great with Lex.\n\nGet paid for sharing Every with your friends. Join our referral program.\n\n\n\n",
      "word_count": 942,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3390/Screenshot_2025-01-08_at_10.19.28_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3538/thumbnail_Screenshot_2025-04-01_at_11(2).06.41_AM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "source-code"
    },
    {
      "url": "https://every.to/the-crazy-ones/the-secret-father-of-modern-computing",
      "title": "The Secret Father of Modern Computing",
      "author": "Gareth Edwards",
      "author_url": "/@gareth_9984",
      "publication_date": "December 15, 2023",
      "content": "The Secret Father of Modern Computing\n\nHow Ed Roberts created the personal computer industry—and then walked away\n\nWe’re in the midst of the biggest paradigm shift in technology since the internet and the personal computer. If you want to understand what’s going to happen with AI, you have to understand how previous technology shifts played out—because history repeats itself. That’s why we’re publishing this original essay by digital strategist and historian Gareth Edwards on the secret history of the first PC revolution. It's a long read with which to settle into the weekend. We hope it sheds light on the past—and on the future. We’d like to publish more of these pieces by Gareth, so if you like it, please let us know. —Dan\n\n\n\n\n\nIn September 1974, Ed Roberts was sitting at the bank in a foreclosure meeting. His once-profitable calculator company, Micro Instrument and Telemetry Systems (MITS), had exhausted its $250,000 overdraft and was on the verge of bankruptcy. But Roberts wasn’t getting ready to shut down. Instead, he was soliciting a $65,000 loan. Not to spend on calculators, he explained to the bank, but for something completely different. Something nobody had done before. He planned to build an affordable personal computer.\n\nThe bankers were dubious. Everyone knew that computers were large and expensive, the domain of big business. “The banker asked me, ‘Well, how many of these do you think you'll sell?'” Roberts remembered later.\n\nIt was a question that he’d hoped they wouldn’t ask because Roberts had no answer. He had decided to pivot his entire company on a personal hunch: that he could sell a large number of low-cost computers in a market where most companies expected to sell four or five expensive ones every year. “I said, ‘I think we'll sell seven or 800 of them over the next year.’ [The banker] laughed at me, accused me of being a wide-eyed optimist and all that.\"\n\nFor a second, Roberts thought that this was the end of MITS. Instead, the banker sighed and signed off on the loan. He explained that he saw little value in foreclosing now. If, somehow, Roberts managed to sell even 200 of these machines, it would yield the bank some return.\n\nRoberts went away surprised, but happy. This didn’t mean he wasn’t worried. His business depended on him being right about two things everyone insisted were wrong: that you could create a useful computer for less than $400, and that there were people who would buy it.\n\nBut Roberts had conviction. \"Here’s the thing that’s so hard for people to understand now,” he said. “Those of us who wanted computers lusted after computers. That's the only way to describe it. The idea of possessing your own computer... I mean... wow. There were only one or two things more exciting about that. And I'm not even sure about them!\"\n\nWe often picture tech disruptors as brash, dynamic figures who are keen to be both seen and heard. Yet the personal computing industry was largely sparked by a straight-talking ex-Air Force officer—one more Ron Swanson than Elon Musk. He ignored claims by IBM and others that people didn’t want a computer at home, and risked his whole company on a hunch that they were wrong. His approach to business was different from the “move fast and break things” model we’ve come to expect from tech entrepreneurs, yet he succeeded beyond all expectations because of it.\n\nThis is the story of Ed Roberts, the man who created the personal computer, launched the careers of Bill Gates and Steve Wozniak, and decided—at the height of his success—to walk away. It is based on archival video interviews with Roberts, Gates, Steve Wozniak, and many of the other key figures involved. I also draw on written accounts by Forrest Mims, Paul Allen, and others who were there; contemporary publications, such as Dr. Dobbs Journal and Popular Electronics; and books like Fire in the Valley and Endless Loop: A History of Basic.\n\nRoberts had started to act on his hunch about personal computers long before meeting with the bank. As early as 1972, as the power of microprocessor chips was increasing and their prices were dropping, he sensed that there was an opportunity to produce a mass-market computer. He also understood that the electronic calculator market in which MITS had enjoyed great success was about to implode.\n\nLike most of the firms that had ridden the calculator boom, MITS made very few parts itself. The company designed the boards, selected the chips, sourced the parts, and (for an additional fee) would even assemble your calculator for you. However, as demand grew, chip manufacturers started entering the market, and companies like Texas Instruments began to sell directly to customers. They could offer cheaper products than third-party assemblers like MITS. Almost overnight, Roberts’s profit margins disappeared.\n\nRoberts wanted to exit the calculator market entirely—and he had experience making bold decisions. Initially, MITS made electronic telemetry systems for model rockets—hence, its full name, Micro Instrument and Telemetry System, which was cleverly selected to create a mental association with MIT, the university. After several years catering to rocket enthusiasts, Roberts had sensed that the market for electronic calculators was about to explode. When his founding partners in MITS proved reluctant to pivot, Roberts offered to buy them out. After they accepted, he took the company successfully into the calculator market. As far as he was concerned, pivoting to affordable computers was a natural progression from pivoting to affordable calculators.\n\n\"I know now that I'm onto something good when everyone else thinks it’s a bad idea,” he said. “I just didn't figure that out until later.\"\n\nRoberts’s interest in computers was different from most of the customers who would eventually buy his machine. He was a realist—fascinated by what they could do now, rather than the future they represented. In fact, he had always wanted to become a doctor, but he grew up in a relatively low-income family, so he had to find a way to pay for college. He chose to study electrical engineering and committed to a period of service afterward with the U.S. Air Force (USAAF), which ensured that his tuition would be covered. After graduation, he joined the USAAF Weapons Lab at Kirkland Air Force Base near Albuquerque. Some years later, he created MITs along with other Air Force personnel.\n\nAt college and Kirkland, Roberts had encountered some of the most powerful computers then available. He was fascinated by computers—how they could democratize power, and who they could offer that power to.\n\n“To some extent, your worth has always been measured by the number of people you control—the number of people you ‘own,’ so to speak,” Roberts explained. “In the case of the computer, one person can do the work of thousands. So by any historical definition, if you have a computer, you’re wealthy. I mean, wealthy beyond all imagination. That’s always intrigued me about computers. The enormous amount of power it gives us regular folks.”\n\nIn his quest to pivot MITS to computers, Roberts found an ally in Bill Yates, an Air Force veteran who’d worked alongside Roberts at Kirkland. Yates was a talented electrical engineer. When Roberts had needed to buy out his MITS co-founders, Yates stepped in to help. He partially funded the purchase in return for a share of the company.\n\nRoberts and Yates watched as the microprocessor market developed. At the time, the processing power of most available chips was low, which limited their potential usefulness for real-world applications. The National Semiconductor IMP-8 and IMP-16 microprocessors required extra hardware to run, rendering them unusable on a cost basis. Another possibility was the Intel 4004 or 8008 chips. However, the duo soon realized that they weren’t powerful enough to create a fully programmable machine. There were rumors that Motorola was working on a solid microprocessor, but that’s all they were—rumors.\n\nBy the beginning of 1974, both men knew the window to save MITS was shrinking. The company was in the red and was down to fewer than 20 employees. It was then that they enjoyed a moment of luck.\n\nRoberts had cultivated a strong relationship with Intel, from which he regularly sourced calculator chips. He mentioned to MITS’s Intel rep that they were hunting for a microprocessor with which to build a home computer. The rep took Roberts and Yates into his confidence and confessed that Intel had an unannounced microprocessor that was almost ready—the Intel 8080, which was a major improvement on the 8008. He suggested that it might be powerful enough to meet their needs. He also secured them early access to the 8080’s data schematics, as well as some samples. Roberts and Yates immediately recognized that the 8080 was exactly what they had been searching for.\n\nRoberts’s straight-talking approach with his suppliers and financial backers occasionally created problems for MITS in the cut-throat calculator market, where overpromising and under-delivering were routine. But it also resulted in a level of trust with MITS’s partners that few other companies enjoyed. This had already landed the company early access to Intel’s new chip. Now it proved its worth financially as well. Intel planned to sell the 8080 microprocessor for $360 a unit. It cost the company barely a fifth of that to manufacture them, but it correctly believed that the majority of its customers—computer firms manufacturing machines that cost tens of thousands of dollars—would pay the high price.\n\nRoberts, however, was a veteran of the brutal price wars over calculator chips. He knew that Intel’s sales team liked the security that bulk orders offered them, so he took a gamble. He told Intel that MITS was prepared to order 8080 microprocessors in batches of 1,000, at a minimum. In return, he wanted a massive discount. Intel agreed to a much lower price of $70.\n\nThis deal was a game changer. It made MITS’s plans to sell a personal computer that retailed below $400 viable—an impossibility if $360 of that budget went to the microprocessor. Armed with the new deal, Yates began designing circuit boards for a computer based on the 8080, while Roberts created the logic interface—or series of instructions—that would allow their new microprocessor to work with up to 256 bytes of memory and a 2MHZ clock. (This may not seem like much now, but it would make the machine almost as powerful as the computer that had landed Apollo 11’s astronauts on the moon a decade earlier.) It was enough that a home user with enough time and creativity could program the machine to do genuinely useful things.\n\nDuring the design process, Roberts realized that customers might come up with ways to use the new computer that he hadn’t considered. In what would prove to be a revolutionary decision, he built sockets that would allow peripheral cards to expand the machine’s capabilities. In doing so, he created the open architecture philosophy on top of which much of the computer industry innovated.\n\nBy June 1974, with the last of its cash reserves almost exhausted, MITS was close to having a workable computer. But the company had not yet worked out how to let its potential buyers know it existed.\n\nOne day in July, Roberts got a phone call. “Ed! It’s Les Solomon,” came a cheerful voice. “You’ve still got that 8080 project going on, right?”\n\n“We do.”\n\n“Great. Then I’m coming to Albuquerque.”\n\nThroughout the seventies, two electronics magazines were waging a war for readers: Popular Electronics and Radio-Electronics.\n\nLes Solomon was the technical editor at Popular Electronics. He’d first met Roberts in the summer of 1970. Forrest Mims, an ex-Air Force engineer, had been writing for the magazine under Solomon. One day, while Solomon was visiting Mims in Albuquerque, Mims insisted that he meet a local friend—Mims’s former business partner.\n\nSolomon found himself in a steakhouse later that night with a tall, broad-shouldered man with a military air. This was Ed Roberts—it turned out that Mims was one of the original co-founders of MITS. “Ed had this idea about offering an electronic calculator kit,” Solomon later recalled, “And, well, I had to listen since he stands over six feet and weighs 235 pounds or so!”\n\nSolomon thought that the idea was a good one. Popular Electronics would run a cover story on the calculator. In return, Roberts would write an assembly guide exclusively for the magazine. The feature was a hit with readers. Roberts became someone Solomon could turn to if he needed an expert in a hurry, and he spent the next few years writing for Solomon whenever the need arose.\n\nIn the spring of 1974, Solomon and Art Salsberg, Popular Electronics’s editor in chief, became convinced that they needed to feature a computer on the cover to boost sales over their rivals at Radio-Electronics. Solomon started looking for projects that might fit the bill. He learned that Roberts was working on an 8080 microprocessor machine. The idea sounded promising, but MITS didn’t have a working prototype yet. Instead, Solomon turned to Jerry Ogden, another contributor who had created a machine using Intel’s existing 8008 chip. It was simpler than Roberts’s idea, but it already existed.\n\nIn July 1974, as Solomon was working with Ogden on the Popular Electronics piece, the latest issue of Radio-Electronics hit newsstands. Its cover featured an 8008 machine called the Mark-8. It was too simple to qualify as a computer, but it was easily a match for Ogden’s machine. Popular Electronics had been beaten to the punch. “I felt as though the rug was pulled out from under me,” Salsberg later wrote.\n\nHe called Solomon into his office and asked if he knew of anyone working on something better, ideally using the 8080 chip. Solomon mentioned Roberts. Salsberg said that if Roberts could get them a machine and article by December, he would turn over the magazine’s January 1975 cover to this new computer. This was a big offer—the January issue was the best-selling issue each year.\n\n“Tell him that he’s got to have an attractive cabinet in order for it to be a cover story,” Salsberg shouted after Solomon. Salsberg knew that the machine needed to look as good as it sounded, so it needed an impressive case. Solomon went to call Roberts to give him the news. He told him that as long as MITS could get a working version of its machine to the Popular Electronics offices in New York by the end of October, the cover would be theirs. Roberts agreed to the deal. The race to create a working machine was on.\n\nIn October 1974, Roberts, Yates, and Jim Bybee—one of the dwindling number of staff still at MITS—finished the prototype for the world’s first personal computer. Roberts, never one to worry about names for his machines, christened it the PE-8. The company was running on fumes, propped up by the emergency loan from the bank. Roberts didn’t care. They had hit Art Salsberg’s deadline. Now, all they had to do was get the PE-8 to New York so Salsberg and Solomon could see that it existed.\n\n“We were gonna die if this article didn’t go. We were dead,” Roberts recalled later. “So I sent it by Railway Express/Air Express, which was a sort of UPS of the time. I figured that would be the safest way. Even sent it Priority… I got on a plane to get out there, after we’d loaded it up… guess what day Railway Express decided to go bankrupt?”\n\nWhile Railway Express had yet to go bankrupt, a series of strikes erupted in October 1974 that brought shipping to a standstill. Upon arrival at John F. Kennedy International Airport, Roberts discovered, to his horror, that his only working computer was lost in that chaos. “I figured we were dead now,” he said.\n\nStill, Roberts went to his meeting with Salsberg and Solomon. He had the schematics and functional diagrams in his luggage. All he could hope to do was persuade the magazine’s editors that MITS wasn’t bluffing, and that Popular Electronics should stake its reputation on a machine its editors had never seen.\n\nTo his surprise, they agreed. “I think they trusted that we had done enough projects together,” Roberts said later, still with a hint of astonishment in his voice. “And because we’d always done what we’d said we do, they trusted us. They said ‘Okay. If you can send us something we can photograph, we can go with that.’”\n\nWhen Roberts returned to Albuquerque, he got another phone call from Solomon. This time it was about the name. PE-8 just didn’t sound very exciting. Would MITS consider calling it something else?\n\n“I don’t care what you call it,” Roberts told him bluntly. “But if we don’t sell 200, we’re doomed.”\n\nSolomon suggested “Altair,” a word his daughter had heard during an episode of Star Trek. Roberts agreed. MITS pulled together a dummy case, rebranded it Altair 8800, and shipped it to New York for a photo shoot. Luckily, this one arrived.\n\n“It was an empty box,” Roberts told an interviewer later, laughing. “The lights came on, but that was about it.”\n\nEven before the story was published, Roberts began to suspect that they might be onto something with the Altair.\n\nIn November, a man named Roger Melen visited MITS offices. He came from Stanford University and begged to be sold a machine. He’d been in New York to submit a story to Solomon on a prototype digital camera, and had seen the Altair mockup in the Popular Electronics office. Rather than fly back to California, he’d decided to come straight to Albuquerque. Roberts agreed to ship Melen the first production machine: it would be the third off the production line after the now-lost test machine and the one MITS was keeping for itself.\n\nRoberts’s empty box had already started to change the world.\n\nThe January 1975 issue of Popular Electronics was published in December 1974. On the cover was the dummy Altair 8800, alongside the headline: “World’s First Minicomputer Kit to Rival Commercial Models.”\n\nWithin minutes of hitting newsstands, the phones at MITS were ringing. “And by the second week in January,” Roberts said, “we were already taking 200 orders a day.”\n\nAt the time, Bill Gates and Paul Allen were studying at Harvard University. In their spare time, they were trying to get a company known as “MicroSoft” off the ground.\n\n“We were walking through Harvard Square, and saw this Popular Electronics magazine,” Bill Gates said. “And here was someone making this computer around the 8080 chip, in exactly the way Paul had talked to me about. And it was happening without us… we wrote to this company immediately and offered to do [programming language] BASIC for them.”\n\nTheir timing was fortuitous. If the computer was to be truly useful, it needed a human-readable programming language that ran on it, not just raw, binary computer code. Yates, who had highly technical users in mind, had been trying to convince Roberts that a sophisticated scientific or mathematical programming language would be best for the Altair. Roberts disagreed. He wanted something that anyone could use.\n\nBASIC fit that bill perfectly. It lacked some of the high-end functionality of its rivals, but this was deliberate—BASIC was created in 1963 for non-technical users. By making BASIC the language of the Altair, Roberts could stay true to the idea that the machine was one designed for “regular folks.”\n\nRoberts and Allen spoke over the phone. Roberts told the young software engineer that many people had promised him a version of BASIC for the 8080 chip, but nobody had shown him something that worked. The first person to do so would get the job.\n\nA month later, Allen landed in Albuquerque, wearing a borrowed suit and clutching a paper copy of the code necessary to run BASIC on the Altair. Allen and Gates had written it in a flurry. Allen called MITS and told a surprised Roberts he was there. Roberts drove to the airport himself to pick Allen up.\n\nContrary to popular belief (and even Microsoft’s official history), the version of Altair BASIC that Gates and Allen created did not run perfectly the first time. When it reached the command prompt, the program crashed. Allen was horrified. He thought they’d blown their chance. He called Gates, and they debugged it over the phone. Allen asked Roberts for one more shot. Gates was already rewriting the code, which would be rushed by priority mail to Albuquerque.\n\nRoberts agreed. Because it was already late, he drove a protesting Allen to a nearby hotel. It was there that the developer confessed he didn’t have enough money for a room. Amused, Roberts handed Allen his own credit card and said he’d retrieve it the next day. Although Allen and Gates didn’t know it, they’d already impressed Roberts by getting as far as they had, and he had already decided to offer them jobs. When their code ran without error the next day, that only confirmed his decision. Within weeks, Allen was MITS’s new director of software. Gates dropped out of Harvard later that year and joined MITS, writing new versions of BASIC and other software for the Altair.\n\nGates and Allen weren’t the only ones inspired by the Altair. In California, the Popular Electronics story spurred Gordon French and Fred Moore to found the Homebrew Computer Club—a regular meetup in which professionals and amateurs could share their knowledge of computers.\n\nThirty-two people turned up at the first meeting in March 1975, which took place in French’s garage. Half worked in mainframe computers, several were from university departments, and a smattering were musicians, engineers, and other dreamers who thought that they would never get another chance to play around with a proper computer after graduating from college—let alone own one.\n\nAnd there, on the table in the middle of the garage, was an incredible sight—one of the only Altair 8800s in existence at the time, the Altair #3. It had been shipped to Homebrew Computer Club member Roger Melen.\n\nSeeing the Altair was a near-religious experience for one of the attendees. “It was that day, the first day of Homebrew Computer Club, that I realized, finally, I can have the computer I wanted,” a young engineer named Steve Wozniak remembered. “I was too scared to say anything. I’d been spending my time designing calculators for Hewlett-Packard. I’d gotten out of computers. But they gave me a datasheet. They passed out datasheets! I took it home and said, ‘Oh my gosh, this is like the computers I used to design back in high school!’ So I was back in business.”\n\nWozniak, inspired and empowered by the Altair, created the first Apple computer later that year. After meeting fellow enthusiast Steve Jobs at the Homebrew Computer Club, they decided to go into business together.\n\nRoberts had hoped his computer would sell well, but the demand was well beyond anything he could have predicted. The sheer variety of uses caught him by surprise.\n\n“The very first call I ever took for an Altair was from a dentist in Chicago,” Roberts later said. “He was president of a model train club. They wanted to use an Altair to control their model train layout.”\n\nBy the end of February 1975, two and a half months after launch, MITS had gone from having a $250,000 overdraft to more than $250,000 in the bank. By August, the company had shipped over 5,000 machines—and that was barely making a dent in its outstanding orders. Roberts’s hunch had been correct. The result was an entirely new industry: personal computing.\n\nIn 1977, with MITS registering sales upwards of $6 million (roughly $32 million today), Ed Roberts sold MITS to a microchip and motherboard supplier called Pertec Computer Corporation. And then he walked away.\n\n“[Ed] was utterly confident his entrepreneurial gifts would allow him to fulfill his ambitions of earning $1 million, learning to fly, owning his own airplane, living on a farm, and completing medical school,” Forrest Mims remembered when describing his good friend later.\n\nRoberts had achieved the first three. Now, the thought of finally mastering the last two—owning a farm and securing a medical degree—had entered his mind. And because he’d come within a few weeks of losing everything, he knew the importance of cashing out while the going was good. On top of this, the personal computer industry he had created was changing—and he wasn’t sure he fit in.\n\nIn style and personality, Ed Roberts was different from the other figures at the forefront of the computing revolution. He was a gruff ex-Air Force officer with a strong sense of honesty and honor, and he wasn’t fond of excess or the limelight. When he picked up Paul Allen at the airport, it hadn’t been in a fancy car or slick suit. Roberts had been in his pickup truck wearing a plain shirt and tie.\n\nEven in 1977, Roberts could read the writing on the wall. The moment he’d proven that there was a demand for personal computers, big personalities and big-money businesses started to move in. He’d already sold a controlling interest in MITS to Pertec at the end of 1976, agreeing to stay on to run its special projects division. In this role, he saw Paul Allen and Bill Gates move to secure the IP rights for the Altair version of BASIC from under the company, claiming they had always belonged to Microsoft. Roberts believed that this was dishonest and a fundamental breach of trust. He knew what he’d paid for and signed off on, and this soured the relationship between him and his former proteges for years to come.\n\nIn late 1977, Roberts revealed the new product his division had been working on to the Pertec-run MITS management: a computer that wasn’t only portable but could be used on your lap. Roberts had another hunch, one that said portable computers was another market waiting to explode. The new management told Roberts that there was no interest in a lap computer, and that there never would be. They declined to pursue it.\n\n“I guess consider this my resignation then,” he told them, walking out of the door at MITS and away from a role at the forefront of the industry he had created forever.\n\nIn early 2010, hospital staff in Macon, Georgia were stunned when a man recognizable across the globe walked into their hospital.\n\nIt was Bill Gates.\n\nGates asked to be pointed in the direction of a specific patient, one best known in Georgia as a beloved rural doctor. One who never turned away a patient, even when he knew they couldn’t pay, and who’d treated AIDS patients for decades, even when fear and prejudice had seen other practices close their doors. He was a doctor who had been elected to medical honors society Alpha Omega Alpha in recognition of his contribution to rural medicine. At 68, he was losing a battle with pneumonia, one that would soon take his life.\n\nThe man was Dr. Henry “Ed” Roberts.\n\nAfter walking away from the industry he helped create, Roberts moved to Georgia and returned to college. He studied to become the doctor he’d always wanted to be. He never hid his past in computers. In his medical office, there were two Altairs proudly on display. If asked, he’d talk about the role he’d played in creating them. He continued to dabble in computer programming and system design on the side. However, most people in his hometown of Cochran, Georgia only knew him as a doctor.\n\nSome years before, he and Paul Allen had resolved their differences. Allen had even arranged for Roberts to be interviewed as part of a computer history project for high school students. He felt there were few better examples of computing pioneer role models.\n\nMany of the quotes in this piece come from those interviews, in which Roberts was his usual, candid self. He was asked what advice he would give to teenagers who hoped to make their way in business and technology.\n\n“The most important thing is to be honorable, and kind of work from there,” he replied. He spoke about the various times MITS had come close to failure, only to be saved by the blind trust placed in him by others. “If you have integrity, that makes up for a lot of things. A lot of inadequacies. I never lied to anyone. I always told them exactly what the situation was and what we could do to get out of it. That’s true for life in general as well. Don’t lie to yourself.”\n\nBill Gates’s relationship with Ed Roberts remained cold for some time. Roberts always believed Gates had betrayed his trust when it came to the ownership of Altair BASIC. He also felt Gates had lied on the stand during the IP dispute over it, and had acted in a way that didn’t conform to his principles on how business should be done.\n\nBut Gates had heard from their mutual associates that Roberts was seriously ill. This was likely the last opportunity they’d have to talk. So he’d hurried to Georgia to visit his old boss one last time. We’ll never know what words, if any, passed between them—whether a final rapprochement was reached between the honorable old engineer who had created an industry and the brash, young software developer who went on to conquer it.\n\nAsked once about his legacy, Roberts said he had a hunch that neither he—nor the Altair—would be remembered in the end, and that he was fine with that. The people who he felt mattered knew what they’d achieved.\n\n“I guess it will be interesting to see what the history books say,” he said. “But I think a lot of what we did with the Altair will be lost. Because that was a giant step to go from nothing to the Altair. And after that, well… when you get something to work from, it all seems a lot easier.”\n\nEd Roberts died on April 1, 2010. Outside of the technical press, the death of the man once known as the father of modern computing passed mostly unnoticed. The media at the time was talking excitedly about the launch of Microsoft Windows Vista and the new MacBook Pro.\n\nRoberts’s final hunch was right. The world had moved on.\n\n\n\n\n\nGareth Edwards is a digital strategist, writer, and historian. He has worked for startups and corporations in both the UK and U.S. He is an avid collector of old computers, rare books and interviews, and abandoned cats. Follow him on X, Mastodon, and BlueSky.",
      "word_count": 5105,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/2904/fatherpc.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3479/thumbnail_Screenshot_2025-03-06_at_8.56.44_PM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "the-crazy-ones"
    },
    {
      "url": "https://every.to/the-crazy-ones/the-woman-that-tech-history-forgot",
      "title": "She Built a Microcomputer Empire From Her Suburban Home",
      "author": "Gareth Edwards",
      "author_url": "/@gareth_9984",
      "publication_date": "April 8, 2024",
      "content": "She Built a Microcomputer Empire From Her Suburban Home\n\nThe untold story of Lore Harp McGovern\n\nIf history is written by the victors, Lore Harp McGovern should have volumes devoted to her contributions to the personal computing industry. In the mid-1970s, from her suburban California home, Harp McGovern—a housewife and mother of two—began assembling memory boards and other computer expansions to sell to the growing hobbyist and business markets. With her friend Carole Ely, she grew their company, Vector Graphic, into a major manufacturer of microcomputers, eventually taking it public before Big Blue—IBM—muscled into the market. In the latest installment of his column The Crazy Ones, Gareth Edwards tells the untold story of one of the last remaining original founders of Silicon Valley.—Kate Lee\n\n\n\n\n\nTucking her short brown hair behind her ears, the same young woman straightens her suit and walks confidently up onto the stage. A murmur of surprise spreads across the room, which soon gives way to polite applause. She nods in acknowledgement, her eyes scanning the audience, searching.\n\n“My name is Lore Harp, CEO and founder of Vector Graphic,” she says, her accent a mix of German and Californian. She locks eyes with the investor who asked her to refill his cup. “Sir, do you need me to get you any more coffee?”\n\nThe crowd looks at the embarrassed investor. He shakes his head.\n\n“Good,” Lore Harp says with a thin smile. “Let’s continue, then, shall we?”\n\nThis is the story of Lore Harp McGovern, founder of Vector Graphic. With her friend Carole Ely, she launched a multimillion-dollar computer company from her suburban home and became one of the most important founders of the microcomputer age. It is based on contemporary accounts in publications such as the Harvard Business Review, Interface Age, Kilobaud, Time, and the Los Angeles Times, as well as books such as Women, Technology and Power by Marguerite Zientara; Future Rich by Jacqueline Thompson; and The Untold Story of the Computer Revolution by G.H. Stine. It is also based on the words of Lore Harp McGovern herself.\n\nLike many of Silicon Valley’s pioneers, Harp was an immigrant. Born Lore Lange-Hegermann, she grew up in Bottrop, Germany amid World War II, where she shared a bombed-out building with her parents and grandfather, Hermann Lange-Hegermann.\n\nLange-Hegermann had been a businessman and politician during the pre-war Weimar Republic, but the rise of Hitler and the war had cost him his political career and much of his business empire. He believed in the importance of a proper education for all of his children and grandchildren, regardless of gender. As a result, Lore grew up watching her aunt become a successful lawyer and her father take over what remained of her grandfather’s businesses.\n\nLore’s grandfather was her biggest influence. “I remember, as a seven-year-old, getting a little book from him,” she recalled later in an interview with the Computer History Museum. “In my child’s mind’s eye, it was gigantic. And it was a photographic book of people from all over the world in their native costumes, their traditions and all this. And I was so enthused about the book that I said, ‘I will see all these people!’”\n\n“You can do anything you want,” her grandfather responded.\n\nWhat her family hadn’t entirely grasped was just how determined Lore was to achieve this goal. Smart and observant, it hadn’t taken long for her to spot that reality didn’t always match the ideal. Her mother was a talented photographer and had studied the subject in college, but society expected her to become a housewife, which she did. So while Lore studied hard, she also watched for an opportunity to do something different. In February 1964, one of her friends pulled out of a planned six-month exchange visit with an American family. It was the opportunity Lore had been waiting for. She went instead.\n\nOn February 8, 1964, Lore Lange-Hegermann arrived in Santa Cruz, California. She was 19 years old and had promised her family that she would only stay for six months.\n\nSix months later, to her parents’ surprise and disappointment, Lore sold her return ticket to West Germany and hitchhiked to Mexico. After that, she headed to San Francisco. When her tourist visa expired, she became undocumented, unable to officially work. She crashed in a shared house with four other women and took off-the-books jobs to pay rent and survive, while immersing herself in the growing sixties counterculture.\n\nDuring this time, she met Bob Harp. Bob was a young computing researcher and engineer whose talents had secured him a well-paid role at a prestigious research institute in Germany. On his return to the U.S., his path crossed with Lore’s. She was attending a friend’s party when a British sports car roared up outside. It was Bob.\n\nBob was as outgoing as he was brilliant, and the two soon fell into conversation. The fact that Bob had broader horizons than most of his peers and spoke fluent German, thanks to his time in Europe, also helped. He made an instant impression on Lore, and she on him. It wasn’t long before they began dating and fell in love. When he was offered a research job at the California Institute of Technology, she agreed to go with him. For the next year, the pair enjoyed living a bohemian life in Los Angeles, until the inevitable happened—immigration services caught up with Lore. Threatened with deportation and summoned to an interview, the couple hatched a plan.\n\n“I put on my little black shift dress,” Lore later said. “My hair was down. I put it in a big bun. I put on my pearl necklace, my father’s gold bracelet, my grandmother’s ring. I sat there like Miss Prim and Proper. And we said, ‘Oh, we just got engaged, and we’re getting married.’”\n\nAnd they did. Lore Lange-Hegermann became Lore Harp. “We found some minister in our neighborhood, and then we went to McDonald’s and had a hamburger.”\n\nWhile Bob had worked at Caltech, Lore was able to immerse herself in the flourishing local art community. But over time the gears of his career began to turn. In the early seventies, Bob was offered a better-paid aeronautical research role at Hughes Research Laboratories, which he accepted. For Harp, this meant leaving vibrant Los Angeles for a more traditional suburban life in Westlake Village, California. “We moved from there to way out in the boonies,” Harp recalled. “Westlake Village which is…oh my God.”\n\nBy 1975, this lifestyle had begun to take a toll on her mental health. Harp had stayed in America to escape a future where her only option was to be a housewife.Yet in Westlake Village, this was the only role it seemed possible for her to play. While Bob worked, she was required to manage the home and join the various women’s groups and their activities like charity fundraisers and dinner parties—obligations expected by her community and Bob’s employer. To try and prevent this from taking over her whole life, she started studying anthropology. But then she became pregnant with their first child and was forced to abandon her studies. A second—another daughter—followed two years later. When the children were three and five, Harp tried to pursue school again, this time hoping to follow in her aunt’s footsteps and become a lawyer. But law school was not friendly to young mothers.\n\n“My husband was not the kind of person who would take over half the chores while I studied, even though he was otherwise supportive,” she said. Forced to quit, Harp felt frustrated and isolated. The social activities that seemed to provide a sense of value and purpose for many of her neighbors just didn’t feel satisfying for her.\n\n“I was 32 at the time, and I felt…‘My God, suddenly I’ll be 40, the children will be gone, and where am I going to be?'”\n\nHarp first met Carole Ely while they were waiting to pick up their children from school. Ely had started a promising career as a bond trader when marriage and children intervened. Now, like Harp, she was stuck living the life of a Westlake Village housewife. She, too, felt caged.\n\nThe duo talked about starting a business together. Their first idea was a travel agency. However, the travel industry in California was one of entrenched interests—when it came to securing partnerships and permits, who you knew mattered just as much as how good your product was. Networking required membership of the kind of business and social clubs that would never allow two women like Harp and Ely to join.\n\nThen, in January 1975, Popular Electronics published a picture of the Altair 8800 on its cover. Bob Harp, like many who worked with large computers in their workplace, had never imagined that he might one day own a machine of his own. He placed an order for the Altair, which was billed as the world’s first mass-market “microcomputer.” When the machine arrived in kit form, Bob quickly assembled it and it became one of his obsessions. The Harp house was soon filled with pamphlets, newsletters, and how-to guides about microcomputers, and Bob discovered, to his delight, that the Altair’s creator Ed Roberts had built it around a principle of “open architecture” via its S-100 expansion socket. Anyone could create memory boards or peripherals that could expand the functionality of the machine . A few third-party expansions were already on the market and more were being released regularly, but Bob decided it would be more interesting (and a fun test of his skills) to design his own expansion board. Over the course of a few months, he created a board for his own use, one that would double the amount of RAM in his Altair from 4K to a mighty 8K.\n\nWhile Bob was at work, Harp would read the computing materials that littered the house. Dinner table conversations would routinely include discussion of the latest trends in technology. Through a form of osmosis, she became versed in the growing computer industry herself. “[Bob] was reading tech publications all the time, and I kind of read them as well, and looked at them, and saw what was going on,” she said.\n\nHarp decided that Bob’s 8K RAM board was the opportunity that she and Ely had been waiting for. They would make and sell them from home. In return, Bob would receive a royalty payment on every sale. She called her prospective business partner and asked her if she wanted to team up and sell memory boards.\n\n“Sure,” Ely replied. “What’s a memory board?”\n\nTwo days after that phone call, Lore Harp and Ely attended the Southern California Computer Society’s monthly show. They were there to scout out their potential market. They watched vendors try to sell bags of chips and parts for memory boards and other expansions, often with poorly composed hand-written instructions on how to build them. The whole operation seemed distinctly amateur, yet it seemed to work. Attendees would hand over bundles of money—sometimes as much as $1,000 (about $5,000 today)—in exchange for these products.\n\nTwo days later, on August 23, 1976, Vector Graphic was incorporated. Its head of marketing was Carole Ely. Lore Harp was the CEO.\n\n\n\n\n\n“It’s Lore Harp from Vector Graphic. We have a new memory board and need about 50,000 chips.”\n\nHarp was seated in the family room of her Westlake home on the phone with a sales representative at chip manufacturer AMD. The company was one of a small number of independent U.S. chip manufacturers that were prepared to supply third parties. Harp and Ely needed these chips so they could package them into kits in Harp’s house and sell them as memory board kits.\n\n“Oh!” The sales representative on the other end of the phone sounded keen. “I’d be happy to come to your office to discuss it.” Harp looked around the room and across to the kitchen beyond, where a large pot of stew was cooking on the stove.\n\n“We’d love to meet you in our office, but we’re in the middle of moving,” she replied, thinking on her feet. Harp told the representative they were in Westlake and suggested they meet at the Westlake Inn. The sales representative agreed. After calling Carole and telling her the news, Harp called Bob at work.\n\n“You’ve got to get home from Hughes,” she told him. “You’ve got to be here at a quarter to five to care for the kids. We have to go meet a guy from AMD.”\n\nThe memory of that first meeting was seared into Harp’s brain. “He had these little monogrammed cufflinks and that aftershave everybody had. Some Old Spice thing,” she remembered about the salesman later. “And he gave us this up-and-down look. I never forget this.”\n\nThe three of them sat down in the hotel’s restaurant area and tried to negotiate a deal. Harp told the man from AMD that they planned to manufacture memory boards and sell them to the growing hobbyist market. The salesman nodded along, then gave them a price. It was far too high. “He didn’t even know what an Altair was,” Harp said. As a result, he didn’t believe their assertions that there was a large enough market for their product to make a discount worthwhile. They refused AMD’s terms.\n\nNot to be deterred, Harp called Fairchild Semiconductor, another major chip manufacturer. Once again, it led to a meeting at the Westlake Inn.\n\n“You know what,” the Fairchild representative replied after Harp had explained their plan. “I’ll help you.”\n\nNow Harp took her biggest gamble. They didn’t have enough money to pre-pay for the chips, so she decided to be honest.\n\n“We will pay within 30 days because we cannot afford to prepay,” she told him. Harp knew that they’d need to sell enough boards first to cover the cost. “We promise we’ll pay in 30 days or before.”\n\nThe Fairchild man was silent. Then he laughed. “You know what? I trust you.”\n\nThey shook hands and went their separate ways. A few weeks later, there was a knock on the Harp family door. When Lore opened it, a man named Dick Kirkpatrick introduced himself. He explained that he was their Fairchild distributor and pointed to the boxes of chips in the back of his rental car. Harp helped him carry the boxes into the back bedroom that they had begun converting into an assembly space.\n\nStan Veit had just opened up his computer store one autumn morning in New York when the phone rang. It was a woman calling from California. She wanted to sell him some memory boards.\n\n“I listened because a woman selling computer equipment was indeed a novelty,” he wrote later. “After speaking with her, I found out that her name was Lore Harp.”\n\nVeit didn’t know it, but he was about to be subject to a sales pitch created by Carole Ely to make Vector stand out.\n\nHarp told Veit that the Vector boards were not only superior to anything else on the market—they were cheaper as well. She made Veit a simple offer.\n\n“She would ship me two boards, and if I liked them, I would call her and she would ship me six more and I would pay cash on delivery for the six,” Veit recalled. “If I didn’t want them I just had to send her boards back. Well, that seemed like a fair offer, so I agreed.” When the boards arrived, they were as good as Harp had claimed.\n\nVeit made the call. “Thus, I became a dealer for Vector Graphic, a company run by two women,” he wrote later.\n\nVeit wasn’t the only one. Harp and Ely systematically went through computer hobbyist magazines like Byte and Interface Age, which were full of advertisements from dealers like Veit. It was from these computer dealers that most hobbyists purchased their microcomputers and parts, so the Vector Graphic team targeted them aggressively. They would call them and pitch the same arrangement that they had offered Veit. By October 1976, orders were flooding in. Harp and Ely’s product wasn’t revolutionary, nor were their boards significantly cheaper than their rivals, but their approach to the process of sales and ordering was more professional. This also extended to the board kits themselves. The pair hadn’t forgotten the poor-quality instructions and packaging they’d seen at computer fairs when starting out. They put extra effort into making sure that the packaging for their own boards was of a high quality, providing clear instructions for assembly, and even color-coded their chips. Overall, Vector’s commitment to high standards made them stand out.\n\nBy the end of the year, they were almost overwhelmed with orders for their memory boards, with demand starting to exceed the number of kits the two women could assemble themselves at Harp’s home. They were also attracting neighborhood attention. It was hard not to. Every weekday morning, Bob Harp would depart for work and Lore would take the children to school. Shortly after, Lore would return home and Ely would knock on her door.\n\nThe rest of the day would see a steady stream of men in suits visiting the house. A short while later, they would leave. It would stop when Lore left to pick up the children and Bob got home. The men were computer parts dealers, but the neighbors didn’t know that.\n\n“I think our neighbors thought we had a brothel going,” Harp said.\n\nEventually Harp’s next-door neighbor, Jean, grew too curious to remain silent. She knocked on the door and asked what they were up to. Harp invited her in. Jean was stunned by the operation. The rear bedroom and family room of Harp’s house had been converted into a production line for memory boards and board kits. Boxes of chips and parts were stacked on the floor, while the table was covered in fruit bowls into which the correct chips for each board had been carefully sorted, ready to be packaged. In the kitchen, salesmen helped themselves to coffee while discussing orders with the women. Toward the end of the afternoon, local high school students would arrive, paid by Harp and Ely to help with packaging and distribution. Watching, Jean admitted she had never had a job, although she had always wanted one. After a brief discussion, Harp and Ely told Jean that they were expanding and offered her a job as their receptionist. She became one of their first full-time employees. Forty years later, Harp would still vividly recall the joy of giving Jean her first ever paycheck.\n\n“It…it was just great,” Harp said, a smile on her face.\n\nBy December 1976, Harp and Ely had built Vector Graphic into a million-dollar company. In 1977, Harp decided they should go one step further: They should release a desktop microcomputer themselves. This would go from a company oriented around building add-ons for other company’s machines to making machines themselves.\n\nHarp persuaded Bob to leave his job at Hughes and join Vector Graphic full time. Harp and Ely had already employed a number of engineers to design parts, but building a computer would require someone to manage them and create an overarching design. Bob possessed the right skills and vision to do this.\n\nThe type of computer the company would build was determined by a growing demand for business machines that had been identified by their dealer network. The pair had a reputation for treating the dealers that sold Vector products fairly, so they were happy to be regularly canvassed for their opinion on what products would sell. Vector had an advantage over its competitors when it came to market intelligence. Vector’s dealers reported that their clientele was expanding. The hobbyist market was still the primary driver for sales of first-generation computers like the Altair, but small-to-medium-sized businesses were becoming interested in owning a microcomputer to use for word processing, accounting, and other business-related tasks. Unlike the hobbyists, they were often leaving stores empty-handed.\n\nThis wasn’t due to fears over price—quite the opposite. These buyers were prepared to pay more than $3,000 (roughly $16,000 today) for the right machine coupled with the right hardware add-ons or business software. It was that they wanted a microcomputer that was reliable, powerful, expandable, and pre-built—unlike hobbyists, most businesses had no desire to assemble their own machines from a kit. It also wouldn’t hurt if it was something that could serve as an office centerpiece around important clients. A machine that ticked all these boxes didn’t yet exist. The market was machines like the Altair or Apple at the low end or expensive, room-sized computers by IBM or others at the high end. There was nothing in between, so Vector decided to fill that gap.\n\nAt the 1977 West Coast Computer Faire, Steve Jobs and Steve Wozniak set the home computer world abuzz with the announcement of the Apple II, a pre-built machine for home users. Just a few booths down, Lore Harp and Carole Ely did the same thing for businesses with the announcement of the Vector 1, designed by Bob Harp. In terms of CPU and RAM, it wasn’t anything special, launching with the same specifications as the Altair 8800. What differentiated it was that it could be easily expanded—well beyond the limits of the Altair. It also came pre-built.\n\n\n\n\n\n“Maybe people are really interested in having a computer that doesn't have all the switches,” Harp told an excited Personal Computing World journalist. “Maybe it’s a little beyond the hobbyist who likes to fiddle with all that and likes to see everything work.”\n\nThe Vector 1 was a no-nonsense, ready-to-use computer designed for businesses that wanted a machine that would just work. It also had style, featuring a sleek metal case with rounded corners. It was even available in four colors—burnt orange, dark green, black, and beige. “It was not Apple that did colors first,” Harp remembered later.\n\n“The folks at Vector have managed to come up with a rather slick-looking entry into the market,” Kilobaud Microcomputing wrote. “And, it’s all theirs.”\n\nOther reviews of the Vector 1 were equally impressive. So, too, were those for the Vector 2—a machine that kept to the same principles but was faster and had more RAM—that followed soon after. Together, the machines pushed Vector Graphic to the top of the second tier of microcomputer manufacturers that almost exclusively focused on business customers. Companies like Apple and Commodore could boast larger unit sales if figures for both the business and home markets were combined, but when it came to more expensive machines for medium-sized businesses, Vector was the dominant player. By 1980, it was achieving $25 million (about $95 million today) in annual sales. The company that had been started in Harp’s converted back bedroom was now a well-known brand within the computing industry.\n\nWall Street also began to notice.\n\nIt wasn’t just the functionality of Vector’s machines that impressed the business market. It was also that they reliably worked.\n\n\n\n\n\n\n\nIn customer surveys of the time, Vector Graphic consistently outperformed Apple, Commodore, Tandy, and others in terms of customer satisfaction among business users, largely due to reliability. Lore Harp had mastered running microcomputer production lines, something most other computer startups struggled with. Under her leadership, Vector rarely suffered any workforce issues, and the quality of output from the production lines themselves was high. Her success wasn’t just due to her eye for detail. It was also because she recognized that production is, fundamentally, about people.\n\nIn an era in which production-line staff was largely treated as unskilled labor and corporate benefits were reserved for the C-suite, Vector Graphic bucked the trend. When the company hit its first $1 million sales month, Harp closed the factory and took all 500 employees out to play baseball and drink beer. The company also paid well. It even had a daycare and offered home cleaning services to employees who were struggling to balance household responsibilities with their work.\n\nThese benefits did not go unnoticed in the trade and business press, nor that, as a result, Vector had a higher-than-average number of female employees. In interviews, magazines would ask if Harp’s approach was intended as some kind of feminist experiment. Alternatively, they would ask if it was evidence that female CEOs managed more emotionally than strategically—often with the implicit accusation that the company benefits were a sign of weakness. Harp’s answer was always the same: These benefits and policies were in place because they made economic sense.\n\nHarp’s philosophy was made clear when Vector went public in 1981. In the first meeting with the IPO’s prospective underwriters, she dropped a bombshell—she wanted every Vector employee to receive stock options.\n\n“That guy in assembly who puts in the last screw? If he is really mad, and he doesn’t do it properly, and Quality Assurance misses it, it’s not just the guy back there who hears about it. It’s the VP of sales,” Harp explained. “Because soon it is sales going down because suddenly you’re no longer delivering quality product. Everybody is deserving, not just those of us sitting at the front office.”\n\nShe was told it wasn’t normal. Share options for senior staff was fine, but offering them to the entire staff would harm the value of the offering.\n\nHarp wouldn’t budge. “Well, you’ve got five minutes,” she told them. “We must have a deal at the end of that time, or we walk.”\n\nThe underwriters protested again.\n\n“Okay,” Harp said calmly, looking at her watch. “Well, that’s 30 seconds gone.”\n\nAfter a frantic discussion, the underwriters agreed to find a way to make it work. In the end, Vector’s staff received stock options based on their time at the company, priced at $1 per share. When the IPO was successful, these shares increased in value by a factor of 13.\n\n“People couldn’t believe it,” Harp said later. “They were thrilled.”\n\nThe IPO also made Harp the second-ever female founder to take a company public on the Nasdaq stock exchange. Fellow Silicon Valley tech entrepreneur Sandra Kurtzig beat her by just a few days. Harp didn’t mind. Kurtzig was the founder of ASK, a software company focused on business productivity applications. As the two most prominent female founders in the industry, they had become good friends and business allies.\n\nAlthough the IPO would represent a major achievement for both Harp and Ely, running Vector was taking a toll on their marriages. Ely’s husband had tolerated her role at Vector as an outlet for her boredom, but as she continued to invest more of her time in the company, their relationship began to deteriorate. For the Harps, cracks were also appearing. Bob had also initially seen Vector as a side project for Lore Harp, and his direct involvement created further problems when the two began to hold different opinions on how the company should be run. He was resentful of the level of attention she received in the press, feeling it diminished his own role at Vector.\n\nIn the beginning, both Harp and Ely were treated as a curious novelty by the rest of Silicon Valley. Their impressive range of products allowed them access to the right circles and markets, but that often came at a price. At best, they were treated with a sort of benign paternalism by competitors that Harp was often all too happy to exploit. Often, the first time a competitor realized how ruthless she could be was when they discovered their customers were now Vector’s customers instead.\n\nDeals and product demos often took place in hotel rooms during industry shows or on sales tours. Unfortunately, Harp and Ely were often left having to deal with attempts at abuse or exploitation.\n\n“They either just loved you, or they were trying to be after you,” Harp said later. “One guy actually got slapped. I said, ‘I’m here for one purpose only.’”\n\nAs Harp climbed higher within American industry, the paradigm started to shift. Senior figures within other companies began to resent her presence at the top of the tech pyramid. What had begun as an unthreatening story of two housewives running an odd little business became one instead of two women successfully building and expanding their empire. To many, this didn’t seem possible, and articles of the time suggested that Harp’s husband Bob played a larger role than he actually did. By diminishing the role of the two women in the success of their own company, readers were reassured—whether purposely or not—that behind every successful woman, there must be a man.\n\nThis attitude wasn’t universal. There were those who saw Harp’s skills clearly for what they were. In late 1980, it was Harp—and Vector—who Adam Osborne approached while looking for a manufacturer for his revolutionary portable computer. Osborne was making the jump from writing about computers to designing them. He knew that manufacturing his new machine—the Osborne 1—would be difficult and complex, so he wanted it to be made by the best. In his mind, the best was Lore Harp. Harp was skeptical and wanted to wait until Osborne had a production prototype. Unwilling to wait, Adam Osborne pushed ahead on his own.\n\nAfter Vector went public in August 1981, the negative perception of Harp held by some executives only grew stronger. Female business icons were allowed, as long as they followed the unwritten rules and remained quiet and humble. Harp was proud of her company and her success, and was happy to call out individuals who treated her poorly, as she had done at that London meeting for Vector’s IPO.\n\nSoon, she was referred to as the “Ice Maiden” within the industry. Early in 1982, a female employee wrote to Harp, congratulating her on her success. However, the employee expressed her dismay at some of the things she would hear from male industry figures when she mentioned that she worked at Vector. She told Harp that one man had complained to her about “the awful bitch who was running the company.”\n\n“I sent a nice note back,” Harp remembered later, “and said I especially enjoyed the comment about this bitch running the company because that poor guy is either so jealous or he’s so stupid that he doesn’t have anything else to talk about, and I must be terribly important in his eyes.”\n\nLong before the phrase was coined, Lore Harp was busy living rent-free in many male executives’ heads.\n\nHarp and Ely’s success came at a cost. By the end of 1981, Carole Ely was divorced; her husband was unhappy with how much of her time was occupied by her career. Lore and Bob Harp had already effectively separated by the end of 1980, and the possibility of a divorce was even declared as a business risk in the company’s IPO documents. Any faint chance of reconciliation ended with the positive press Vector received after the company went public. Much of this focused on Harp’s leadership role and impact on the company’s success, including an interview in Time magazine. Bob, annoyed at the attention his then-wife was receiving, burned a number of copies of Inc. magazine—which had featured Harp on its cover—in front of her.\n\nOfficial divorce proceedings began not long after, eventually concluding in the summer of 1982. In the end, Harp would be divorced for only a single day. She had already begun a relationship with the man who would become her second husband—publishing mogul Pat McGovern. She became Lore Harp McGovern. They proved to be a good match, enjoying their time together but respecting each other’s boundaries. The marriage would last until McGovern’s death in 2014.\n\nAdam Osborne was not the only person in Silicon Valley impressed with what Lore Harp McGovern had built at Vector. Just before she took the company public, a man named Don Estridge led a delegation from IBM to pay her a visit. Estridge indicated that IBM was thinking about making a small move into the microcomputer market, and suggested that Vector could supply computers for IBM to badge and sell under an original equipment manufacturer (OEM) arrangement. Rather than designing and selling its own microcomputer, IBM would be happy to confine itself to purchasing stock from Vector that it would sell—with a mark-up—as IBM products.\n\n“Let me get this straight,” Harp McGovern asked him. “You are a $25 billion business. We’re a $25 million business. And you are interested in potentially buying OEM products from us? That seems like a highly unlikely proposition.”\n\nEstridge insisted it was true, and Harp McGovern played along. Estridge left with a number of Vector machines as samples. Harp McGovern was smart enough though to know what this really meant: IBM was building a microcomputer. She called an emergency meeting of her senior executives.\n\n“We have one year, if that,” she said. “The world is going to change.”\n\nVector Graphic knew that if IBM (“Big Blue” to its friends and enemies) entered the market, it would target business clients—Vector’s bread and butter. This couldn’t have come at a worse time. Bob Harp, who despite the divorce was still an intrinsic part of the company’s design team, had recently overseen two major technical missteps.\n\nVector was late in moving from machines with 8-bit processing to 16-bit, which had become the new industry standard. This left Vector—and its dealer network—selling a range of machines based on dated technology longer than other manufacturers. As a result, its customer base was slow to upgrade to new machines, choosing to wait until Vector released one based on 16-bit technology. This problem was compounded by the release of the Vector 3, its final 8-bit machine. The computer itself was as reliable as ever, but its keyboard wasn’t detachable and instead was built into the computer’s case. Users found this design uncomfortable to use and the Vector 3 became the first of the company’s machines to garner negative reviews.\n\nBecause of these mistakes, Vector failed to sufficiently expand its business before Big Blue arrived—even though Harp McGovern had correctly guessed that IBM was about to enter the game. Vector had little financial room to maneuver once the first IBM PC was released in August 1981.\n\nVector made another bad decision later that year, even after the impact of the IBM PC on the business microcomputer market became apparent: Vector continued to use the CP/M operating system rather than switch to Microsoft DOS.\n\nCP/M had been the operating system of choice within the business sector for some time. Most business software was written to work with it, which made it the obvious choice for any microcomputer manufacturer around which to build their machine. Despite this, Vector had always enjoyed a close relationship with Microsoft, which had its own aspirations to be a power player in the operating system market. Indeed, Bill Gates occasionally worked out of Harp McGovern’s office when he was in town.\n\nAs a result, Harp McGovern had the opportunity to see, sooner than most other companies, what Microsoft was adding to its own operating system in an effort to capture the market. Once the IBM PC debuted with Microsoft DOS—not CP/M—installed, building future machines around this upstart operating system began to look more attractive. It could offer more functionality, while IBM’s adoption of DOS all but guaranteed that software companies would rewrite their business software to support it. It was a switch that Harp McGovern herself was inclined to make, so she contacted Gates and negotiated a provisional contract for Vector to pivot to using DOS instead of CP/M on far sweeter terms—and at a much faster pace—than were being offered to other manufacturers.\n\n“We had an amazing relationship with Microsoft. I’d signed a contract where every update and every new system in perpetuity we would get at no increased royalty,“ she explained.\n\nThe deal was taken to the board, but the collective decision was made that it was better to stick with the known quantity that was CP/M for the in-development Vector 4. Switching would potentially mean redesigning the next line of machines. It meant re-educating their dealers and clients in the new operating system, and there was no guarantee that every piece of software they needed would be ported to it. The board, which included a number of ex-IBM employees, was also convinced that IBM would soon lose interest in the microcomputer market, leaving it entirely. If that happened, it would leave Vector alone on DOS—a precarious position to be in. In the end, the board agreed that moving to DOS was the bigger risk. This decision robbed Vector of the chance to be one of the first manufacturers to offer “IBM compatibility.” The window for survival in the post-IBM world would be narrow, and Vector had just narrowed it even further.\n\n“I would say not having forced this through to make it happen was probably a flaw on my part,” Harp McGovern reflected. “By kind of going against my instinct that this needed to happen in order to be competitive. Because IBM was lusting after our dealer network.”\n\n1982 was a tough year for Vector and the microcomputer industry in general. IBM aggressively pushed to gain market share with its PC, squeezing out many of the smaller players in this space. Harp McGovern worked hard, and successfully, to defend Vector’s share of the market in this hostile environment. Margins were squeezed, but the company’s commitment to quality and support gaveVector a fiercely loyal customer base and dealer network. Sales remained strong, and the company remained profitable. Vector seemed to have secured its niche. So at the end of 1982, Harp McGovern stepped back, relinquishing the role of CEO that she had held since founding the company in 1976. She oversaw the appointment of Fred Snow, an experienced industry hand from Honeywell, as Vector’s new CEO. Since the divorce from Bob, Harp McGovern had wanted to find more time to spend with her own children. She also wanted to fulfill the promise she had made herself as a child and travel the world in her spare time. Both Bob and Carole Ely had left the company by this point, and she decided it was her turn, too. She thought Vector no longer needed Lore Harp McGovern. She was wrong.\n\nIn 1983, the Vector board petitioned Lore Harp McGovern to retake the position of CEO. In her absence, the company had lost more ground to IBM. Countering its moves required quick, decisive action, which the new CEO was unable to provide. The company’s market share had declined precipitously, and it was losing money at an alarming rate.\n\nHarp McGovern was reluctant to step back into the fray.\n\n“I had moved up to northern California at the time,” she said later in an interview. “I’d just moved up here a few months earlier with small children, nine and eleven, right after school was out, no friendship, no circle for them.”\n\nHarp McGovern had promised to spend more time with her children. It was not a promise she was prepared to break. The board pleaded with her to return anyway, stressing that layoffs were already necessary. Without her back at the helm, they likely faced bankruptcy. Harp McGovern relented.\n\nFor almost nine months, Harp McGovern worked to save what was left of the business she and Ely had built. She oversaw a round of layoffs, which was painful for someone who believed the employees were the heart of the business. It was clear to everyone now that the future lay in IBM-compatible machines running DOS—the boat that Vector missed in 1982. Harp negotiated new investment to enable the development of IBM compatibility for the Vector 5 and beyond. . With gargantuan effort, Harp McGovern managed to drag Vector back close to profitability.\n\nThe personal toll, however, was enormous. Keeping the company alive took all of her talent, but it also took her away from her children. When she had agreed to become CEO again, it was conditioned on her not having to move back to LA. She wanted her now school-age children to have a stable home life. To achieve that, she endured multi-hour, long commutes to Vector’s headquarters in southern California.\n\n“I commuted every day to Los Angeles between here and Burbank,” she said. “I would take a 6 a.m. flight. I’d get to Burbank, have my car in the parking lot, got to the office at 8:30. And at night, I’d try to get the 6 o’clock flight back so I could have dinner with my kids a little late but still have dinner, and the next day, do the same thing again.”\n\nSoon, Harp McGovern wasn’t just fighting external battles. Friction grew with the board over where savings should be found. Where they wanted to find more cost efficiencies in staffing or production, she argued instead that they should seek new investment and expand into markets yet to be targeted by IBM. They rejected her plan to develop a new machine that would focus on networking and telecommunications, which she saw as the future of computing.\n\nIn the end, Harp McGovern was worn down. In 1984 she walked away (again) from her own company: “I finally said, ‘Guys, I’ve had it. I’m out of here.’ I dumped all my stock, had a good cry at my lawyer’s office because it was just…Oh, it was just…”\n\nHarp McGovern’s departure sealed the fate of Vector Graphic, although the company would limp on for a few more years. In October 1987 Vector Graphic finally declared bankruptcy. By that point, Harp McGovern herself had been out of the picture for three years. That didn’t stop a number of journalists from treating its failure as unspoken vindication that housewives—and Ice Maidens—lacked the mettle to succeed. The departure of Bob was often pushed as the turning point. Bob himself was often on hand to provide a useful quote in support of this idea.\n\n“They didn’t develop any successful products after I left there,” he told the Los Angeles Times in 1985 after Vector filed for Chapter 11 bankruptcy protection. “If the proper decisions had been made, it would be quite successful.”\n\nBy contrast, Harp McGovern refused to talk much about Vector for a long time after her departure. To her, Vector wasn’t just a company. It was more than that. It was something she and Ely had built from nothing into a profitable community of people.\n\nHarp McGovern had only intended her absence from the business world to be temporary. By 1987, she was back. With Vector gone, she founded (and funded) one of the first companies attempting to develop disposable urinal funnels that would allow women to urinate standing up. Then, in partnership with her husband Pat, she launched a venture capital fund. In 1994, she became one of the original “Band of Angels”—one of the first angel investor groups in California focused on technology and life sciences.\n\n“What I really enjoy is growing the company,” Harp McGovern said when asked what drove her. “Growing people within the company, accepting the challenge of being out there, competing against other companies and making an impact.”\n\nAt first, venture capital and angel investment seemed to offer those opportunities for growth, but over time she became disillusioned with this world. Many investors were happy to take her money, but they refused to accept that she might have useful advice to offer.\n\n“After I’d done Vector—building a company from totally nothing to fairly good size with an international distribution network, having gone through raising venture capital, having gone through taking the company public and that sort of thing—I felt I could make a great contribution to other young companies that wanted to start in business,” she said later. The reality was quite different. Most entrepreneurs don’t want all the help I thought I could bring.”\n\nProviding funding without hands-on advice held little interest for Harp. She eventually moved away from this industry as well.\n\nIn the end, Harp McGovern’s legacy would end up being something different. In 2000, alongside her husband Pat, she gave $350 million to endow the McGovern Institute at MIT. She played an active role in establishing it as one of the foremost research institutes into the brain in the world.\n\nOf all the figures we have explored so far in this series, and of all those we are yet to explore, Lore Harp McGovern is likely the one who has been overlooked the most. Perhaps only Harp McGovern’s friend Sandy Kurtzig runs close. While Steve Jobs and Steve Wozniak were building a computer empire in the suburbs of California, Lore Harp McGovern and Carole Ely were doing the same. As with Adam Osborne, however, the history of Silicon Valley likes to focus on its winners.\n\nBut the voices that are the most outspoken about the need for women to step up and beat men at their own game are often those that are the quietest when that actually happens. Harp McGovern didn’t just shatter Silicon Valley’s glass ceiling—the Ice Maiden (or “the awful bitch”) used its broken shards to carve out a place for herself, her company, and her employees along the way. All too often, her successes have been allocated to other people, while her failures have been attributed to her alone. For all these reasons, one of Silicon Valley’s true pioneers has been granted only a single inaccurate paragraph on Wikipedia.*\n\nIn 2016, Harp McGovern recorded an interview with the Computer History Museum. “I'm delighted to do this, mainly because there were so few women in the industry at the time,” she said, when thanked for her contribution to the museum’s archive. “And also for my grandchildren to see that their grandmother actually did things that not a lot of women did in those days.”\n\nIt’s not just Harp McGovern’s grandchildren who should be aware of her achievements. Because unlike many of those who kickstarted the golden age of computing, Lore Harp McGovern, in her late seventies, is still with us today.\n\nIf you are a young founder who finds themselves in her presence, you would do well to ask one of Silicon Valley’s last remaining original founders for her advice. If she’s prepared to offer it, then listen.\n\n\n\n\n\n*As of April 10, 2024, Lore Harp McGovern's Wikipedia page is no longer a paragraph.\n\nGareth Edwards is a digital strategist, writer, and historian. He has worked for startups and corporations in both the UK and U.S. He is an avid collector of old computers, rare books and interviews, and abandoned cats. Follow him on X, Mastodon, and BlueSky.\n\nTo read more essays like this, subscribe to Every, and follow us on X at @every and on LinkedIn.",
      "word_count": 7771,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3030/Screenshot_2024-04-08_at_9.50.35_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3479/thumbnail_Screenshot_2025-03-06_at_8.56.44_PM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "the-crazy-ones"
    },
    {
      "url": "https://every.to/the-crazy-ones/the-misfit-who-built-the-ibm-pc",
      "title": "The Misfit Who Built the IBM PC",
      "author": "Gareth Edwards",
      "author_url": "/@gareth_9984",
      "publication_date": "June 5, 2024",
      "content": "The Misfit Who Built the IBM PC\n\nDon Estridge broke all of Big Blue's rules to create the home computer. The company would never forgive him for it.\n\nWe launched our consulting arm because we were constantly hearing from readers that while they wanted to implement AI throughout their operations, product, and services, they were struggling to. We're now working with select businesses to co-innovate, research, analyze, recommend, implement, and, finally, train their organizations on AI. Interested? Contact us to start a conversation.\n\n\n\n\n\nDon Estridge literally gifted the entire personal computing market to IBM. When we first saw him in this series, he was competing with Lore Harp to build the first personal computer. We’ve seen that story from her perspective—now it's time for Estridge's. You might think that the man who ushered IBM into the PC age would have been a central figure within the company, but in reality, he worked in the relative backwater of its Boca Raton, Florida office. This is the story of how Estridge successfully navigated complicated corporate politics to build the iconic IBM PC—and his shocking betrayal. It's the latest installment of The Crazy Ones, Gareth Edwards's monthly column about the forgotten men and women who built the future of technology. Subscribe to Every so that you don't miss out.—Kate Lee\n\n\n\n\n\n\n\n\n\nIn a burnished-oak corridor outside the committee room at IBM’s headquarters in August 1980, two engineers pace nervously. Eventually, a door opens. Their boss, Bill Lowe, emerges from the board room next door. Before they can say anything, he smiles and nods. They laugh. They can’t quite believe it. It’s official. IBM is going to try and build a home computer.\n\nBill Lowe kicked off this ambitious project, but he wouldn’t be the person who would finish it. That role would fall to his successor, a humble, cowboy boot-wearing mid-level executive, out of favor and kicking his heels in the IBM corporate backwater of Boca Raton, Florida. He would take Lowe’s project forward, one nobody else in the company wanted. Just 12 months later, on August 15, 1981, a computer would launch that would change the world: the IBM PC.\n\nThis is the story of Don Estridge, the man who brought the IBM PC to market and changed business and home computing forever. In just five years he created an IBM division that almost nobody else in the company wanted to exist. By 1983, it had seized 70 percent of the microcomputer market and was valued at over $4 billion ($12 billion today). Under Estridge, IBM’s PC division sold over 1 million machines a year, making it the third largest computer manufacturer in the world on its own. This story is based on contemporary accounts in publications such as InfoWorld, PC magazine, Time, and the New York Times, as well as books such as Blue Magic by James Chposky and Ted Leonsis; Big Blues by Paul Carroll; and Fire in the Valley by Michael Swaine and Paul Frieberger.\n\nIn 1980, no one senior at IBM wanted to build a microcomputer, as home computers were often called, except its CEO Frank Cary. But one man’s will was far from enough to get things done at IBM, even if he was the CEO.\n\nIn the late seventies, IBM was vast. Known as “Big Blue” to its friends and enemies, the company had almost 350,000 employees, ran so many branches, and operated in so many markets that one commentator at the time described IBM as a country, not a company. It made mainframe and minicomputers that filled rooms—sometimes, whole buildings—and cost vast sums of money. It made business electronics, dominated the global market for typewriters, and made millions selling a wide variety of office supplies. A former employee would later describe it even more accurately: IBM didn’t stand for “International Business Machines.” It stood for “International Business Mafia.”\n\nIBM’s huge divisions, spread across the U.S. and the rest of the world, operated like a series of global mafia families. They cooperated when under threat from the outside, and occasionally fought. The heads of those corporate families would regularly come together at the company headquarters in Armonk, New York to form the Management Committee. There, under the watchful eye of IBM’s CEO, they made decisions that would shape IBM’s business empire globally.\n\nCary started at IBM in 1948. He’d been its CEO since 1972. He had helped it dominate the world of mainframe computing, selling machines that could cost tens—or even hundreds—of thousands of dollars. But he also didn’t believe that the company should rest on its laurels. The Apple II personal computer had been selling in enormous numbers since 1977. At these meetings, he had one question for IBM’s divisional capos.\n\n“Where’s my Apple?”\n\nHis divisional heads always had the same answer. Microcomputers—home computing—were a fad. They were low-cost and low-profit. Let others scrabble around in the metaphorical dirt of home computing. The real money was in the markets that IBM’s divisions already dominated—selling vast mainframes and minicomputer systems to large businesses. Cary was even told to buy Atari, which by then had established itself as America’s home video game system of choice. That’s all home computers were good for: gaming.\n\n\n\n\n\nFrank Cary in 1972. Credit: IBM.\n\nBut Cary didn’t back down. In July 1980, he finally forced a concession out of John Rogers, the head of IBM’s General Products Division (GPD). Rogers agreed to set up a project to create a prototype IBM microcomputer—as long as it didn’t come out of his budget.\n\nThe answer lay in Boca Raton, Florida. There, lurking near-forgotten in his vast empire of typewriters, photocopiers and other low-level business electronics, was the Entry Level Systems (ELS) Facility, headed up by one of Rogers’s lieutenants, Bill Lowe. It was a leaky, rundown concrete facility that existed primarily to research and prototype basic electronics. Lowe, who was one of the few microcomputer supporters at IBM, was summoned before the Management Committee in July 1980. He was assigned to “Project Chess” and told to create a prototype of a microcomputer. Lowe was given one month to do so, after suggesting to the Committee that one could be assembled from off-the-shelf parts. And he would report directly to Cary. After all, Cary was footing the bill, not Rogers.\n\nTo pull off this minor miracle of engineering, Lowe assembled a core team known as the dirty dozen (there were 13 of them in total). They were a mix of engineers and planners taken from a number of different divisions. Mostly, they were individuals who struggled to fit in with the risk-averse, rules-heavy way of working within IBM. Bill Sydnes, for example, was a talented engineer who had taken the initiative on a failing project and spun off parts of it into a success. His reward for doing so was a reprimand for going outside of IBM’s standard operating practices. Other misfits, like systems engineer Lew Eggebrecht and software engineer Jack Sam, joined for similar reasons—a chance to work on a project with few limitations.\n\nThe project seemed doomed to fail. Mainframe computers were very different from microcomputers, and nobody at IBM had any real experience with the latter. Even if suitable off-the-shelf parts could be found, there was no guarantee those parts would work well together. They’d also need to program their prototype to do something that proved it would work. The risk that problems would occur was high, and they’d been given little margin to fix those that did. But it would be a fun way to spend a month. And as most of them were out of favor within IBM, they had little to lose.\n\nTo their own surprise, after a frantic month of development, this team pulled it off. They created a machine that worked. The computer didn’t do much, but it was enough to show the Management Committee.\n\n\"The system would do two things. It would draw an absolutely beautiful picture of a nude lady, and it would show a picture of a rocket ship blasting off the screen,” Bill Sydnes confessed later. “We decided to show the Management Committee the rocket ship.\"\n\nThis demo, held in August 1980, convinced Cary and the Committee that the work should continue—for now. They told ELS to turn its prototype into a product—and to do everything else needed to take it to market.\n\nLowe was under no illusions about the difficulty of this task. He was convinced that the project was valuable, but Cary still seemed to be the only senior figure within IBM who agreed. The various division heads wanted nothing to do with the project. But as long as the cost (and any eventual blame) sat squarely on the ELS facility in Boca Raton, they didn’t feel a need to kill it. What the Committee did, instead, was impose a deadline for launch: August 1981. It was another impossibly tight deadline, just one year away.\n\nLowe headed back from the headquarters in Armonk, New York to Boca Raton with Sydnes and Eggebrecht. There, the dirty dozen began the necessary work to turn their prototype into a real machine. But Lowe, who was seen as a rising star within the company, was already being considered for a new, bigger role elsewhere in IBM. Soon his promotion to that position was confirmed.\n\nLowe believed in the project but didn’t believe he was the right person to do it. Taking it forward would require a unique set of leadership skills. It had to be led by someone who thrived on breaking the rules and who could use the ELS’s newfound position outside the regular financial and management structure to its maximum. Luckily, Lowe knew just the man within IBM for the job—Philip “Don” Estridge.\n\nDon Estridge turned 43 in August 1980. He had been an IBM man his entire professional life. He loved being able to tell people he worked there. He would tell people that his blood ran big, and it ran blue.\n\n\n\n\n\nYet in many ways, Estridge ran as counter to the grain at IBM as the rest of the dirty dozen did. Tall with a mop of well-kept hair, Estridge wore the crisp suit, shirt, and tie that was the standard uniform for an IBM executive. But he coupled that look with a pair of expensive cowboy boots that often drew frowns from more senior executives. He was a humble man who had no time for flattery and a strong distaste for corporate politics. In IBM, this made him unusual. His fellow senior executives would frequently complain that he failed to return their phone calls, and rarely agreed to join golf sessions or long lunches. And his junior staff noted that he made a deliberate effort never to sit at the head of a table. Estridge believed in collegiality, not seniority.\n\nEstridge was hugely charismatic, although his personal magnetism was drawn from a different source than that of Steve Jobs at Apple or Adam Osborne at Osborne Computing. They were men who sold their own visions. They could create “a reality distortion field” around themselves (a term coined by Apple’s Bud Tribble about Jobs). They could convince you of the value of their ideas and inspire you to give everything in their service.\n\nEstridge was the polar opposite. He listened and supported. His role was to set objectives and provide people with the resources or political cover they needed. This approach inspired a different kind of loyalty from those who worked for him, but it was just as fierce. And it delivered results.\n\nLowe had seen how effective Estridge had been on the IBM Series/1 minicomputer project. The Series/1 was intended to be flexible enough to serve a variety of big business computing needs. It would be a workhorse that businesses would buy in large numbers, making IBM healthy profits on its five-figure price tag. But its development was plagued with problems and project overruns, and the end result was criticized for being underpowered. As a result, the Series/1 project was regarded as a failure within IBM.\n\nHowever, one small part of it was successful. IBM’s sales department had secured a large contract to convert all of State Farm Insurance’s operations to run on Series/1 machines. That part of the project had been led by Don Estridge, who had managed the production of these specific machines, complete with required software. They had been delivered to State Farm on budget and on time.\n\nWhen the Series/1 project ended, Estridge found himself tied to its wider failure—and out of favor. But IBM didn’t fire people who might still be useful. It simply sidelined them. They would be sent somewhere quiet and remote in case the company decided it needed them again. So Estridge was thanked for his work and sent into the Florida wilderness, to kick his heels in the corporate backwater of Boca Raton.\n\nEstridge was a self-confessed computer nut. In his early IBM years, he had worked on radar systems for the military and software for NASA’s Apollo programme. Estridge was amazed by the Altair 8080, the world’s first home computer. He never believed that he might one day have a computer at home. And when Apple released the Apple II in 1977, Estridge bought one for himself. During the day, he would help IBM build mainframes and minicomputers. In the evenings, he would tinker with a computer of his own.\n\nWhen Estridge heard about Project Chess, he wanted in. Lowe was happy to recommend him to the Management Committee as his replacement. In the fall of 1980, Estridge took over. He brought his Apple II with him, setting it up in his office at Boca Raton. If he felt that visitors weren’t seeing the value of microcomputers, they would be subject to an extended personal demonstration of what the Apple II could do until they conceded his point.\n\nNobody at the ELS would later remember how the machine they were building acquired the nickname “Acorn,” just that it was a sideways nod to “Apple.” Whatever the name, no one outside of the department seemed to care.\n\nLowe had warned Estridge to expect this. In early September, ELS approached the management of IBM’s new assembly plant in Boulder, Colorado. The new plant was significantly under capacity, and Lowe had offered them the chance to build the Acorn. He had received a polite but firm refusal. Boulder’s senior management would rather let their plant sit idle than associate themselves with Project Chess.\n\nHowever, although IBM senior management clearly didn’t want anything to do with the Acorn, plenty of junior staff did. This would become a trend—senior management would first tell Lowe, then Estridge, to go away. Junior staff would be more interested. Those with useful skills would be lured down south to join Estridge’s ever-growing group of misfits in Entry Level Systems.\n\n“We got some excellent people out of Boulder,” Bill Sydnes confessed later.\n\nEstridge and his senior team quickly realized that the only way they could get their home computer to market was if they did everything themselves. Whenever Estridge was told that yet another IBM department or division refused to cooperate, he would fly from Florida to IBM’s corporate headquarters in Armonk, New York. There, he’d petition Frank Cary for more money or people before returning home once again. It was difficult to secure additional resources at IBM—even if upper management believed in what you were doing. Yet, to the astonishment of his senior staff, Don Estridge was almost always successful. His charisma and quiet persuasiveness got him the concessions he needed. At their height, these trips were happening two or three times a week.\n\nEstridge was lucky enough to inherit two things from Lowe: a viable design for a mass-market microcomputer and a core team of competent and enthusiastic engineers. It was Estridge, however, who realized that they should enter the small-to-medium business market, not home computing.\n\nThe design that Lowe’s team had developed was perfect for this. Nothing about their design was pioneering, but it provided enough power, at a low enough price, to run basic small business software, such as word processors and spreadsheets. Historically, IBM had ignored this market because these companies didn’t have the five- or six-figure budgets needed for mainframes or minicomputers. However, they did have enough money to buy a single machine for $5,000 dollars or less. These same business users associated IBM with good things. As the saying went, no one ever got fired for buying an IBM.\n\nHowever, to turn a profit, they would need to sell in volume, which meant making a lot of machines. Estridge’s options for manufacturing support within IBM were limited, so he took a trip to California to meet Lore Harp, CEO of Vector Graphic. Under Harp’s leadership, Vector had carved out a niche for itself making computers for the small business market. The company also had a reputation for quality that matched IBM’s. Estridge toyed with a partnership. He asked Harp to sign an NDA, and then revealed that IBM was considering a small move into this market itself. The discussion was friendly, but Harp was wary. Estridge left with five Vector microcomputers and a vague agreement that they should talk again.\n\nWhile the offer to partner had been genuine, it would never take place. Instead, Harp would find herself rushing to save her business as Estridge filled out his senior team with individuals interested in going up to the challenge of the ELS alone.\n\n\n\n\n\nWord spread quickly that Cary had given Estridge and the ELS freedom to operate outside of IBM’s byzantine structures and processes. As operations expanded rapidly in Boca Raton, it became clear that Estridge wasn’t afraid to use this authority.\n\nDan Wilkie, who came on board to lead production, experienced first hand what a difference this freedom made. With Estridge helping to cut through red tape around budgets, staffing, and processes, Wilkie created an assembly facility from scratch in about four months. The previous unofficial record for doing so at IBM stood at three years. He became one of Estridge’s most loyal and effective lieutenants.\n\n“With the PC project, I saw the whole pie for the first time,” Wilkie said later. “We saw the costs, we solved the problems ourselves. We lived with the good and the bad. It’s no exaggeration to say that I made more decisions in the first 30 days with that group than I made during my first 14 years with IBM.”\n\nAlso critical was the recruitment of H.L. Sparks, known to his friends and colleagues as “Sparky.” A born salesman and a rising star within IBM, Sparks first encountered Estridge after the Series/1 project ended. Sparks could see that Estridge was a talented manager. When the Series/1 project had shown signs of failure, others had shifted the consequences elsewhere. Sparks was impressed that Estridge had done the opposite, shielding his team from blame, even though it meant accepting corporate exile to Boca Raton for himself. Then, in December 1980, Sparks received a call from Estridge, who offered him a job.\n\n“A job doing what?” Sparks replied.\n\n“Don’t ask. It’s a really great deal. Trust me and just say yes.”\n\nSparks didn’t hesitate, abandoning 18 years of climbing the ladder the IBM way to join the project. Estridge put him in charge of marketing and distribution. There was no point in having a machine if users didn’t know about it or have a way to buy it.\n\nSparks contacted the Office Products Division (OPD) within IBM, which was responsible for selling office items—such as typewriters and photocopiers—to businesses. He’d previously worked with an advertising executive in the division named Jim D’Arezzo and had been impressed with his work. Sparks lured D’Arezzo down to Boca Raton, where he was subjected to one of Estridge’s personal Apple II demonstrations. Sparks and Estridge ran D’Arezzo through the market potential they felt the Acorn could tap into.\n\n“I saw right away that this thing was fantastic, and I knew that it was a barn-burner as one of the biggest items of all time in the IBM low-end product category,” D’Arezzo said later.\n\nHe returned to the OPD offices in New York where he met with Richard Young, the division’s president.\n\n“Dick, we need this product,” D’Arezzo insisted.\n\n“No, we don’t,” Young replied. Young didn’t like new things. And, as the capo of this particular IBM family, his word was final. Conversation over.\n\nD’Arezzo was shocked. Sparks and Estridge weren’t. While Estridge provided senior management cover, Sparks did something heretical instead. He ignored the OPD and worked with mass-market stores directly, negotiating retail partnerships for the Acorn with Sears Roebuck and ComputerLand. Both jumped at the opportunity to sell a product from IBM.\n\nSparks suggested that D’Arezzo join them in Boca Raton. Angry and astonished that his division had rejected the Acorn, D’Arezzo agreed. In January 1981, Estridge welcomed D’Arezzo to Boca Raton as the advertising lead for the Acorn. He told D’Arezzo to take a few weeks and come back with a full marketing plan and advertising campaign, which he would bring to the Management Committee for sign-off in July.\n\n“I was sitting there taking notes and so I asked what the product was going to be called when it was introduced. He said he didn’t know. I asked how the product was going to be packaged and he said, ‘Packaged?! We don’t even know what its size will be!’\n\n“About this time,” D’Arezzo continued, “I started to get a bit apprehensive and I wondered if I should go home and pack my bags and head back north.”\n\nD’Arezzo suggested they stop trying to persuade another division to handle their marketing, and work directly with an external advertising agency instead. This wasn’t how things were meant to be done within IBM, but Estridge again smoothed the way. Freed from IBM’s normally restrictive creative shackles, D’Arezzo and the agency came up with a campaign that featured Charlie Chaplin’s depiction of the Tramp in the 1915 film of the same name. In it, the Tramp is confronted by overwhelming giant machines. This was the IBM of old. Afterward, the Tramp would be shown happily using the Acorn. This was the new IBM.\n\nAs Project Chess’s misfit reputation grew, other divisions started sending their more vocal problem children Estridge’s way. One such arrival was Joyce Wren.\n\nWren worked at one of IBM’s smaller offices in Silicon Valley. She was outspoken on the subjects of sourcing external development, and IBM’s slow pace of software development and management.\n\nAt one point, needing a program written in a hurry, Wren contracted a couple of programmers directly. She paid for them to stay in a hotel for eight weeks while they wrote it. Her reward was a slap on the wrist from the IBM head office in Armonk. The division that should have gotten the work had complained.\n\nBut Estridge liked Wren’s approach. He formed a new software commissioning arm within the ELS for Wren to lead. Software was critical to the Acorn project. The biggest requirements were a spreadsheet program and a word processor. These two tools, which were popular requests when buying a computer, delivered the most value for small businesses. The makers of VisiCalc agreed to port their software to IBM’s machine, solving the first problem. A distinctly un-IBM solution was required to deal with the second. They paid the creator of EasyWriter to port his word processor from the Apple II to the new IBM machine.\n\nEasyWriter’s creator was John Draper, better known to the world as the infamous “phone phreaker” (and proto-hacker) Captain Crunch. Phone phreaking involved using tricks and tools to make free phone calls illegally. Draper achieved notoriety for being one of the best phreakers in the business. He had only just been released from prison for phreaking when he received the request to convert EasyWriter for Project Chess. He was amused to find himself contracted now to IBM, one of the most respectable (and uptight) companies in America. In Boca Raton, it was decided that it was probably best if Armonk never discovered who the writer of their flagship word processor was.\n\nThe final piece of the puzzle for Estridge’s machine was the operating system—something IBM didn’t have time to develop itself.\n\nAs with many key moments in computing history, the process that led to the adoption of MS-DOS as IBM’s main operating system is veiled in myth. The most popular telling pitches it as a straightforward battle between Bill Gates at Microsoft and Gary Kildall at software company Digital Research for the soul of the new machine—a battle Kildall lost by choosing to take a pleasure flight in his personal plane rather than meet with the men from IBM to discuss a deal.\n\nThe originator of that story is an unreliable narrator—Bill Gates himself. The reality is far more complex.\n\nAs early as September 1980, Gates was approached by Jack Sams, one of Lowe’s “dirty dozen” engineers, to provide a version of BASIC for IBM’s new machine. Sams and Gates were old school friends. Sams asked Gates for his opinion on what operating system they should use. Gates recommended that they talk to Digital Research, run by Gary Kildall and Dorothy McEwen Kildall.\n\nGates and the Kildalls had an informal agreement not to compete. Microsoft focused on programming languages like BASIC and other software, while Digital Research focused on operating systems, CP/M. Although Gary wasn’t present at the first meeting, there was no need for him to be there—Dorothy handled the business side of Digital Research.\n\nCP/M was the leading operating system for business-focused microcomputers at the time. It was regarded as the market leader in this sector, and a lot of software had been written for it already. As a result, Digital Research was in a strong negotiating position. When IBM offered $250,000 for a fixed-cost universal license to use CP/M, the Kildalls refused. Adam Osborne, the charismatic founder of Osborne Computers, had persuaded Gary to give him a license like that only a few months prior for his new microcomputer, the Osborne 1. As sales exploded, the Kildalls were filled with regret. They watched as Osborne reaped the profits due to the fixed cost they’d agreed to up front and decided they would never make the same mistake again.\n\nHowever, back in Boca Raton, the team was growing frustrated with the pace of negotiations with Digital Research. The Kildalls didn’t fully appreciate how tight deadlines were for the Acorn team. When Gates became aware of this disconnect, he sensed an opportunity. After discussing it with his leadership team at Microsoft—Steve Ballmer, Paul Allen and Kazuhiko Nishi,—the men decided it was time to unilaterally end their truce with Digital Research.\n\nGates revealed to Sams that he was aware of another operating system that could be ported to the IBM machine. Sams confirmed that IBM would be interested—but that the company had no desire to get involved in a series of backroom deals or betrayals. If Microsoft did offer them a viable alternative to CP/M, however, they would consider the offer carefully. Emboldened, Gates negotiated the purchase of the QDOS operating system from fellow Seattle software developers at SCP and renamed it MS-DOS. It was promptly offered to IBM as an alternative option to CP/M.\n\nThere would be more twists and turns—and a number of legal cases—in the MS-DOS story, but this sequence of events would cement Microsoft as Estridge’s preferred partner during the Acorn’s development and lead to MS-DOS becoming one of the dominant operating systems of the era. Unlike the Kildalls, Gates was prepared to turn over Microsoft’s entire operation in service of the Acorn ahead of launch. And that was exactly what Estridge needed.\n\nWhen the new machine was finally announced to the public it came with a choice of three operating systems: MS-DOS, CP/M, or p-System from the University of California. The choice was the result of a settlement between IBM and Digital Research, which was threatening legal action over the events that had led to the creation of MS-DOS and Microsoft’s relationship with IBM. But with MS-DOS priced at $40 in comparison to CP/M’s $240, it was clear to buyers which version of the machine Big Blue felt they should choose.\n\nBy March 1981, the hardware for the Acorn was ready to go. By June, the software and operating system were finalized. In July, Estridge received permission to take the product to market from the Management Committee. They would officially launch it in August, right on time.\n\nEstridge’s management style had delivered. He pushed his staff hard but was careful to walk the fine line between hard work and burnout.\n\nThose who worked in Boca Raton during this period remember that Estridge frowned upon late nights in the office unless they were absolutely necessary. He was a devoted family man and had been married to his college girlfriend, Mary Ann. They had four daughters, one of whom they had adopted after her parents died in a car crash while she was young. He believed that work should not come at the expense of family time.\n\nTo Mary Ann’s amusement, he would sometimes drive back to the office late at night to check that everyone had gone home. If he found people staying too late, he would demand to know why. If they needed more resources, he would try and find a way to provide them. New transfers to Boca Raton discovered that leisure time was for everyone, not just executives.\n\nHowever, as pressure to meet their launch date increased, Estridge did ask more of his senior team. Wilkie and Sparks recall informal Saturday morning conclaves in the office. It had become impossible to find uninterrupted moments to debate and address problems during the week. These unofficial get-togethers were Estridge’s answer. Attendance was not compulsory for anyone—music recitals and Little League games had priority. Nor did they have set durations. What they offered was a chance for the senior team to get together, take a breath, and work through crises.\n\nIt was perhaps at one of those sessions that they finally decided on a name. Acorn had always been a placeholder. Internally, its official designation was the IBM 5150. At some point people just started calling it the Personal Computer, “PC” for short. It was a name that seemed like a natural fit.\n\nOn August 12, 1981, IBM revealed the IBM 5150 to the press and the world. At a grand event in a New York City hotel, journalists were given the opportunity to test it out while Estridge and others stood by, available for questions. Estridge confirmed it would go on sale at Sears and ComputerLand stores from August 15 onward.\n\n\n\n\n\nThe coverage the next day was overwhelmingly positive. The machine was quick, reliable, and well built. The software was good and the price point didn’t break the bank. The press had already fallen in love with the PC, a viable contender to the Apple II for small businesses.\n\n“It appears that IBM has a better understanding of why the Apple II is successful than Apple,” the New York Times wrote on the day after its announcement.\n\nThe launch of the IBM PC changed computing. Prices started at about $1,500 for a basic model running MS-DOS (about $5,000 today). Most people opted for extras, such as a monitor or additional disk drives, that brought the price up to around $3,000. Still, the price was easily in the range of a similarly fitted-out Apple II and cheaper than a Vector. It was well within the price range of most small businesses. And IBM stood for quality and reliability. It was less risky than buying an Apple.\n\n“They didn’t know what to buy until they heard about the IBM PC,” Martin Alpert, the founder of computer hardware manufacturer Tecmar, said, “And then they figured they couldn’t go wrong because it was an IBM.”\n\nIn July 1981, when the PC was announced, Alpert sensed which way the market was likely to go. By the time it had launched, he had already started the process of pivoting Tecmar to focus entirely on the PC. It was a smart move, one made possible by a design choice led by Estridge. Estridge realized that whoever set the new computing standard would be able to dominate the market for some time to come. The easiest way to set that standard wasn’t just to sell machines; it was to let other companies sell parts, software, and even whole computers that would be compatible with your machine. Unlike all of its major rivals—including the Apple II—the IBM PC was built with an open architecture.\n\nThe PC swept all before it. Within months, demand exceeded production capacity at Boca Raton by roughly 800 percent.\n\n“We can only handle so many factors of two,” Estridge told Byte magazine shortly after launch, when asked how work was going on increasing supply. They’d had a gut feeling that their machine would sell well, but not this well.\n\nBy the end of 1981, they were shipping 13,000 machines a month out of Boca Raton. It still wasn’t enough to meet demand. By the end of 1983, they had sold 750,000 machines and controlled an estimated 70 percent of the entire home and business computing markets. If IBM had spun the ELS off into a separate business at that time, they would have been the third-largest computer manufacturer on the planet.\n\n“I think we’re in an era where the public has adopted computing the same way it adopted the automobile.” Estridge told Byte in 1983.\n\nThat same year, Time didn’t declare a “Man of the Year.” The magazine declared it a “Machine of the Year.” The PC had conquered the world.\n\n\n\n\n\n\n\n\n\nThere are few things in business that can change minds faster than profit. So it was within IBM. In less than two months, the ELS went from the ignored and unwanted child of IBM’s computing arm to its favored son.\n\nIt was a vindication for Estridge and his team. While Estridge’s management had limited the impact of burnout, getting the PC to market had taken long hours and weekend work. Many—Estridge included—had believed that they’d be able to mentally pause post-launch. Instead, they found themselves under even more pressure than before—to increase production as fast as possible and provide direct consumer support in a way that nobody at IBM had ever needed to do before.\n\nSecuring the resources to achieve these things took even more trips to Armonk. These were just as successful as before, not least because Estridge was no longer dealing with a Management Committee that viewed the IBM PC with suspicion. But more resources also meant more paperwork and more management responsibility, both for Estridge and his senior staff and engineers. People like Sydnes or Wilkie now found themselves having to rely on others to solve technical problems as their teams—and responsibilities—grew. They could no longer dive straight in and fix things themselves.\n\nIt also wasn’t long before Boca Raton was regarded as the place you needed to work if you were an ambitious IBM executive. Suddenly, everyone was a PC evangelist, including many who the original PC team knew had been actively hostile to their efforts before. One member of the original “dirty dozen” later described Boca Raton as IBM’s Woodstock: Everyone would claim to have been there when it started, and the vast majority were lying.\n\nAs operations at Boca Raton grew exponentially, it became harder and harder for the original ELS staff to maintain their sense of identity. For many, the joy of working there had come from their status as ignored and unloved misfits. Those days seemed to be over. Boca Raton was changing, and not for the better. They felt like they were being reabsorbed and forgotten. The pressure to reintegrate with IBM’s traditional way of operating began to build. It didn’t help that IBM’s “salarymen” culture didn’t enable financial rewards for exceptional achievements.\n\nThe ELS had invented an entire industry—the PC business, one that IBM and others were now making a lot of money from. Very little of that money filtered back to the men and women of ELS. Not because IBM didn’t recognize what they’d achieved, but because the company had no way of providing major financial bonuses, at least not ones that weren’t tied to promotion into management.\n\nWilkie, for example, couldn’t help but comment on the difference on a visit to Tandon, one of the companies that supplied IBM with disk drives. “When I passed the executive parking lot, all I saw were Rolls-Royces, Mercedes, and Porsches,” he said. “I did consider that, after all, I was in Southern California, but I also remember thinking, ‘I am definitely in the wrong end of this business.’”\n\nEstridge struggled to find ways to financially reward the core members of the PC team without promoting them into management positions—positions many of them didn’t want, because they took them further away from the hands-on engineering they loved. While nobody blamed Estridge for the lack of an alternative reward scheme, its absence bred resentment.\n\nAnd then, in September 1982, the resentment imploded.\n\nA phone call arrived, from Martin Alpert, the Tecmar CEO. A group of IBM staff members had contacted Tecmar, offering to sell the company commercially sensitive designs and specifications for the PC. Alpert was an honorable, intelligent man. As a major peripheral manufacturer, his relationship with IBM was the cornerstone of his business. He informed IBM of their potential security breach and then went a step further—he offered to assist them in a sting operation.\n\nOn September 4, 1982, Alpert met with the rogue IBM employees in a hotel at Cleveland Airport. He listened to their pitch. He told them he was interested and they agreed to talk. He was also wearing a wire.\n\nA week later, IBM fired William Erdman and Peter Stearns, two newer members of the IBM PC operation for attempting to sell corporate secrets—along with Lew Eggebrecht, one of the original dirty dozen members and forefathers of the PC.\n\nThe discovery of Eggebrecht’s betrayal sent shock waves through the original members of the PC project. He had been there from the beginning. He was one of them. They believed that his actions were naive rather than malicious. But it brought all the feelings that something had been lost in Boca Raton back to the fore.\n\nIt wasn’t even about money. They just wanted someone—something—to recognize that what they had achieved as a group had been special.\n\nOne day shortly after the incident, Wilkie turned up to a meeting with Estridge and noticed that he was wearing a red rosette on his jacket lapel.\n\n“What’s that for?” Wilkie asked.\n\nWordlessly, Estridge opened his briefcase and pulled out another red rosette. He handed it to Wilkie.\n\n“What’s this mean?” Wilkie asked again, confused.\n\n“It means you’re a member of the finest, most professional and most loyal team that’s ever been assembled in the history of IBM,” Estridge told him. “Put the rosette in your lapel and wear it everywhere you go, so people will know who you are and what you belong to. Besides, we all need to stop and smell the roses from time to time.”\n\nWilkie, a man not prone to displays of emotion, began to well up. It was a small, silly thing, but Estridge had somehow managed to distill all of their frustrations into something tangible.\n\n“Now state your business, then get out of here,” Estridge told him. “I’ve got more of these things to hand out.”\n\nFrom that point onward, you could always spot a member of the original PC team at Boca Raton. They were the ones proudly wearing one of Estridge’s red rosettes.\n\nThe more successful the PC became, the more IBM’s other divisions—and its more ambitious executives —wanted in. Having finally realized the potential profits to be made in the microcomputer industry, IBM’s most senior management were pushing the ELS for more. Estridge pulled together his weary senior team. They agreed that one of three projects looked promising—a cheaper, cut-back version of the PC (the PC Junior); a high-end version of the existing PC, complete with a hard disk (the PC/XT); or an improved version using newer Intel chips (the PC AT).\n\nWith everyone at Boca Raton already stretched thin, Dan Wilkie asked the question nobody else wanted to ask.\n\n“My god, what happens if the Management Committee approves all three programs?”\n\nThere was a long, drawn-out silence. Eventually, Estridge spoke. “That’s something we’ll worry about if and when we get that order.”\n\nAs Wilkie had feared, the order was given.\n\nThe decision to push all three post-PC projects proved to be the final nail in the coffin for what Estridge had built at Boca Raton. They had become too successful.\n\n\"You couldn't have a business that might account for 25 percent of your revenue not to be tied into the formal system,\" a member of the Management Committee from this time later explained.\n\nEstridge had fought to maintain the independence of the ELS and keep the rest of IBM away. Now, even his supporters appeared to be working against him. The more resources they gave him, the more he was pressured to take on more standard IBM ways of operation to deal with the size of the operation.\n\nEvery promotion inserted additional levels of management and bureaucracy between him and the factory floor. His swift decision-making, approachable nature, and ability to see the full picture had always been his strengths. These became significantly harder to wield once layers of secretaries and junior managers asserted control over his schedule.\n\nAll three of the PC successor projects needed Estridge’s managerial hands-on touch. But there was only one Estridge.\n\nOn August 1, 1983, IBM tacitly confirmed to the company that the misfits of Boca Raton were misfits no more. They were so important and successful that the Management Committee had upgraded Entry Level Systems at Boca Raton. The media and press were informed that ELS had been replaced by the Entry Systems Division in Boca Raton. Its president was Don Estridge.\n\nThey were a fully-fledged IBM family. That brought with it an implicit requirement to behave the IBM way. Like sharks circling, other divisions began to take back responsibility for activities that they had been happy to let the ELS do before. Distribution was returned to the IBM National Distribution Division. Marketing went to the IBM National Marketing Division. Each change was meant to bring stability; instead, it created complexity and established a more conservative and risk-averse way of operating. That brought delays, which would be blamed on the ESD and Estridge, miscast as problems related to any freedom the division retained.\n\nIn the end, the failure of the PC Junior in the home market triggered Estridge’s final fall. The project, led by Bill Sydnes, suffered a catalog of delays and failures—in part, because Estridge, still used to managing large projects directly rather than stepping back as a senior executive, could never quite relinquish control. Sydnes, for example, recognized that competing for the home computer market meant going up against Atari and Commodore, and facing off against sharp operators like Commodore’s ruthless founder, Jack Tramiel. In order to beat the master of bargain-basement computing, IBM would have to sink down to Tramiel’s level and sell machines in the kind of discount electronics chains that IBM had always shunned. Estridge, too distant from the minutiae of the project to understand this, vetoed Sydnes’s plans.\n\nIn its wake, Estridge was finally forced to agree to something he had been trying to avoid for almost a year: accept one final promotion. In early 1985, IBM announced that Don Estridge was now the Director of Worldwide Manufacturing, responsible for 116,000 people at 41 IBM plants in 15 countries worldwide.\n\nWhen Estridge announced the news in the giant corporate auditorium at Boca Raton, the assembled members of the ESD gasped. Wilkie, like many of the old guard present, instinctively reached for the red rosette on his lapel. Some of them began to cry. So did Estridge. On paper, it was a promotion. However, it was a role with no real power. They all knew what it meant. Their leader had been quietly benched, just as he had been in 1979 on the Series/1.\n\nWhat happened next wasn’t hard to predict. IBM failed to remember one of the key things that made Estridge so successful—his humility. The company assumed that once it controlled 70 percent of the PC market, nobody would be able to compete again. Employees labored away at projects like the PC Junior using the same generation of PC technology, rather than focusing on what was happening in the market around them—the rise of the clones.\n\nEstridge’s decision to base the PC on an open architecture was a smart one, but it had been built on a bad assumption—that IBM would continue to move fast and innovate. The clones would always follow in its wake. But IBM took its eye off the ball. The development of a true PC successor, the PS/2, which used Intel’s next-generation processor—the more powerful 80286—proceeded at a snail’s pace.\n\nFinally, in April 1987, IBM announced the release of the IBM PS/2, built around the “286” (as the 80286 had come to be known). When it launched, it was already a generation of processors behind. Six months earlier, Compaq, an aggressive PC clone that had lured many of Estridge’s former team away, released the Deskpro. It was the first mass-market machine to use Intel’s new 80386 processor—a “386.”\n\nBy the end of 1987 market share fell from 70 percent down to 20 percent. IBM finally realized its mistake. It was time to bring Don Estridge off the bench and push IBM to the forefront of the PC business once again.\n\nPerhaps, in another timeline, that’s what happened. In this one, Don Estridge was no longer there to save the day.\n\nAt 7:30 p.m. on Friday, August 2, 1985, Dan Wilkie was enjoying a quiet evening at home when his phone rang. He was the site manager for Boca Raton and the designated contact in case of an emergency. He listened in horror to the voice at the other end of the phone. An hour earlier, Delta Flight 191 had crashed as it approached the runway in Dallas, Texas, and 137 passengers and crew were now dead.\n\nAfter demand for the PC had soared, the ESD opened an additional manufacturing facility in Texas. The Dallas evening flight had become popular with IBM staff heading between the two sites. For the rest of the night, Wilkie stayed by the phone, coordinating with Delta to identify who from Boca Raton had been onboard. He spoke to worried relatives and promised to use the corporate weight of IBM to support them however they needed, logistically or financially.\n\nAt 11:30 p.m., he received another call. It was from the manager of an IBM sales office in Fort Lauderdale. Wilkie had been fielding calls from various IBM managers all evening, checking on missing staff. He asked the manager who he wanted to check on.\n\n“No, It’s Patty Estridge, Don’s daughter,” the manager said, sounding distraught. “She just called me and said her folks were on the plane.”\n\nWilkie recoiled, as if he’d received a punch to the stomach. For a brief moment, he refused to believe it. Estridge had already left Entry Level Systems. He was preparing to move to New York. There was no reason for him to be on a flight between Texas and Boca Raton. But something deep in his soul told him it was true. He hung up the phone and placed his head in his hands.\n\nFour hours later, Delta was finally able to confirm it. Don Estridge was dead.\n\nDon Estridge had always been a family man. After news of his benching by IBM got out, in 1985, Steve Jobs made him an unbelievable offer: $1 million to take over from Jobs and run Apple. Estridge refused. IBM was his family. So were his employees. Even when he’d been made the president of an entire IBM division, he’d continued to drive around the buildings at Boca Raton at night to check on his staff.\n\nMost of all, he loved his real family—his wife Mary Ann and his four daughters. They were his life. So, before leaving Florida forever for his new role at IBM headquarters in Armonk he decided to take Mary Ann on a long-overdue camping holiday. They decided to travel via Dallas to meet up with their daughter who lived there.\n\n\"I think he went to his grave with the love affair still going on with his wife,\" Ed Faber, the CEO of ComputerLand, said. \"I know that sounds corny, but you just had to see the two of them swooping around the dance floor to understand how in love they were.\"\n\nThe funeral service for Don and Mary Ann Estridge was held on August 5, 1985, attended by their friends and family. They were not alone. Over 1,000 people crowded the church and graveyard that day. They had come, en masse, from Boca Raton.\n\nThe crowd was a sea of black and gray, flecked with the occasional small flash of red from a lapel. Every one of the pall-bearers for Don’s casket also wore the red rosette..\n\nEven after the service ended, the crowd seemed reluctant to leave. Leaving meant admitting that Don Estridge was gone. The man who had always stood behind them, championed them within the conservative culture of IBM, and helped change the world forever. He had given so much of himself to them. On some level, they knew they needed to give some part of themselves back to him. They didn’t want him facing the next world alone.\n\nEventually, it was Wilkie who made the first move. Overwhelmed with emotion, his eyes red and swollen with grief, he stepped forward and detached the red rosette from the lapel of his suit jacket. It was the same one Don had given him years before. Leaning down, he gently placed the rosette on the casket.\n\nFrom behind him, he heard someone else moving through the crowd of mourners. Wilkie didn’t turn around. He knew what was coming. The mourner reached past Wilkie and another red rosette was placed gently, next to his own, on Don’s casket.\n\nMore movement. Another rosette. Then another.\n\nThen, after a while, it was done.\n\nWilkie stepped back, not daring to make eye contact with the friends and colleagues who stood alongside him. He turned and slowly walked away. His colleagues did the same. The spell broken, the other mourners started to disperse, too.\n\nWithin minutes, all that remained was the silence of the graveyard. On the casket of Don Estridge, a collection of red rosettes cast pink shadows in the pale morning light.\n\n\n\n\n\nGareth Edwards is a digital strategist, writer, and historian. He has worked for startups and corporations in both the UK and U.S. He is an avid collector of old computers, rare books and interviews, and abandoned cats. Follow him on X, Mastodon, and BlueSky.\n\nTo read more essays like this, subscribe to Every, and follow us on X at @every and on LinkedIn.\n\n\n\n",
      "word_count": 8544,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3119/Screenshot_2024-06-05_at_10.04.26_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3479/thumbnail_Screenshot_2025-03-06_at_8.56.44_PM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "the-crazy-ones"
    },
    {
      "url": "https://every.to/the-crazy-ones/the-rise-and-fall-of-steve-jobs-s-greatest-rival",
      "title": "The Rise and Fall of Steve Jobs’s Greatest Rival",
      "author": "Gareth Edwards",
      "author_url": "/@gareth_9984",
      "publication_date": "March 4, 2024",
      "content": "The Rise and Fall of Steve Jobs’s Greatest Rival\n\nAdam Osborne was the master of momentum—until it all came crashing down\n\nIn the Oscar-nominated film The Holdovers, the lead character, a history teacher, says, “Before you dismiss something as boring or irrelevant, remember, if you truly want to understand the present or yourself, you must begin in the past. You see, history is not simply the study of the past. It is an explanation of the present.”\n\nThis quote aptly describes the work of Gareth Edwards, a digital strategist, writer, and historian who’s previously written for Every about the secret father of modern computing, the rise and fall of Elon Musk's earlier incarnation of X, and the trust thermocline. Today’s businesses and technologies were not just defined by the names we remember, and in his new column, The Crazy Ones, Gareth will tell the stories of the forgotten men and women who thought differently and helped build the future. His latest piece demonstrates how the personal computing battles of the early 1980s—when Steve Jobs and Adam Osborne battled for supremacy—echo to today. It’s a reminder of how easy it is for founders to repeat mistakes from the past. Read this to 1) bask in the incredible writing, 2) enjoy the fascinating story, and 3) learn how others’ missteps can help solve your problems. (If you prefer an audio version, listen to Gareth's narration on Spotify.)\n\nGareth will be bringing a new story to light in his column on the first Monday of each month—making a subscription to Every that much more valuable for paid subscribers. As always, let us know what you think in the comments. —Kate Lee\n\n\n\nOn June 5, 1981, journalists from around the world gathered at NASA’s headquarters in Washington, D.C. to watch as the Voyager 2 spacecraft became the first man-made object to reach Saturn. In the aftermath of this historic event, the main attraction wasn’t NASA’s staff. It was fellow journalist Jerry Pournelle. Pournelle had something none of them had ever seen before: a portable computer, the first mass-market one in history.\n\n“There were over 100 members of the science press corps packed into the Von Karman Center (the press facility),” Pournelle wrote in his regular column for Byte magazine a few months later. “Most had typewriters. One or two had big, cumbersome word processors…nobody had anything near as convenient as the Osborne 1.”\n\nJust six years earlier, the Altair 8800 had been unveiled at the first meeting of the Homebrew Computer Club. There, Steve Jobs recognized that the future of computing lay in the consumer market, not the hobbyist. But Jobs was not alone. He stood alongside someone who would go on to become a “frenemy” of sorts. Like Jobs, he was intensely charismatic. Like Jobs, he had a near-supernatural ability to sense what consumers wanted before they knew it themselves. And, like Jobs, he knew how to sell his ideas to the world.\n\nThat man was Adam Osborne, creator of the Osborne 1 that had wowed those gathered at NASA. He was Jobs’s first true rival—one who seemed destined to beat him, until his $100 million company was no more, almost overnight. Today, Adam Osborne is mostly forgotten. He only survives as a warning whispered to business students and first-time entrepreneurs: “Beware the Osborne effect!”\n\nThis is the story of Osborne’s spectacular rise and fall. It is based on contemporary articles in publications such as the New York Times, Business Insider, Infoworld, Dr. Dobbs Journal, and Byte; published accounts from those who were there; books such as Steve Jobs by Walter Isaacson and Fire in the Valley by Michael Swaine and Paul Frieberger; and, finally, on the words of Adam Osborne himself.\n\nIn late 1943, a three-year-old boy approached Bhagavan Sri Ramana Maharshi, a Hindu sage living in Tamil Nadu, a state in southern India. The boy’s name was Adam and he lived at the Maharshi’s ashram with his mother.\n\nTo the many seekers of enlightenment visiting the ashram, a young western child on its premises would have seemed unusual. His familiarity and informal interactions with the great man would have bordered on the disrespectful. Yet the sage responded with warmth. He had offered the boy’s mother sanctuary from the war sweeping through the world after Adam’s father, a British philosopher, had been captured by the Japanese at the fall of Singapore. There had been no news of him since—until that morning when, with Adam watching on, his mother received a telegram from the War Office announcing that her husband was dead.\n\nAdam refused to believe this was true. He pushed his way through the crowd until he caught Sri Ramana’s eye.\n\n“Bhagavan, please bring my daddy back safely,” Adam asked matter-of-factly in fluent Tamil.\n\nBhagavan Sri Ramana Maharshi looked at him, smiled, and promised Adam that everything would be okay. And it was. At the end of the war, his father was found weak but alive in a Japanese internment camp.\n\nThe pace of life at the ashram represented a stark contrast to the world outside it. While relatives his age in England were being evacuated to the countryside or spending their nights in air raid shelters to avoid German bombs, Adam and his friends were exploring the hills and valleys of Tamil Nadu. His early life was one free of materialism, in a community of devotees who believed that moderation and self-reflection were the route to happiness. It was a time free of fear and full of love, one that only became more pronounced once his father joined them after the war.\n\n“The years after he came home from the war were, for us children, a great joy,” Adam’s older sister recalled.\n\nFor a brief period, Adam continued to live an idyllic life in the ashram, and his creativity and desire to explore were encouraged. But it couldn’t last forever. Although his father became a devotee of the Bhagavan, he believed that Adam needed to experience the outside world. At the age of 11, Adam was enrolled in boarding school in England while his parents remained at the ashram.\n\nThe culture shock for young Adam was enormous. Life in India was about freedom and creativity—neither of which postwar boarding schools in England believed had a place in a young boy’s life. On top of this, Adam faced another huge challenge. While he was fluent in English, Tamil was the language he considered his own. His wardrobe of light summer clothes contrasted with the more formal shirts and gray shorts of his English peers. On arrival, everything about Adam would have screamed: foreigner. Different.\n\nIn a boarding school environment, being different was the worst thing a young boy could be. It made you a target.\n\nThis experience could have been the breaking of Adam, as it has been for many young boys before and since. Instead, he responded in the way he would learn to respond to everything in life—by changing himself and pushing ruthlessly forward.\n\nHe charmed those around him with the same easy confidence he had seen the Bhagavan exhibit time and again. It was perhaps the only part of his Indian upbringing (other than a life-long fascination with eastern philosophy) that he decided to preserve. Over his remaining years at school and later university, he would gradually shed all the other parts of his old self. How he used words changed. He discarded the southern Indian accent of his youth in favor of a more clipped, upper-class English tone. He modified how he dressed, adopting a more conservative, British style.\n\nAdam, the young boy who had played in the hills of Tamil Nadu, was gone. He had become Adam Osborne, a young man determined to move forward without ever looking back. This would be the Adam the world would see for almost all of his life.\n\nAlmost everyone who met Adam Osborne would describe him the same way. Well dressed. Soft-spoken. The owner of a not-quite-English accent, which still carried a hint of his Indian upbringing. In England, he’d worked hard to rid himself of it. In America, he discovered it caught people’s attention. And once Adam had your attention, you were in trouble, at least if you had something he wanted. He was viciously smart, almost impossibly persuasive, utterly ambitious, and eternally restless. He was a man driven by twin goals: to succeed and to make money. He also enjoyed indulging in the excesses that achieving those goals enabled. From parties to poker games, Osborne was a regular at them all. Nor was he afraid to broadcast his achievements to the world.\n\nAll of these things would eventually make Osborne one of Silicon Valley’s first true tech celebrities, but they came at a personal cost. His goals and lifestyle were the antithesis of everything taught by the Maharshi back at the ashram, where his parents remained. This was not the Adam they had raised, and, to his frustration, they rarely acknowledged what he believed to be his successes.\n\n“He never forgave his parents for sending him away,” author and journalist Michael Swaine wrote of Osborne later. Swaine knew Osborne personally, describing him as someone driven by twin demons—a desire to be seen as worthy of their love, but determined to make them acknowledge him on his terms, not theirs.\n\nWhether Swaine’s insight into Osborne’s motivations is accurate or not, it’s certainly true that by the time Osborne moved to Silicon Valley, his relationship with his parents was fractious. Not long after, that fracture would become almost permanent. This would also lead to a strained relationship with his siblings for most of his life.\n\nWhen the Altair 8800 was revealed in 1975, Osborne, like Jobs, had an instant vision of the future it foretold. He was in California, working as a chemical engineer for Shell until he grew bored with his occupation and became active in the world of computing. He’d always been a good writer, and his 1972 book The Value of Power—a title commissioned by a large computer manufacturer—was one of the earliest books on mainframe computing that was written for business people, not engineers. This was the start of a reasonably lucrative career as a consultant and technology journalist.\n\nAfter seeing the Altair, Osborne was determined to write the first business-friendly guide to using it, so he quickly wrote his next book—Introduction to Microcomputers. Traditional publishers didn’t believe there was a market for Osborne’s book and hesitated to publish it. But his reckless energy wouldn’t allow him to wait. He decided to start his own publishing company. By March 1976, the book had sold 20,000 copies.\n\n“Publishing was clearly a better business than consulting,” Osborne wrote later, “so I refocused my attention.”\n\nOsborne’s company became the leading publisher of books on home and business computing in California. That landed him a regular column in Interface Age, one of the first personal computer magazines. Osborne called his column “From the Fountainhead,” and he became one of the most widely known, respected, and even feared writers on the home computing revolution.\n\nOsborne’s bold and forthright columns were part of a calculated plan. He’d come to believe that everything was about momentum in the rapidly changing world of home computing. You had to be part of the digital zeitgeist or you would be left behind. “From the Fountainhead” was the perfect way to stay current, which, in turn, drove his company’s book sales. By 1979, Osborne was the foremost publisher of personal computing books in the world and a well-known figure in Silicon Valley. Then, in late 1979, to the astonishment of everyone, Osborne sold it to McGraw-Hill, one of the oldest and most traditional publishers in America.\n\nOsborne agreed to stay on in a leadership role at the newly rebranded Osborne/McGraw-Hill. However, he ensured that his agreement with McGraw-Hill would allow him to pursue other projects. He could also leave the company without penalty by 1983, three years after he had sold. The truth was that Osborne felt like he’d conquered computer publishing and was losing momentum. He wanted—no, needed—to get that momentum back. And having watched the hardware business from the outside for a while, he thought he had a way to do it.\n\nOsborne sought out the one person he trusted not to laugh at his plan: fellow Homebrew Computer Club veteran Lee Felsenstein. To Felsenstein’s astonishment, Osborne told him that he was setting up a new company to build the world’s first truly portable computer, and that Felsenstein was going to design it for him. Felsenstein objected, saying it was a bad idea. It would require squeezing a lot of components into a very small space—and was entirely contingent on whether these components could be sourced at all, and at prices that weren’t prohibitive. Unfortunately, he already knew it was futile to say no.\n\n“He was extraordinarily charismatic,” Georgette Psaris, who would later work at Osborne Computers, said of Osborne. “When he feels that someone doesn’t get something, the whole dam of his charisma opens up. His passion was contagious.”\n\nBy the end of their conversation, Felsenstein agreed to design Osborne’s portable computer. In return, he would receive a small salary and 25 percent of Osborne’s new company, Brandywine Holdings.\n\nFor several years, Osborne had been thinking seriously about what—and who—stood out in the home computing marketplace. It had grown crowded by the 1970s, and Apple, Tandy, and Commodore seemed to have cornered the market. To Osborne, his old acquaintance Jobs and Apple, which had launched the Apple II in 1977, was doing the best job.\n\n“Technology has nothing to do with Apple's success,” he wrote later. “Nor was the company an aggressive price leader. Rather, this company was the first to offer real customer support and to behave like a genuine business back in 1976 when other manufacturers were amateur shoe-string operations.”\n\nOsborne understood that copying Apple wasn’t enough. The company had too much of a head start. So he looked at IBM, which was still focused on mainframes, and asked himself why it had been able to secure such a significant share of its market, even when competitors had better products. He came to a realization—one that would become something of a mantra for him.\n\n“Adequacy is sufficient. Everything else is irrelevant.\"\n\nHe didn’t need to design a computer that was beautiful or special. Let Steve Jobs do that. He would instead create one that did 90 percent of the basic business tasks most regular people needed it to do.\n\n\"If the market was to grow,” Osborne said, “it would have to rely on customers who would plug a computer into the wall, as they might a toaster.\"\n\nAnother logical step followed: If you’re going to make a self-contained computer—with a keyboard, drives, and monitor all in one—you might as well make it portable.\n\nFelsenstein and Osborne spent early 1980 in a space they shared with a Berkeley electronic anarchist collective working on a final specification for their new machine. They used relatively cheap parts to help keep the overall cost low. It would have the popular Z80 microprocessor, 64k of RAM (the most the Z80 could support), a five-inch screen, and two disk drives. They could fit all of this into a case small enough to comply with airline carry-on luggage requirements.\n\nFelsenstein was surprised—but happy—to admit that Osborne had been right. They could indeed build a portable computer that was powerful enough to run any software the customer decided to buy.\n\nOsborne then hit Felsenstein with his next masterstroke: This computer would come with all the software the customer needed, for free.\n\nSoftware bundling—the practice of including key pieces of software with the purchase of a PC or console —is universal in the modern era. But in 1980, it was considered a bad idea.\n\nToday, only a few names dominate the world of business productivity software, which encompasses word processors, spreadsheets, and databases. In the 1980s, things were different. The market was full of products, all offering different features or optimized around certain ways of working. Nor were they cheap. Prices for a good word processor ranged from about $150 up to $500. Adjusting for inflation, that would be like paying $1,700 for Microsoft Word today.\n\nAs a result, most manufacturers considered it bad business to include major software with hardware. Osborne realized that there was a misconception that ran through the industry. Most people believed that computer buyers were technically literate, and would want to do their own research before buying software. Bundling software was seen as something that increased the price of the machine for everyone in order to appeal to a few buyers.\n\nOsborne’s theory of adequacy allowed him to see differently. For the average business or home customer, the variety of software was a problem. They didn’t care which piece of software was best—they just wanted something good enough. So if his computer came with a range of useful software, that might be an attractive proposition.\n\nOf course, it wouldn’t be attractive if the software license costs inflated the price of the machine, so Osborne turned the full force of his personality on his industry connections.\n\nThe first and most important deal was struck with Gary Kildall and Dorothy McEwen, the owners of Digital Research. Kildall was the creator of CP/M, an operating system that was starting to lose market share. Osborne gambled that this slide would increase his chance of getting a better deal on the price.\n\nHe was right. First, he procured a fixed-cost universal, perpetual license for CP/M for just $55,000. Not only was this a good price, but the universal license meant that the more machines they sold, the better the value of Osborne’s purchase. CP/M would never offer such a license again.\n\nOsborne closed on a number of fixed-cost software licensing agreements on equally beneficial terms. Such agreements weren't generally offered to manufacturers by the major software companies of the time. However, most manufacturers weren't run by Osborne. Throughout 1980 and into early 1981, he leveraged his easy charm and personal relationships with many of the leaders in computing to great effect.\n\nMost notably, Microsoft agreed to an unlimited license for Microsoft BASIC. Then, MicroPro agreed to the same for WordStar, one of the most popular and well-respected word processors on the market. In return, both companies got no money; they received shares in Osborne’s new company. Failing to tempt the makers of VisiCalc, the world’s first spreadsheet program, with the same deal, Osborne approached Richard Frank at Sorcim Software instead.\n\nDuring a poker game, Osborne had already persuaded Frank to write the boot-up firmware for his new machine. Now, Osborne persuaded him that Sorcim should make the first real VisiCalc rival as well. In return for about 3.5 percent of shares and $20,000 up front, Frank and his fellow programmers worked nights to create SuperCalc that would be included with Osborne’s machine.\n\nThere were plenty of other deals too. By the time Osborne was finished, the Osborne 1 would be bundled with over $2,000 ($7,000 today) of useful software at no per-unit cost to Osborne.\n\nTo help finance his startup, Osborne managed to snag Jack Melchor, one of the most prominent venture capital fund managers in Silicon Valley. Melchor insisted on two conditions—that Osborne change the company name, and that they start looking for a permanent headquarters. Changing the name would better capitalize on Osborne's personal reputation, while more space would allow the company to expand quickly. Brandywine became Osborne Computers (officially known as the Osborne Computer Corporation), and they began a search for factory space that would eventually lead them to Hayward, California. Osborne tried to persuade Bill Gates, who was then running Microsoft, to join the board, but Gates declined, citing unspecified potential conflicts of interest. Microsoft was already working behind closed doors with IBM on the latter’s yet-to-be-announced mass-market “personal computer,” although nobody knew this at the time. For Gates, licensing BASIC to Osborne in return for shares was a hedged bet—nothing more.\n\nBy January 1981, Osborne’s first paid employees were hired: Georgette Psaris and Tom Davidson. Psaris was a talented young marketer who had worked with Osborne before. Davidson was forced on Osborne by circumstance. The company needed someone to oversee the purchase and supply chain, as well as manufacturing, especially since Osborne split his time between Osborne Computers and McGraw-Hill.\n\nOsborne tried to find someone with experience at building computers at scale, but everyone turned him down. They wanted to see the prototypes first. Osborne didn’t feel he could wait for that. Slowing down risked losing momentum. So he gambled on Davidson. Davidson was a heavy-set, larger-than-life Brooklynite with a thick accent. His previous experience was in running a large New York taxi company before moving to California to manage manufacturing for a canned food supplier.\n\nBoth Psaris and Davidson arrived to find the pressure ramping up. Osborne told them that they had just $900,000 dollars in the bank. Based on manufacturing and operating costs, Osborne forecast that if they weren’t selling 4,000 computers a month within 18 months, they’d go bankrupt. To have a chance of reaching this figure, they needed their machine on sale by June 1981—only six months away.\n\nAs if this wasn’t pressure enough, Osborne set them an even earlier deadline. They needed the first machines ready for the 1981 West Coast Computer Faire at the beginning of April. If they missed that, he explained, the chance to build enough launch momentum would be lost.\n\nOsborne’s ruthless focus on the West Coast Computer Faire was related to his obsession with momentum, or as he later described it in his book Hypergrowth, his “Wave Theory” of publicity and hype. Osborne believed that you could manage your product momentum by ensuring media attention at the right time and intervals. You needed to create waves of interest in the public narrative.\n\n\"Few journalists specifically look for good or bad stories; they look instead for interesting ones,\" he said. \"Media stories are initiated by knowledgeable professionals. But invariably, subsequent press coverage is the work of less-informed journalists who are in mortal terror of penning a harsh statement they might be called on to defend. So they rehash previous stories, adding little or nothing new.\"\n\nOsborne’s plan was simple: Dazzle the experts and early adopters. When the mainstream press would start picking up that buzz, their coverage would be positive—even if the experts had since found problems with his product. Meanwhile, Osborne would address those problems quickly, announce a new feature or product variant that would dazzle the experts, and kick off the whole cycle again.\n\nThe West Coast Computer Faire was the biggest computer industry show around. At the first show in 1977, Apple had revealed the Apple II, while Commodore had announced the launch of its personal computer, the PET. Tandy introduced a number of new products there in subsequent years as well. These three companies were those that Osborne considered to be his main rivals, and thanks to the industry connections he had built up writing his computing column, he knew that none of them had any major announcements to make there in 1981. He believed that he could encroach on their markets by stealing the narrative of the show from them.\n\nThrough extreme efforts, the prototypes were ready by the end of March. The resulting computer, christened the Osborne 1, was very heavy (only Davidson could lift it with one hand), and it grew so hot you could fry an egg on its case, but it existed. And it worked.\n\nWith excitement and trepidation, almost the entire staff of Osborne Computers headed to San Francisco, ready to reveal the Osborne 1 to the world.\n\nOn April 3, 1981, the sixth annual West Coast Computer Faire opened its doors. Upon entering, attendees were greeted by rows of booths filled with familiar names like Commodore, Tandy, and Apple…\n\n…and then they would have seen it. Towering high above the show floor was a multi-story plexiglass booth. At the very top was a brilliantly-lit logo—a giant “O” with wings.\n\nThis was the brainchild of Osborne’s new head of public relations, Barbara Burdick. Osborne had told Burdick to spend as much of their remaining $900,000 as she needed in order to create a booth nobody could miss. She’d done just that.\n\nOver the next three days, attendees flocked to the Osborne booth. What was on offer there seemed fantastical. For just $1,795—less than the price of Tandy’s TRS-80 microcomputer—you could get a portable computer.\n\nThat was also $500 cheaper, Osborne told show-goers and journalists, than the price of the Apple II. The Apple sales staff at the show repeatedly pushed back against this comparison. They countered that the newest Apple IIs came with almost twice the memory of the Osborne 1, which also had a barely adequate five-inch screen. The Apple II was a beautiful machine in comparison to the Osborne 1.\n\nSure it is, Adam would point out. But what good is it if you can’t afford any software to run on it? Without the right software, the perfect machine is just the perfect paperweight. The Osborne 1 came bundled with a word processor, spreadsheet software, BASIC, and more—all the business productivity software you would need, with no extra purchase necessary.\n\nBy the end of the first day, the Osborne 1 was the talk of the show. Digital Deli was a major chain of dealers that supplied computers to buyers across the country. At the Faire, it had the stand directly opposite Osborne's. The company immediately started taking pre-orders for the new machine from the show's attendees and received enough over three days to cover half of Osborne’s sales target for its first month after launch.\n\nOsborne reveled in the limelight. Speaking to the tech and business journalists present, he issued a public challenge to Apple, Commodore, and his other rivals. He declared that the Osborne 1—with its bundled software—was the future of computing.\n\n“Do as I have done,” he declared flamboyantly, “or perish!”\n\nShortly after this hit the newswires, the phone rang at Osborne Computers’s near-empty headquarters in Hayward. Almost everyone was at the show, and only a young intern was there to answer it.\n\n“Hey. It’s Steve Jobs,” the voice on the other end of the phone told the astonished young temp. “Is Adam there?”\n\nThe young man stammered that Osborne was still out of town. Unsure what to do, he asked Jobs if he wanted to leave a message.\n\n“Yeah,” Jobs replied. “Tell Adam he’s an arsehole.”\n\nIt’s hard now to grasp just how quickly the Osborne 1 propelled Osborne Computers to the top ranks of the home computing pyramid. Demand for the machine—enabled by Osborne’s avoidance of the standard distributor network—was instant. Traditionally, computer manufacturers sold machines to large distributors, which provided consistency to the order pipeline, made revenue easier to manage and predict, and lowered overall risk. These distributors supplied local computer shops and dealers, who sold them directly to customers.\n\nThe trade-off with using a distributor network was that new computers, or models, could take time to reach dealers’ shelves. It also increased unit price as the distributors took a cut of each sale.\n\nOsborne decided that these negatives outweighed the positives. They would compromise his company’s momentum. So Osborne Computers ignored the risks and sold directly to dealers.\n\nThe response suggested that Osborne had once again been right. The number of Osborne 1s hitting the market continued to climb, and the company often struggled to meet demand throughout the rest of 1981. It achieved its first 4,000-machine month long before Osborne’s June 1982 target. Indeed, by June 1982, Osborne Computers already had 3,000 employees and had shipped 50,000 machines worldwide. Behind the scenes, the company was developing the Osborne Vixen, a low-price variant. It had also started working on the Osborne Wayne, a purely desktop IBM-compatible computer.\n\nThe Wayne was as close as the company had come to acknowledging the existence of the new computing elephant in the room: the IBM PC. It had hit the computer market in August 1981 and demand for it was continuing to grow. Increasingly, it seemed the only way other manufacturers could compete was to offer IBM-compatible computers—machines that could run the same software, and use the same peripheral hardware and plug-ins, as the IBM PC.\n\nMost importantly, though, the company had begun development work on the Osborne Executive. This would represent a step-change over the Osborne 1. It would have a larger screen, better disk drives, and a raft of other improvements aimed at making it the must-have machine on the portable market.\n\nBy summer 1982 Osborne Computers was the darling of the business and computing press. The apparent dynamism of Osborne was increasingly contrasted with a period of stagnation for Jobs, his old friend and rival. While Osborne was announcing three new machines, for example, all Apple seemed able to offer was yet another iteration of the Apple II.\n\n\"I liken myself to Henry Ford and the auto industry,\" Osborne said in one interview. “I give you 90 percent of what most people need.”\n\nIn his Cupertino headquarters, Jobs raged at comments like these. Apple employees remember their charismatic founder wandering the corridors, mocking Osborne’s pronouncements that good enough was enough.\n\n“This guy doesn’t get it!” he’d tell random employees. “He’s not making art. He’s making shit!”\n\nWhatever Job’s opinion, the press and industry seemed to disagree. They wanted what Osborne was selling, and they wanted to know more about the man himself. Yet, strangely, this was a topic that Osborne generally avoided. He was happy to talk about his achievements and his company. He was happy to tell them his ideas on libertarianism and management. He was happy to show them his cars and his houses, and to party with friends. Who he was in his head, however, seemed known to Osborne alone.\n\nThe rise of Osborne Computers seemed unstoppable. In late September 1982, 60 Minutes aired a special called The Silicon Valley Boys. It focused on Osborne Computers, which was by then a $100 million company. The show triggered another of Osborne’s waves and spurred sales.\n\nThe company had also announced the appointment of Bob Jaunich, who used to work at Memorex, a major manufacturer of computer peripherals, as its new CEO, allowing Osborne to focus on strategy as its chair. Whispers that Osborne Computers planned to go public began to spread. It seemed a likely next step for one of Silicon Valley’s biggest success stories, and Jaunich was exactly the kind of experienced operator you’d appoint in order to make it happen.\n\nIn 1983, when Osborne revealed the new Osborne Executive to excited dealers in a country-wide tour, that IPO seemed even more likely. Press coverage of the new machine was enormous. As usual, Osborne’s wave theory seemed to be working. This was exactly the kind of hype a company would want to generate before an IPO.\n\nEveryone knew it would be a big one. Initial expectations were of an offering somewhere in the $7-per-share range, just $1 less than Apple was trading at the time. There were even whispers that Osborne Computers shares would trade for more. Adam Osborne was not just catching up with Steve Jobs. He seemed about to eclipse him.\n\nFinally, in September 1983, the company indicated it had a major announcement to make. Excited investors and existing shareholders who had preferential purchase rights tuned in with baited breath…\n\n…to see Osborne Computers announce it was filing for bankruptcy.\n\nDo not announce future products too early. You will cannibalize your existing sales. This is referred to as “the Osborne effect.” It is taught in MBA programs around the world.\n\n“If you take a look at the record of right and wrong decisions, we did damned well—as good as anyone.” Osborne told the New York Times in November 1983 in a story about the bankruptcy. He made some general comments about how difficult IBM had made the home computing market. He said very little else.\n\nThis was a mistake.\n\nAdam Osborne soon discovered the problem with his wave theory: If you stop creating the waves, the media starts manufacturing them itself. So it was that a narrative began to form in the business press.\n\nAdam Osborne’s announcement of the Osborne Executive was too early, the narrative said. Dealers and customers were spooked, and they canceled their orders for the Osborne 1, preferring instead to wait for the newer machine. This collapsed Osborne’s sales, stories in newspapers and magazines contended, and created a sudden, catastrophic cash-flow crisis—one that took down the company before any kind of financial relief package, or the IPO, could be organized and provide an urgent injection of capital. As a result, the company was forced to declare insolvency.\n\nOsborne realized his mistake in not speaking out and tried to take back control of the narrative. In early 1984, he appeared on PBS’s The Computer Chronicles, one of the most respected TV shows covering the computing industry. Coincidentally, his interviewer was Gary Kildall, the man from whom he’d licensed CP/M.\n\n“The company plain and simple committed suicide,” Osborne told viewers. “All I will say about it right now is that everything you have read in the papers you can hit the reset button on, because it’s not right.”\n\nIn June 1984, he published Hypergrowth: The Rise and Fall of Osborne Computers. It was put out by a small Berkeley publisher—the only one that would agree to do so, given its contents. In the book, he went to great lengths to explain how the collapse of the company was not his fault. He blamed it on Jaunich, Davidson, and others. He wrote of bad financial decisions behind the scenes, and made veiled claims that there had been collusion between the banks and his rivals. He was fighting to keep the company’s momentum going, he argued, but these forces had conspired to make it stop.\n\nOsborne’s book didn’t change the narrative. Even if everything Osborne claimed in the book had been true, the tone hardly screamed “reliable narrator.” Track down one of the few copies in circulation today, and you’ll discover that over a third of its length is a prolonged personal assault on Bob Jaunich’s professional ability and character. The book even comes with a threat of litigation for libel from Jaunich himself published just inside the cover.\n\n\n\n\n\nOsborne published this threat of litigation from Jaunich in his book. Source: the author.\n\nSo what did kill Osborne Computers?\n\nIn late 1981, at the height of Osborne Computers’s early growth, Barbara Burdick noticed that the company’s only accounts receivable clerk seemed to be doing odd jobs around the office. Confused, she asked why he wasn’t focusing on his work. Burdick was told that the computer they used for processing payments and sending invoices was broken. They’d asked about having it fixed, but nobody had turned up yet.\n\n“What are you doing about it?” Burdick asked, trying to remain calm. “Have you told Adam?”\n\n“Oh, no.”\n\n“I think you should tell Adam before he finds out,” Burdick said, firmly but gently. “I think he would like to know that no one has been billed in two weeks.”\n\nScratch beneath the surface of Osborne Computers and you’ll find many accounts like this. Many even feature in Osborne’s own book—including a mention that the 1982 budget for the whole company was put together by Burdick and Osborne using a copy of SuperCalc and a spare Osborne 1. This was hardly appropriate for a multi-million-dollar computer manufacturer with over 3,000 employees spread across multiple departments and U.S. states, and with subsidiaries around the world.\n\nWhen tech commentators have written about Osborne Computers in more recent years, they have tended to side more with Osborne, taking his account of events at face value. To believe that the company was killed by financial mismanagement and poor decisions by figures like Jaunich who were too “establishment” to understand the startup culture required for “hypergrowth.”\n\nThe truth, however, is that the media was right. The Osborne effect happened. It did kill Osborne Computers.\n\nIt just shouldn’t have been able to.\n\nFrom the day Adam Osborne started boarding school in England, he had been restless. His sister recalled that his interests seemed to constantly shift. A fascination with poetry gave way to science. Science gave way to engineering. Adam wanted to understand and master it all. That constant drive forward, his obsession with momentum would lead him to abandon a promising career with Shell for the unknown promise of  computing and Silicon Valley. It created unprecedented growth that pushed Osborne Computers to the top of its industry in less than 18 months. But it also meant that Osborne never stopped to address any of the logistical or financial risks that growth brought with it, until it was too late.\n\nIn 1984, as part of his attempt to clear his name, Osborne published copies of sale-and-return sheets, balance statements, and a wide range of other internal papers from Osborne Computers. To him (and to later commentators), these clearly demonstrated that overall sales continued to climb, well beyond the point at which the media said they had stopped. This is true, but it is the returns part of them that tells the real story.\n\nFor the majority of its production life, the Osborne 1 experienced a unit failure rate somewhere between 10–15 percent, roughly five times the industry average. This was in no small part due to Tom Davidson’s inexperience managing computer production. Perhaps if the Osborne 1 had been a more traditional computer, Davidson’s inexperience wouldn’t have been a problem. But its compactness was genuinely revolutionary, and alongside quality assurance failures that a more experienced industry hand would have avoided were fresh issues that arose because the design was cutting-edge. For example, the monitor was so close to the disk drives that it created radio signals that would disrupt the way the drives read data. The solution was to add some shielding around the monitor, but it was only implemented in 1982. Until then, hundreds—if not thousands—of Osborne 1s were returned for new disk drives, as it was assumed there was a failure in manufacturing.\n\nOsborne’s commitment to creating waves worsened this situation, because it meant that he was constantly iterating and improving the machine rather than pausing to optimize its production. Each wave of publicity would create another wave of issues, such as a glut of returns that would need to be fixed (often for free, at Osborne’s insistence). It would also lead dealers to hold off on placing orders until they were confident any new issues had been resolved—after all, it was their reputation that was at stake with their customers.\n\nOsbornes waves were propelling the company forward, but each of them set the company rocking upon them. He didn’t create one giant Osborne effect. He created tens of smaller ones, on a regular basis.\n\nIn each instance, they would lead to a minor crisis, as Osborne Computers’s direct relationship with its dealers left it highly vulnerable to minor cash-flow issues should a month-on-month sale-or-return imbalance occur.\n\nNone of these Osborne effects should have been large enough to trigger a catastrophic collapse—not as long as Osborne could secure short-term financing to bridge the crisis. This is probably why Osborne himself took so long to start addressing the problem, beginning with firing Tom Davidson in April 1982. But short-term financing requires someone to fund it, and that someone has to trust your financial management.\n\nAnd, as Barbara Burdick discovered in 1981, Osborne Computing was terrible at securing financial trust.\n\nIn September 1981, at the peak of the machine’s initial hype, Osborne Computers asked Bank of America for credit to cover the unexpected fluctuation in accounts-payable and -receivable.\n\nBank of America said no.\n\nFor the company, this wasn’t a huge problem. It was solved by a $1.6 million cash injection from funds managed by Jack Melchor. But it should have been a warning. Banks don’t make decisions based on how good your narrative is. They make them based on how well you keep your books.\n\nOver the next 18 months, Osborne would repeatedly trigger the Osborne effect. Worse, external factors— such as the entry of Compaq and Kaypro into the portable market, and the behemoth that was the IBM PC—started causing additional minor sales crises. Each time one occurred, it would collapse whatever small financial runway the firm had managed to build up. Or it would require another cash injection from shareholders (including Osborne himself) or a funding round. The company became overly reliant on sourcing funding from places where a growth narrative mattered more than accurate financial data until there was only one untapped source left: an IPO.\n\nIn November 1983, the New York Times asked Jack Melchor what would have happened if Osborne had relinquished the CEO role more quickly and Bob Jaunich had been hired six months earlier.\n\n“Well, the company probably would have been okay today,” he replied.\n\nBob Jaunich was about as close to an establishment figure as you could get in Silicon Valley. He was a man the banks trusted to do things the right way. He knew how large businesses should be run. He was hired to shepherd the IPO and address the chronic structural issues that Adam Osborne’s constant quest for momentum was creating.\n\nThe two men hated each other instantly.\n\nBy April 1983, Osborne wasn’t blind to the firm’s oversized exposure to even minor crises. He agreed it needed to be addressed. But he believed that anything that collapsed the company’s momentum would kill it faster than the cure. They needed to issue the IPO, then maybe, maybe ease off a bit. Jaunich, by contrast, believed that the only way they could secure the IPO was to ease off first. They needed to address the QA issues. They needed better organization structure and people in senior roles. They needed, above all else, to have a full understanding of Osborne Computers’s finances that could be included in the offering.\n\nThe problem was that, by April 1983, the company was likely impossible to save, because both men were right. Osborne Computers was surviving on the momentum created by its announcement of new models and its entry into new markets in Europe and beyond. But all that activity drew focus away from Jaunich’s efforts to fix the instabilities in its manufacturing and distribution chain. It also prevented him from creating the stable financial environment required for an IPO.\n\nFor the last few months of its existence, Osborne Computers was a collapsing empire torn between two emperors and their rival factions, beset by issues that were invisible to everyone on the outside.\n\nUntil, finally, it fell.\n\nAdam Osborne didn’t stop after the collapse of Osborne Computers. He founded Paperwork, a software company focused on a new idea: cheap business software for home computers. In 1989, a lawsuit from Lotus Software, one of the giants in the business, drove Paperback into bankruptcy. His health ruined by the stress of its collapse, Osborne finally lost his momentum. He looked around and decided to do something he perhaps hadn’t done since the day he left the ashram.\n\nHe stopped.\n\nYou will struggle today to find recorded interviews with Osborne. Yet in the media of the time he stands tall, shoulder to shoulder with his rival Steve Jobs, both leading technological evangelists for the new computing age. He wrote several books on where he thought computers were going and how businesses would use them, some of which remain visionary today. All are out of print, nor are there any biographies of him.\n\nMore than any other major figure in computing at the time, Adam Osborne was a man who lived in the moment. He wrote of the future. He built computers for it. He had no time for the past and so, it seems, the past has no time for him. He weaponized momentum, and his own restlessness, in a way no other tech founder has managed before or—if we allow for inflation and other factors—since.\n\nAnd perhaps he was only able to do that because for so long, he was scared about stopping and looking back.\n\n\"He never forgave his parents for, as he saw it, abandoning him,” his sister Katya confirmed years later. “And he resented it for the rest of his life.”\n\nAdam Osborne’s relationship with his family had always been complex. There was no doubt he loved them. He was also married twice (his second time to Barbara Burdick) and had three children of his own. But the contrast of his life in Silicon Valley with his upbringing in India was, through his own doing, extreme. By creating that contrast, he avoided for a long time having to ask himself who Adam Osborne really was.\n\nWith his health failing, however, Adam Osborne perhaps realized he was running out of time to face his demons and do just that.\n\nIn 1991, Adam returned to India, now suffering from a brain disorder that triggered frequent minor strokes. It was a place he hadn’t visited much since he had left it as a child, especially after the death of both his parents. He hadn’t intended this visit to be a long one. Just a way to bring closure. Perhaps to quieten some of those memories he’d never quite managed to forget. After all, the green hills of reality could surely never match up to the green hills in his mind.\n\nBut once there, back in Tamil Nadu, he reconnected with his siblings, his elder sister Katya in particular, who had returned to India many years earlier herself. So he stayed a bit longer, then longer still. Over time, and as he reconnected with the countryside and Tamil people of southern India, he realized something about himself. He didn’t have to be either the young Adam who had loved the hills and mountains of India or Adam Osborne the Silicon Valley entrepreneur. He was allowed to be both.\n\n“How could anyone, even an English boy, grow up in Tiruvannamalai, in the ashram of Sri Ramana Maharishi, and not acquire a pride in his roots?” Osborne wrote in an article for Indian computing magazine Dataquest at the time. In it, he acknowledged that he realized now what he had always been. Something he’d never known he was allowed to be: not English, not American, but Tamil.\n\nAnd with that, Adam’s life came full circle. He moved in with Katya. He spent his remaining years living with his elder sister in the hills of Tamil Nadu where he had grown up. The restlessness was finally gone. He was happy with what he achieved, and he was happy with who he had become.\n\nWhen Adam Osborne passed away in his sleep, at the age of 64, he was finally at peace.\n\n\n\n\n\nDid you work in the nascent computing industry and have memories about this era that you'd like to share? If so, please email us at [email protected].\n\n\n\n\n\nGareth Edwards is a digital strategist, writer, and historian. He has worked for startups and corporations in both the UK and U.S. He is an avid collector of old computers, rare books and interviews, and abandoned cats. Follow him on X, Mastodon, and BlueSky.\n\nTo read more essays like this, subscribe to Every, and follow us on X at @every and on LinkedIn.",
      "word_count": 7904,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/2997/Artboard_91.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3479/thumbnail_Screenshot_2025-03-06_at_8.56.44_PM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "the-crazy-ones"
    },
    {
      "url": "https://every.to/the-crazy-ones/the-first-king-of-home-computing",
      "title": "How Commodore Invented the Mass Market Computer",
      "author": "Gareth Edwards",
      "author_url": "/@gareth_9984",
      "publication_date": "March 10, 2025",
      "content": "How Commodore Invented the Mass Market Computer\n\nThe untold story of Jack Tramiel, Holocaust survivor and home computing's first king\n\nI have vivid memories of my family's first computer: a blocky Commodore 64 parked in a corner of our basement, its cursor blinking on a royal blue screen. It was just one of the more than 12 million units sold, an astonishing business success pioneered by a Holocaust survivor and Polish immigrant named Jack Tramiel. In his latest piece for The Crazy Ones, Gareth Edwards recounts Tramiel’s journey from Auschwitz to founding Commodore, and later reviving Atari. His ruthless approach to vertical integration and relentless cost-cutting made computers accessible to millions of families who could never have afforded them otherwise—launching a generation of tech careers and helping shape our digital present. Plus: Listen to an audio version of this piece on Spotify or Apple Podcasts.—Kate Lee\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nIn 1980, Commodore opened its first computer factory in Germany. In just three years, the company had become the third-largest computer manufacturer in the world. With annual revenue of $680 million (more than $2.2 billion today), its success was largely due to its Polish-American founder, Jack Tramiel. As he ascended to the front of the 2,000-employee crowd at the new factory, he was advised to avoid mentioning his past. Specifically, to omit that he’d been a prisoner in Nazi slave camps and at Auschwitz during the war. Tramiel listened to the advice and took to the stage.\n\n“I told them I was Jewish and that I was a survivor of the concentration camps. And then I said that I wanted anyone who was in the SS in my office in the next two days.”\n\nNobody—nobody—told Jack Tramiel what he could or couldn’t do.\n\nOver the next few days, six men resigned saying that they would never work for a Jew. Over 15 others presented themselves to Tramiel and confessed that they had served in the SS. Tramiel thanked each man for his honesty, offered his forgiveness, and then told them to get back to work. He was determined to make Commodore a business of the future, not the past. He just wanted them to know who he was. And that they worked for him now.\n\nThis is the story of Jack Tramiel, one of the most explosive and ruthless founders the computer industry has ever seen. It is the story of four machines—the PET, VIC-20, Commodore 64, and Atari ST—and of the man who ruled home computing for over 20 years.\n\nThis account is based on contemporary accounts in Time, Fortune, and the New York Times, as well as books such as Back into the Storm by Bil Herd, Retro Tech by Peter Leigh, and The Home Computer Wars by Michael Tomczyk. I am particularly indebted to Commodore: A Company on the Edge by Brian Bagnall, and to both the Computer History Museum and the Commodore archive for their considerable archive of material. It is also based on the words of former Commodore executive and computer designer Leonard Tramiel, creator of the PET computer Chuck Peddle, and former editor of Commodore’s print publications Neil Harris. Also, on the words and testimony of Jack Tramiel himself.\n\nMake music—for a run, an ad campaign, or a party—that sounds exactly how you want it, for free. Riffusion uses AI to generate music catered exactly to you, learning from your choices over time and giving you control over what influences your songs.\n\nThey’re rolling out new features constantly. The latest? “Projects.” Which gives you new ways to organize your music—keeping you productive and efficient through the entire creative process.\n\n\n\n\n\nWhen Idek Trzmiel was an adolescent, he worked as a tailor’s apprentice in Łódź, Poland. In 1939, at the start of World War Two, Trzmiel, who was Jewish, was sent to the Łódź Ghetto with his family. He would spend the next five years there fighting to survive and to avoid being deported to Nazi Germany’s extermination camps. In 1944, the Łódź Ghetto was finally liquidated and its remaining occupants were marked for death. Alongside his father, Trzmiel was sent to Auschwitz. During the process of liquidation, they lost touch with Trzmiel’s mother.\n\nBy that time, Trzmiel was 16. He was saved by his ability to work. At Auschwitz, he and his father were among the small number of Łódź deportees selected by the camp authorities for survival. For almost a month, they were used as slave labor within Auschwitz itself, witnessing some of the worst horrors of the Nazi regime.\n\nTrzmiel escaped death at Auschwitz by the narrowest of margins. In August 1944, Germany’s desperate need for slave labor at home meant that approximately 10,000 people were relocated from Auschwitz to a new work camp in Hanover. The Trzmiels were among them. They were saved from death, but this salvation would prove only temporary for many. As slaves, they were treated brutally. Once they were no longer able to work, they were killed.\n\nIn early 1945, this fate befell Idek’s father. Because he was no longer able to work, he was murdered with an injection of gasoline. By April 1945, only 250 of the original slave laborers sent to the camp from Auschwitz were still alive. This number included Idek. They were emaciated and unable to work. The Nazis ordered them to start digging their own graves. Right at that time, American forces finally reached the camp and liberated it.\n\nIdek spent three months recovering in an Allied hospital in 1945. Amid the chaos of liberation and immediate post-war Germany, Idek, like many others, struggled to come to terms with what they had just survived.\n\n“I came out like a wild tiger,” he remembered later. “I wanted to get back everything I had lost.”\n\nLike many survivors, Idek struggled to understand his experience. Over the next two years, he took odd jobs in Germany wherever he could find them. He also became fixated on revenge. When a German police officer disparaged his Jewish background, he beat him, which led to Idek’s arrest and trial for assault. A sympathetic American lieutenant helped him escape jail by telling Idek the exact statutes he needed to cite to be sentenced as a Polish combatant, rather than as a civilian survivor. As a result, he was sentenced to only 30 days of confinement in a military stockade operated by American occupation forces, rather than in a German prison.\n\nWhile serving his sentence, a brief encounter changed the course of his life. “There I met a priest, because there was no rabbi, and he opened my mind up, you know? He said: ‘If you are going to be killing them the same way that they did to you, then what’s the difference between you and them?’”\n\nOnce his sentence was complete, Idek decided that he needed to leave the past—and Germany—behind for good. In November 1947, Idek, who was in his early twenties, emigrated by ship to the United States with the help of a Jewish survivors’ charity. He had married fellow Holocaust survivor Helen Goldgrub a few months before but had to leave her behind. The couple agreed that she would follow once he had secured reliable work. By the time he arrived in New York City, Juda Idek Trzmiel had Americanized his name and become Jack Tramiel. He had no money, job, or connections but was determined to make his mark. He lived out of a shelter for Jewish emigrés, worked odd jobs, and learned English. Then, in 1948, he joined the U.S. Army.\n\n\n\n\n\n\"I felt I owed something to this country,” Tramiel explained later. “And I believed in paying it back.\"\n\nThis idea—that a debt should always be repaid—became the first of a series of rules by which Tramiel decided to live his life. It was his philosophy that applied to everything from relationships to personal choices—and especially to business.\n\n“Jack called his management philosophy ‘the Religion.’ ‘You have to believe in it, otherwise it doesn't work,’ he’d say,” Michael Tomczyk, who worked for Tramiel at Commodore and Atari, later remembered.\n\nAt this stage, “the Religion” was still a work in progress. In many ways, so was Jack himself. He spent four years in the U.S. Army. While in uniform, he returned to Germany, where he discovered that his mother had also survived the war and was reunited with her. On his return to the U.S., he was accompanied by his wife Helen. Thanks to his army position, Tramiel had the paperwork—and financial security—to bring her back to the U.S.\n\nBy the time Tramiel left the Army in 1951, he’d also become a father to the first of three sons. The army had given him a new set of technical skills—typewriter maintenance—that he intended to put to good use. He took a job at a typewriter store in New York but wasn’t there long. Tramiel used his army connections to secure a lucrative repair contract for the store’s owner. In return, he expected to get a raise. When that didn’t happen, he quit on the spot.\n\n“I have no intention of working for people who have no brains,” he told the man. Then, he walked out the door.\n\nA second tenet of Jack Tramiel’s Religion had been laid down: Only work with smart people.\n\nWith the help of veteran grants, Tramiel set up his own typewriter repair shop in the Bronx. The shop was breaking even, but there wasn’t any real scope to expand. That was when another tenet of his Religion was laid down: Always look for opportunities.\n\nIn 1955, Tramiel was selling mechanical adding machines, an early form of the calculator. They were sourced from a company known as Everest. During a conversation with one of its agents, Tramiel learned that the company wanted someone to be its exclusive importer in Ontario, Canada. Tramiel took on the contract and moved his family, including his first son, to Toronto.\n\nIn 1958, opportunity struck again. Sears was looking for a supplier for typewriters in Canada. Tramiel persuaded the company to issue him the contract, along with roughly $175,000 in advanced sales (about $2 million today). It was an extraordinary coup for Tramiel, but he faced one problem: Despite what he’d told the department store, he lacked the knowledge and manufacturing capacity to build typewriters himself.\n\nTramiel approached the leading U.S. manufacturers, including Royal and Smith-Corona, to see if they would help bring the typewriters over to Canada. Both firms refused to supply machines to Tramiel. They wanted him to fail so they could secure the Sears contract themselves. But Tramiel had no intention of failing. He flew to Europe to find the right manufacturing partner. In Prague, Czechoslovakia, he made a deal with a local typewriter manufacturer. Tramiel’s firm would import Czech typewriters to Canada, where they would alter them just enough to be able to rebadge the machines as domestically produced, exempting them from import tariffs.\n\nAll he needed now was a brand name for his rebadging operation. He wanted a word with a military connection, something that would sound authoritative to Canadian Sears customers, but also in the U.S. if he decided to expand there. All the good ones like “General” and “Admiral” seemed to be taken. One day, while in a taxi in Berlin, he saw a particularly stylish car in front. The name of its maker—Hudson Motor Company—was emblazoned on the trunk. So was the model. It gave Tramiel the word he was after.\n\nCommodore.\n\nUnder Jack’s leadership, Commodore was a financial success, but Jack was never satisfied. Whenever Commodore made money, Tramiel would invest it all back into the firm. He expanded existing facilities, spent more on advertising, and purchased new businesses to add to the Commodore brand, including an office furniture factory. This created periods of enormous growth, but also often left Commodore financially fragile and without significant cash reserves.\n\nAnother tenet of Jack’s religion was established: All growth opportunities must be taken, regardless of the financial burden they might place on the company.\n\nIn conversation with Tomczyk, Tramiel acknowledged that this approach was partly a result of his experiences in the Holocaust. He couldn’t trust what tomorrow might bring.\n\n\"’I live in the future,’ he told me. ‘Only the future. There's nothing else.’\"\n\nEventually, this growth came at a cost. In the late 1950s, Tramiel was forced to sell half of Commodore to Atlantic Acceptance, the third largest non-bank lender in Canada. Then, he took out further loans from Atlantic Acceptance, which allowed the company to expand into electronics, such as radios, and office supplies. This time, the price was surrendering the chairmanship of Commodore to C. Powell Morgan, president of Atlantic Acceptance.\n\nThen, in 1965, Atlantic Acceptance collapsed in a financial scandal considered one of the largest in Canadian history. C. Powell Morgan was jailed for financial fraud. Tramiel, too, was investigated for financial fraud, although he was ultimately cleared.\n\nThis was a financial catastrophe for Commodore. The company was heavily indebted to Atlantic, and other lenders called in their loans as well.\n\nTramiel frantically hunted for a new financial patron. What he got was Irving Gould.\n\nGould, born in 1914, was a powerful Canadian financier and owner (or part-owner) of multiple businesses around the world. Although his exact wealth in 1965 is uncertain, the lowest estimates place it in the hundreds of millions (enough to make him a billionaire, in modern terms). That wealth was, in part, built through his ability to spot financial opportunities lurking in the gray area between business activities, and the regulations and tax authorities that governed them. It was Gould who would later create a byzantine corporate setup at Commodore that would see all of its global business profits reported in the Bahamas, saving the corporation hundreds of millions in tax worldwide.\n\nTramiel first met Gould in the fall of 1965. The financier was a man who liked to operate in the background but enjoyed a flamboyant personal lifestyle. Tramiel was the exact opposite. He was a loud, bombastic figure who lived a frugal life. Despite their differences, both men recognized a mutual talent for business. Gould could see that Tramiel knew how to create profitable businesses—with occasional cash flow crises. Each crisis allowed Gould to take a little bit more of Commodore. Once the crisis had passed, Gould would take the money back out.\n\nOn the other hand, Gould had cash to help Commodore survive. During that first investment, he took 17 percent of the company and was appointed chairman.\n\nThis arrangement would cause Tramiel problems in the future, but Gould opened other doors. Their relationship triggered one of the most important events in Tramiel's life: his first visit to Japan.\n\nWhen Tramiel visited Japan in the late 1960s, he realized that Commodore was in the wrong business. There, he saw the future. That future involved electronic calculators, not typewriters. Electronic calculators used silicon chips to carry out the same range of calculations as Commodore’s mechanical machines, but were much smaller, easier to use, and far less prone to failure.\n\n\"I made the trip to Japan and I found out the world was changing,” he later remembered.\n\nAs is often the case with the history of Commodore, why Tramiel decided to make that trip is open to question. Tramiel often claimed it was on his own volition, but Gould was a life-long Japanophile with shipping interests (and a mistress) there.\n\n“Yeah. Irving [Gould] told Jack to get his ass to Japan,” Chuck Peddle, later one of the most important figures at Commodore, told the Computer History Museum bluntly in 2019.\n\nWhatever the reason, Tramiel was deeply influenced by his trip. Upon his return, he pivoted Commodore to the calculator business, importing Casio calculators and rebranding them for Canadian and U.S. markets. Soon, Commodore set up factories to build calculators of its own in the U.S. These were funded by Irving Gould—in return for a little bit more of the company.\n\nFor five years, Commodore flew high in the calculator business. Tramiel bought silicon chips from domestic manufacturers such as Texas Instruments, one of the largest chip makers in the world, and turned them into calculators, selling the finished product at considerable profit. He wasn’t the only one doing this. In Albuquerque, an ex-Airforce officer named Ed Roberts had founded a company called MITS that was doing the same.\n\nBoth men were generating large profits, but Texas Instruments was watching. Texas Instruments decided to start making calculators itself, and because the company made its own chips, it could make the machines cheaper than anyone else. By 1974, it was selling almost 30 million calculators a year, destroying the market for third-party calculator manufacturers like Commodore and MITS almost overnight.\n\nIn Albuquerque, Ed Roberts reacted by accepting his defeat. In what would prove to be a key moment in the history of computing, he pivoted MITS to produce a personal computer known as the Altair 8800. Tramiel took a different lesson from the experience. He added a new tenet to his Religion: Always control the means of production.\n\n\"I had to decide a way I could not depend on the outside. How to become vertically integrated.\"\n\nBeing vertically integrated meant Commodore, like Texas Instruments, had to make its own chips. But chip manufacture was highly specialized. It wasn’t something you could start doing overnight. So Tramiel, ever ruthless, decided to take over someone else’s chip business instead.\n\nThat business was MOS Technology. Founded in 1969, MOS had perfected low-cost chip manufacture by the mid-seventies. At the beginning of 1975, it stunned the computer industry by announcing the launch of the 6502 central processing unit (CPU) chip for just $25. Meanwhile, rivals Motorola and Intel were selling their own equivalents for $179.\n\nMOS Technology seemed to be on the verge of a bright future, but the company was in deep financial trouble. In part, this was because of a lawsuit from Motorola. It was also because MOS was sitting on a huge pile of unpaid invoices from calculator manufacturers—most notably Commodore, which was in deep financial distress due to its competition with Texas Instruments and Tramiel’s financial strategies.\n\nTramiel sensed a way he could save Commodore. Instead of paying his bills, he returned to Irving Gould. Gould injected sufficient capital to allow Tramiel to buy the near-bankrupt MOS. For another slice of Commodore, of course.\n\nOvernight, Commodore became a major manufacturer of chips. Tramiel had vertically integrated his production line. He also took something else from MOS. The deal was conditional on one man leaving MOS and working directly for Tramiel at Commodore: the designer of the 6502 chip itself, Chuck Peddle.\n\n\n\n\n\n“The 6502 was specifically designed to be the universal solvent. It's just enough, and it's simple enough, and it's cheap enough that you can use it for anything,” Peddle told the Computer History Museum.\n\nThe Altair 8800 had proved that a market existed for low-end computers, but Peddle was one of the first to spot the market’s true potential. While at MOS, he designed the KIM-1, an extremely basic computer using the 6502 to prove it could be done.\n\nPeddle had caught Tramiel’s attention not because of the KIM-1, but because Tramiel wanted a way into a growing off-shoot of the calculator market—chess calculators, or machines that would play you at chess. Once Peddle joined Commodore, however, he suggested to Tramiel that they go one further. Peddle pointed out that the Altair 8800 released by MITS for the computer hobbyist market had shown that there was demand for personal computers. He told Tramiel that they shouldn’t waste time with calculators. Instead, they should build a computer based on the 6502 chip.\n\n“I can build a personal computer that can sell,” Peddle told Tramiel.\n\nTramiel had no real understanding of what a computer was or why people might buy one. But Peddle was a smart man offering up an opportunity. That fulfilled the two tenets of Tramiel’s Religion—work with smart people and look for opportunities. So he told Peddle to do it.\n\nPeddle had talked briefly with Steve Jobs and Steve Wozniak when they were working on the Apple computer. He knew the two men were hoping to use the 6502 chip in their next machine, the Apple II. So he suggested that they let Commodore buy them out. Jobs was excited by the possibility.\n\n“Steve [Jobs] started saying all we want to do was offer [Apple] for a few hundred thousand dollars, and we will get jobs at Commodore, we’ll get some stock, and we’ll be in charge of running the program,” Wozniak said later.\n\nJobs and Tramiel sat down to negotiate. Overconfident, Jobs told Tramiel they wanted $150,000 (about $850,000 today) for Apple. Tramiel was prepared to back Peddle’s idea, but spending that much money on a company based out of a suburban garage seemed ludicrous. Jobs’s attitude also annoyed him. So he walked away from the negotiations, and told Peddle he had three months to assemble a team and design the computer himself. He wanted it ready for the January 1977 Computer Electronics Show (CES).\n\nPeddle tried to explain that this was too short a deadline, but Tramiel waved his objections away and added a new tenet to the Religion: Give smart people a clear deadline and they’ll somehow figure it out.\n\nPeddle set about designing and building a bespoke Commodore computer. At the time, MITS’s Altair 8800 dominated the hobbyist market, while companies like Vector Graphic were making machines like the Vector 1 for small and medium businesses. Both machines required users to understand complex machine language if they wanted to create their own programs. Peddle believed that this was a mistake. He concluded that the first successful mass market computer would be one that people felt that they could program themselves. He designed a machine that came with a keyboard and monitor. Then, he set about sourcing a human-readable programming language. He decided that the language that best met that requirement was Microsoft BASIC.\n\nPeddle approached Bill Gates at Microsoft and requested a version of Microsoft BASIC for the 6502 chip. Gates was skeptical. He thought the chip would use up so much processing power it would cripple the machine, but agreed to do it anyway. Peddle suggested a contract where Microsoft would receive a royalty for each machine sold. Gates laughed him off. He didn’t think the thing would sell, and he wanted the money upfront.\n\nRather than charge Commodore a small fee for every machine they sold with BASIC on it, Gates offered a perpetual license. In return for a fixed fee, Commodore would be given a version of BASIC that it could install on as many machines as it liked, for as long as it wanted.\n\nCommodore and Microsoft never revealed how much the deal cost, but most estimates have placed it at about $25,000. Commodore would go on to use that version of BASIC for every single Commodore designed and released during Tramiel’s time in charge—somewhere north of 15 million machines. In modern terms, the deal cost Microsoft more than $400 million in lost revenue. Bill Gates never made a fixed-fee deal again.\n\nAt CES 1977, the Commodore PET was revealed to the world, wrapped in a stainless steel case that was made by a filing cabinet factory that Tramiel owned in Canada. PET didn’t stand for anything. It was just a pun on the popularity of pet rock toys at the time.\n\n\n\n\n\nThe machine was an instant hit. The only problem was that Commodore did not have the money to set up the manufacturing capacity necessary to bring it to market. Peddle raised this concern with Tramiel, who laughed it off.\n\n“He says, ‘When HP first started selling calculators, you had to pay them in advance for 90 days,’” Peddle remembered. “So he said, ‘We're going to do that.’”\n\n\"Three million bucks in advanced sales,” Tramiel later confirmed with a grin in a Computer History Museum interview. “We knew we had a winner.\"\n\nTramiel suspected that no customer would ask for their money back once they’d pre-ordered the device, as long as they thought it was eventually on the way. Using pre-payments as a form of seed capital, Commodore was able to quickly build up the manufacturing capacity required to turn MOS chips into full-fledged computers, and to source monitors and keyboards to use with them. This strategy was successful, and several other computer firms followed suit. Unlike Commodore, not all of them delivered. Adam Osborne, one of the computing industry’s rising voices, raged about these practices in his Information Age column. He said that companies that used the pre-payment method gave the new computing industry a bad name and alienated potential users.\n\nTramiel shrugged the criticism off. He wasn’t in business to be nice. By 1980, thanks to the PET, Commodore was the third largest computer manufacturer in the world.\n\nThe success of the PET changed Commodore. From this point onwards, it was a computer company—and a global one at that. With Tramiel’s agreement, Gould restructured the business into a series of regional subsidiaries under a single parent company based in the Bahamas.\n\n\n\n\n\nGould designed this structure to minimize Commodore’s tax bills and avoid, as much as possible, the need to file detailed reports and accounts. The structure also mitigated a growing problem for the company: that of managing Jack Tramiel.\n\nAccording to Tramiel’s management philosophy, his Religion, he needed control over almost all aspects of day-to-day operations. He wanted to interview every hire and sign off every expense. He wanted to be the final decision-maker in all aspects of design, sales, and marketing. He was obsessed with control.\n\nWhen Commodore was small, this wasn’t an issue. As the third-largest computer manufacturer in the world, with subsidiaries across the globe, it didn’t work as well. Different markets required different approaches to sales. They used different regulatory frameworks, time zones, and languages. It simply wasn’t possible for these subsidiaries to function if every decision or invoice had to be run past Jack Tramiel back in California\n\nOn top of this, Jack Tramiel demanded absolute dedication and loyalty from his staff. He expected managers to be able to answer any question he asked about their teams or projects, and did not tolerate failure from anyone—no matter the reason.\n\nIf Tramiel felt someone had failed him, then no mercy would be offered. Failure often led to dismissal without warning. If Tramiel felt the employee still had some use or potential, he would subject them to what Commodore insiders called a “Jack Attack.” They would be summoned to Tramiel’s office and subjected to his full wrath. Sometimes, it would happen on the floor in front of the entire department. He would berate and insult them, question their competence and ability, and strip them of their projects or authority. Often, they would be summarily transferred to a distant location within the growing Commodore empire and given tasks well below their level or skill.\n\nLong-term Commodore employees realized that these exiles were always temporary. This was a penance they were expected to perform. If they didn’t quit, they would eventually be summoned back and given their old responsibilities back. Sometimes, they found themselves trusted with even more. Tramiel seemed to believe that surviving a Jack Attack demonstrated character.\n\n\"I wanted Commodore to be a family. Everyone should work together,” Tramiel said later, when asked about his reputation for Jack Attacks. “My personal job was not to tell them how good they are. But to tell them what they were doing wrong.\"\n\nAs a management method, it created a set of die-hard, talented loyalists around Tramiel who began to refer to themselves internally as the “Commodorians.” But it also created a hostile working environment that meant Commodore struggled to retain new talent.\n\n“Once I asked Jack point-blank why so many managers got fired or resigned from Commodore. ‘Business is war,’ he said. ‘You have to be in it to win. Our generals are all in the trenches, so more of them get killed,’” Tomczyk remembered.\n\n“He comes in like a lighted flare in a darkened room. He illuminates the scene with such brilliance that you’re almost blinded,” said James Finke, one of the many presidents Irving Gould put in place at Commodore to try and manage Tramiel. “But his vapor trails take a lot of the oxygen out of the air, and when he leaves the room there’s no more light.”\n\nTramiel wasn’t entirely happy with Commodore’s new structure. He negotiated to retain full control of Commodore’s U.S. arm, including chip design, manufacturing, and global strategy. Gould was happy to agree. His goal was to shield the regional subsidiaries from Tramiel’s need to micromanage, and it worked. This strategy was particularly successful in the U.K., Germany, and Japan, where talented regional managers pushed Commodore’s growth in ways that were hyper-optimized to their local markets.\n\nAlmost as soon as the PET, Commodore’s first computer, hit the shelves, Tramiel was pushing Peddle to design a new one. Peddle believed it was time to push the boundaries of what a home computer could do and began work on what became known as Project TOI (“Tool of Intellects”).\n\nHowever, Tramiel and Peddle had opposing visions, and relations between the two started to deteriorate. Ever since Tramiel had first visited Japan, he’d become obsessed with the Japanese approach to technical development. It wasn’t just about pushing the boundaries of what was technically possible. It was also about finding ways to drive down costs. Doing so would create new buyers for technology by lowering the financial bar to entry.\n\nPeddle wanted to deliver a generational leap in technology. Tramiel was happy being second, but cheaper. What he saw was a market full of computers, all priced roughly the same, competing for the same buyers. He didn’t want a computer better than the Apple II, which was a popular choice. He wanted something that was comparable but cheaper.\n\nAnd Commodore could go cheaper, because Apple didn’t make its own chips. The Apple II was built around the 6502 chip, which it was buying from Commodore-owned MOS Technology. Tramiel believed he could do to Apple with computers what Texas Instruments had done to him in the calculator market—release a much cheaper product, and outcompete.\n\nThe only point on which both men agreed was that the new machine needed to support color displays, something most computers at the time didn’t have the processing power to do.\n\nPeddle didn’t cede, and it wasn’t long before a different group of engineers within Commodore approached Tramiel with something closer to the kind of computer that he wanted. Bob Yannes, another engineer at MOS, had built a prototype known as the MicroPET. As with Peddle’s KIM-1, it wasn’t a full computer design. However, it proved that an evolved version of the PET could deliver everything Tramiel wanted—including a cut in production cost. Tramiel ordered parallel development to start on the project, code-named Project Vixen.\n\nFor a while, development on both machines continued. Things finally came to a head in April 1980 during a conference in London with the leaders of all of Commodore’s subsidiaries. For several days, debate raged over which project should be taken to production. Peddle and most of those present demanded all effort be focused on Project TOI. Only two voices spoke in support of Project Vixen: Kit Spencer of Commodore U.K. and Tony Tokai of Commodore Japan. It was not lost on Jack Tramiel that they were the two regional heads he rated most highly.\n\nFinally, while all the key players were gathered for a pub lunch on the last day, Tramiel rose from his seat and pounded the table once with his fist. Everyone fell silent.\n\n\"Gentlemen,” Tramiel growled. “The Japanese are coming. So we will become the Japanese!\"\n\nHe had listened to all the arguments, but it was his company. His decision was that the next machine would focus on driving down costs. Project Vixen, which had started as the MicroPET, won. The decision marked the end of the successful relationship between Peddle and Tramiel. True to his ruthless reputation, Tramiel forced Peddle to leave Commodore not long after.\n\nMeanwhile, the joy of the Project Vixen team was short-lived. Tramiel issued a mandate that the machine launch at CES in January 1981, only eight months away.\n\nThis tight deadline was made worse as the team found that Peddle (who hadn’t yet left the company) and most of the Commodore U.S. research arm were indifferent or actively hostile to their efforts. They had wanted Project TOI and believed Vixen was doomed. They had no desire to work on it, and they believed that doing so would risk incurring the wrath of Jack Tramiel when it failed.\n\nProject Vixen might have been doomed, except for a quirk of Commodore’s new subsidiary structure. Out of respect for Japan’s electronics industry, Tramiel had allowed Commodore Japan, under Tony Tokai, to build a large research and development arm of its own. Tokai was one of the two subsidiary heads who had backed Tramiel’s decision to choose Project Vixen. The Vixen team asked Tokai for support, and he gave it to them.\n\nTokai’s support proved critical to Project Vixen’s success. He placed all of his development resources at the project team’s disposal. This included an engineering team led by Yash Terakura, Commodore Japan’s talented chief engineer.\n\nThanks to this injection of talent and personnel, the VIC-20 was finished in time for CES 1981—just as Tramiel had demanded. The VIC-20 was barely better than the PET, but it did have color, and could be hooked up to either a monitor or a television. This became a common practice, particularly outside the U.S., and it wasn’t unusual to see a home computer beneath, or alongside, a family TV in many households. However, what stunned everyone was the price. Commodore U.S. and Commodore Japan were both masters of cost reduction in different areas, and their cooperation accidentally created a masterpiece. The machine cost just $299.95 (about $1,000 today), which was less than half that of any other comparable machine on the market.\n\n\n\n\n\nAny doubt over whether Tramiel was correct evaporated once the orders came in. In 1983, two years after launch, the VIC-20 passed 1 million computers sold. It was the first computer to reach that milestone, beating the Apple II despite launching two years after it.\n\nCommodore had made the first true home computer, rather than a microcomputer, as it had often been referred to before. Microcomputers like the Altair were for hobbyists—people who wanted technology to tinker with. The PET was a microcomputer as well. Others like the Apple II or the soon-to-be-released IBM PC were pitched as business or productivity machines, while companies like Atari or Intellivision created games consoles.\n\nMost families didn’t have the kind of money—often $500 or more—required to buy a computer that was specialized around one of those goals. It made buying a computer a luxury purchase. The genius of the VIC-20 was that it could do all of these tasks. It was a machine you could tinker with, use for basic business productivity tasks, or play games on—all for less than $300. You could even hook it up to your television as a monitor if you couldn’t afford to buy one to go with the computer.\n\nSuddenly, every child or teenager who had been pestering their parents for something they could play games on had an argument they could make for buying a VIC-20 that they couldn’t for an Atari. The VIC-20 was educational. It was a computer. It just happened to also play games. This helped adults—many of whom wanted to play games just as much as their children did—justify the decision. Commodore ensured that a series of critically acclaimed text adventures were available to buy at launch, targeted at exactly these grown-up gamers.\n\nIt didn’t take long for Commodore to make the home computer the prime focus of its marketing message. They also found the perfect voice for the machine of the future: William Shatner.\n\n\n\n\n\nThe VIC-20 helped Tramiel decide the final tenet in his Religion: Low cost is everything.\n\n“Computers for the masses, not the classes,” he was quoted saying after the launch of the VIC-20.\n\nThen, in November 1981, less than a year after its launch, Tramiel decided it was time to create a successor.\n\nThe catalyst for the successor came, once again, from inside MOS Technology. Its chips now lay at the heart of various non-Commodore gaming systems, including the Nintendo Entertainment System and Atari’s full line of systems. The subsidiary had also been working on designing chips for a new generation of video game consoles. This included its VIC-II video chip as well as something new and revolutionary: the SID chip, for sound generation.\n\nBy the middle of 1981, MOS was struggling to find an outside buyer for the VIC-II and SID chips. They were bleeding-edge technology aimed squarely at video game console manufacturers. But that market had seen a downturn in investment. Ironically, this downtown was because of the arrival of home computers such as Commodore’s.\n\nIn November 1981, frustrated that his revolutionary design was languishing on the shelf, the SID chip’s designer went to Jack Tramiel. He dragged along Al Charpentier, the creator of the VIC-II, and MOS general manager Charles Winterble for support. He argued that Commodore should use the chips in a new computer instead of video game consoles, and that they should make a VIC-20 successor built around the VIC-II and SID.\n\nTramiel recognized the designer. It was Bob Yannes, the same man who had brought him the MicroPET that had become the VIC-20.\n\nYannes had already given Commodore its biggest success (tenet one). He was clearly a smart man (tenet two). Though it might harm VIC-20 sales, there was a market opportunity (tenet three). Not least because Commodore owned the means of production for both the VIC-II and SID chips (tenet four). Jack Tramiel signed off on the project. The Religion demanded it.\n\nYannes left the room under orders that the new machine should be ready in time for CES 1982, less than two months away (tenet five). The Religion demanded that, too.\n\n\n\n\n\nThe deadline was short but not impossible. With Commodore’s vertical integration, board and chip prototyping could be done in house. Other home computer companies had to create chip designs, send them off to a chip manufacturer, and wait for them to be produced. At Commodore, it was just about finding spare staff or production downtime at MOS Technology. Nor did the team have to worry about project or fiscal management. Tramiel didn’t believe in such things.\n\n“I had no formal budget accountability,” Winterble said later. “Other than Jack watching me. Jack said that budgets were a license to steal.”\n\nThe VIC-20 also gave the project team a solid headstart in components and casing for the new project—there is a reason that the VIC-20 and Commodore 64 look so similar. Even with the headstart, the production process was lightning-fast. The most successful computer that the world has arguably ever seen went from paper to production in just under six weeks.\n\nThat machine launched at CES in January 1982 as the soon-to-be-legendary Commodore 64. The 64 was a reference to the 64 kilobytes of RAM the machine contained. This had been the only other stipulation from Jack Tramiel to the team, even though this amount of RAM was expensive at the time, and was far more than most other home computer manufacturers included in their machines.\n\n“Jack made the bet that by the time we were ready to produce a product, 64KB of RAM would be cheap enough for us to use,” Charpentier said later. Tramiel was right.\n\nThe Commodore 64 stunned both the industry and the press. It wasn’t just its groundbreaking design (which was due to the VIC-II and SID). It was the price. Other machines on the market with the same broad range of specifications as the Commodore 64 were retailing at $1,000 or above. The Commodore 64 was priced at barely half that.\n\n“All we saw at our booth were Atari people with their mouths dropping open, saying, ‘How can you do that for $595?!” David Ziembicki, one of the Commodore 64 project team, remembered.\n\nThe cost of making the Commodore 64 dropped once production started. Another manufacturer with such a significant price advantage may have been tempted to bank these efficiency savings as profits, but that wasn’t Tramiel’s way. Whenever production costs fell, he dropped the retail price further. This created a permanent price war with his competitors, who were often forced to sell their own machines at a loss.\n\nCommodore was now offering a record-making machine at a rapidly dropping price, one with a growing range of games from developers who loved its chipset. Commodore’s rivals desperately tried to match Tramiel’s price cuts to compete, but they couldn’t match the company’s vertical integration. Several were driven out of the business entirely. In a twist of fate, one of those companies was Texas Instruments. It had pivoted from calculators into computing; now it was Commodore’s turn to drive it out of the computer business instead.\n\nTramiel admitted that he found this very satisfying. Revenge is a form of debt, so it needs to be repaid. Tenet one.\n\n\n\n\n\nOver 12 million Commodore 64s were sold during its remarkable 12-year production run. By some estimates, this made it the highest number of computers sold of any type, ever. It marked the peak of Tramiel’s time at Commodore. It was the culmination of all his principles on how a business should be run. It took everything the VIC-20 had pioneered and distilled it into its perfect form. No computer has ever captured the time, the place, and the technology better.\n\n\n\n\n\nIt also did something that nobody could ever have anticipated. Over its 12-year run (which was itself likely another record), it opened up computing to people from backgrounds who never dreamed they would have access to it. Tramiel’s policy of ruthless price-cutting saw to that.\n\n“I firmly believe that Commodore launched more tech careers than any other company, by far,” said Matthew Gracie, a senior engineer at Security Onion Solutions. “Even a working-class family like mine in the 1980s could plausibly afford the Sears bundle of a Commodore 64 and monitor. That set me on my path.”\n\nCES 1983 didn’t bring any major new announcements from Commodore, but nobody was overly concerned. Both the Commodore 64 and its precursor, the VIC-20, were selling in extraordinary numbers. Behind the scenes, Tramiel was pushing for a new computer line that completely diverged from the PET/VIC-20/Commodore 64, and would focus more explicitly on business and education.\n\nHowever, from the moment development began, it was troubled. A lot of that trouble was created by Tramiel, his management philosophy, and his Jack Attacks.\n\nComputing was changing. Advances in technology and user expectations meant that machines and chips now required more intense—and more planned—development. Development like that took time and cost money, neither of which Tramiel believed in providing.\n\n“Tramiel is not an investor,” Peddle said later. “He never invested in any development activity…He never invested. Which is what it takes to get a new high-capability processor.”\n\nThe PET, VIC-20, and Commodore 64 were all the result of chip development at MOS that had started prior to Commodore’s takeover, or were designed by the few smart and talented people who could tolerate Tramiel’s Jack Attacks. That was a shrinking pool.\n\nBy now, there was a shadow management layer operating within Commodore, built around the “Commodorians”—the people who knew how to manage, and survive, Jack. This often didn’t align with the official management chain. It created constant change in staff at the executive level within Commodore, and the firm was incapable of retaining talent.\n\nDespite all of this, CES 1984 began with the launch of the Commodore 16 and the Commodore Plus/4—the first two machines of the new business-friendly line. Tramiel himself took to the stage to announce that Commodore had reached $1 billion in sales—a first for the entire personal computer industry. This was a moment of celebration, but something seemed off for the experienced Jack-watchers in the room.\n\n“Jack was on stage and he didn't look like a happy man, and Jack was not someone to hide his emotions generally—it just seemed strange for some of us in the back of the room,” Neil Harris, then-editor of Commodore’s print publications, remembered.\n\nShortly after this appearance, Tramiel departed CES. Three days later, he met with Irving Gould. Immediately afterwards, to the shock and amazement of the computing world, Commodore announced the departure of Jack Tramiel.\n\nBehind the scenes at Commodore and unbeknownst to most, a struggle for power had been underway between Irving Gould and Jack Tramiel.\n\nOver time, two distinct narratives have emerged for what happened that day. The first is that Gould had become increasingly frustrated and angry with Tramiel’s aggressive management style, including his obsession with maintaining personal control over strategy and spending within Commodore. Gould decided enough was enough, and fired Tramiel.\n\nThe other narrative is that Tramiel had become increasingly frustrated with the way Gould treated Commodore’s assets as if they were his own, and took money out of the company. Tramiel had tolerated this as long as Gould didn’t interfere with how Tramiel ran the company, but when Gould blocked Tramiel from appointing his sons to the Commodore board, Tramiel quit in disgust.\n\nDebate continues to rage to this day over which of those narratives is closer to the truth. What that debate tends to miss is that both accounts are likely true.\n\nIn September 1983, just a few months before CES 84, Osborne Computing had gone bankrupt. The company had produced the Osborne 1, the first truly portable computer, and was seen as a stable and successful business with a bright future. Its sudden and spectacular fall sent shockwaves through Silicon Valley. Adam Osborne, its flamboyant founder, was already defending himself from accusations that his autocratic and chaotic personal leadership style had caused the implosion. Meanwhile, IBM—the most traditional and conservative among technology companies—had come from nowhere to dominate low-end business computing thanks to Don Estridge’s IBM PC.\n\nIt’s easy to imagine Gould wondering if Commodore, his golden goose, would be ruined by Tramiel—his Adam Osborne. Gould had tried multiple times to establish a senior management structure that conformed with standard expectations of how a billion-dollar multi-national business like Commodore should operate. His efforts had continually been undermined by Tramiel and his loyal Commodorians. There are even rumors that Tramiel insisted that one or more of his sons be elevated to the board, strengthening his control.\n\nOn the other hand, there is no doubt that Gould had been taking enormous amounts of money out of Commodore. He regularly treated corporate assets (including the company jet) as if they were his own. This was infuriating to the eternally frugal Tramiel, who still regarded Commodore as his company, not Gould’s. From Tramiel’s perspective, Gould’s continuous attempts to add layers of unnecessary management was an expensive mistake, a direct threat to his control, and a risk to the financial health of the company. If Gould wasn’t going to let Tramiel build Commodore his way, there was no reason for Tramiel to stay there. It was natural for him to have wanted out.\n\nBoth men wanted Commodore to continue growing, but they disagreed over the way to make that happen. It was a battle between Jack Tramiel’s Religion and Gould’s vision of Commodore as a corporate clone of IBM. The result, at that fateful January meeting, was a short but decisive war for the soul of Commodore. As Commodore’s chairman and its largest shareholder, it was a war that Gould was always going to win.\n\n\"It was like the air went out of the room.” Neil Harris said, remembering how it felt when the news became public. Most people assumed that this would be the end of Jack Tramiel.\n\nIn the immediate aftermath of his resignation, Tramiel told former colleagues and the press that he planned to spend a year traveling the world. Three months later, Tramiel and his wife were at a hotel in Sri Lanka when he was summoned to the phone. On the other end of the line was Steve Ross, the CEO of Warner Communications.\n\nWarner had a problem—a problem called “Atari.” Warner had bought Atari in 1979. Atari’s iconic line of home videogame systems, featuring titles such as Pong, Pac-Man, and Super-Breakout, had made it the most successful home video-gaming company in the world. Almost immediately after Warner’s purchase, a crash in the video game market tanked its value. Since then, it was losing hundreds of millions of dollars a year. Warner’s share price weakened the company so much that media tycoon Rupert Murdoch nearly executed a hostile takeover of the entire company. Ross successfully fought it off, but he knew that he might not be able to do so again. He wanted to ask Tramiel if he would consider becoming Atari’s new CEO.\n\nTramiel refused and instead made Ross a counter-offer: Warner should simply give him Atari instead. Warner’s CEO was confused but intrigued, and Tramiel flew back to Silicon Valley to explain his plan.\n\nAfter this, things moved fast. In early May 1984, a small group of Commodorians were invited to meet with Tramiel at a rented room in a small apartment complex in Sunnyvale, California, near Atari’s headquarters. Among them was Shiraz M. Shivji, Commodore’s director of research and development and a former member of the Commodore 64 development team. Tramiel told them what was coming and swore them to secrecy.\n\nOn May 17, 1984, Tramel Technology Ltd. was founded. The spelling was deliberate. Tramiel had grown tired of people mispronouncing his name.\n\nMeanwhile, over at Commodore, a number of Tramiel’s old Commodorians started to resign from the firm.  Initially, these departures didn’t raise much suspicion or alarm in Gould’s reworked C-Suite. This changed at 4 a.m. on July 2, 1984, when Warner Communications announced that it had sold Atari’s entire home computing arm, including all of its assets, facilities, and the brand, to Tramel Technology, owned by Jack Tramiel.\n\nTramiel may have been on vacation when Ross called him, but his business instincts were as sharp as ever. He exploited Warner’s desperation to be rid of Atari to propel himself instantly back to the top of the computer business. But he did it on his terms, not the company’s.\n\nWarner lent Tramel Technology $240 million in return for the option to buy up to 32 percent of Tramel Technology at a predefined share price. Tramel Technology used that money to buy Atari from Warner. In effect, Tramiel made Warner pay for him to take Atari—and the huge liability it represented—off its hands. In return, Warner had the option to get a chunk of the value back if he managed to turn the company around.\n\n“Both the home computer and video game marketplaces continue, in my view, to offer great opportunities,” Tramiel told the Associated Press that day.\n\nThe scale and speed with which Tramiel was moving quickly became apparent. By lunchtime, Jack had installed himself in the CEO’s office at Atari’s headquarters in Sunnyvale, California. Alongside him were his three sons—newly appointed company directors—and more than 20 new Atari senior executives. They were his loyal Commodorians, swapping roles at their former employer for near-identical roles at Atari—including Shiraz Shivji and Commodore Japan’s Tony Tokai.\n\nGould and Commodore’s new C-suite realized that Tramiel was looting them of talent. Then, to their horror, they discovered that they had no way of stopping it. It turned out that many of the best and brightest at Commodore didn’t have non-compete clauses. Many didn’t even have written contacts. The former head of Commodore had never really believed in such things. A good, solid handshake was enough. That former head was, of course, Jack Tramiel.\n\n\"The word started passing through the grapevine, after Jack bought Atari, that if anyone was interested, there were opportunities out there,” Neil Harris remembered. He handed in his notice shortly after. He, too, was off to Atari.\n\nJack was back. He announced that Atari would unveil a new machine—one that would surpass anything Commodore had planned for the Consumer Electronics Show in January 1985, just six months away.\n\n\n\n\n\nTramiel didn’t have a new computer ready to go. He just knew that he needed one. Atari was bleeding cash and his only chance of Atari competing with—let alone beating—Commodore at its own game was if he got a next-generation home computer out before his former company did. He also knew that Commodore had already begun development on such a machine.\n\nJust before Tramiel’s takeover of Atari became public, Commodore had announced the purchase of Amiga, a struggling computer company that already had a much-hyped machine in development. Commodore planned to release this machine as the Commodore Amiga in early 1985.\n\nTo make things worse for Atari, Commodore also filed a legal case against Shiraz Shivji and several of the other engineers that Tramiel had poached. Commodore accused them of intellectual property theft, alleging that they had taken commercially sensitive documents and designs from Commodore when they left. This was swiftly settled, but it delayed Shivji from starting work on Atari’s new machine by another month.\n\nFor a brief moment, it seemed like Tramiel had finally been outmaneuvered. The Amiga was already half-built. Commodore would beat Tramiel to market, unless he could find a way to undermine the company yet again.\n\nIt was Jack’s son Leonard (the middle of his three boys) who gave him what he needed to turn the tables. Tramiel had tasked Leonard with chasing down old payments that Atari had due from partners or suppliers, and in a stack of checks he found one to Amiga.\n\n“I looked through that stack of checks and pulled out ones that were either big, or had interesting people they were made out to,” Leonard recalled. “And one of them was [a] canceled check for the money that Atari gave to Amiga.”\n\nThe check was for $500,000 (almost $1.5 million today) paid to Amiga by Atari in early 1984. Leonard took it to Tramiel, who sensed that there was something lurking behind it that he could use to hamstring the release of the Commodore Amiga.\n\nTramiel discovered that Atari had loaned Amiga $500,000 in early 1984 to help the latter stave off bankruptcy, prior to his takeover. As collateral, Jay Miner, one of Amiga’s founders, agreed to enter talks that would allow Atari to use some of the chips the company had designed for its Amiga computer. The loan was a good-faith payment to ensure Amiga could keep running while the companies negotiated a royalty fee. If Amiga and Atari didn’t agree on a fee within 60 days, Amiga would have to pay back the loan with interest. If they failed to do so, Atari would get the rights to use Amiga’s chip designs for free.\n\nFrom Atari’s perspective, this was a smash-and-grab on Amiga. Atari had no real intention of negotiating. In 60 days, the company would get chip designs that were worth far more than the value of the loan. What nobody at Atari realized was that Miner had no intention of negotiating, either. He was gambling that the extra 60 days of development that the money secured would allow Amiga to refine its computer design further and finally find a buyer for the whole machine elsewhere.\n\nEnter Commodore.\n\nThe extra development time allowed Miner to demonstrate a more complete machine to potential buyers, one of which was Commodore. In fact, Commodore was so impressed with Amiga’s machine that it decided to buy Amiga as a company. As negotiations between Amiga and Commodore neared completion, Miner revealed the details of the loan from Atari. Unwilling to give chip rights to a competitor, Commodore wired Miner enough money to cover paying off Atari. Miner delivered the check for the full amount personally to Atari the same day, just one day before the deadline on payment would have expired.\n\nAtari was surprised, but thanks to the interest payments on the loan, the company had still made money for effectively doing nothing. So the paperwork was filed away and forgotten about, until Leonard Tramiel stumbled upon it.\n\nOnce he learned the full details in July 1984, Jack Tramiel sued Amiga, its founders, and Commodore. He argued that Atari had the right to use Amiga’s chips, and Commodore should cease development on its computer until the terms of that agreement could be negotiated. This was because Atari had loaned Amiga the money in good faith, but there was no evidence that Amiga had opened negotiations (Tramiel’s lawyers skipped over the part where Atari hadn’t opened negotiations, either).\n\nThe case was spurious at best, and Tramiel knew it. But he didn’t need to win. What mattered was that it brought Commodore’s plans to bring its Amiga computer to market to a screeching halt while the case was being settled.\n\nThe Commodore run by Jack Tramiel would have spotted that the case was a spoiler action and settled immediately. The new Commodore didn’t. Its executives could see that Tramiel would lose the case in court, so they decided to fight it. It took a few months for them to realize that Tramiel didn’t care about winning, only about the development delay it was causing them. Once that had sunk in, they bought him off, agreeing to an out-of-court settlement that Tramiel later described as a “rather large seven-figure sum.” By that point, however, the damage had been done. While the two parties were arguing in court, Jack’s ex-Commodorians had been completing the design of his promised new computer.\n\nThat computer, when it launched, was called the Atari ST. It beat the Amiga to market by over a month.\n\nThe Commodore Amiga and Atari ST stand together as the last great machines of the home computing age, before 32-bit games consoles and PCs would come to dominate. While debate still rages over which machine is better, it’s remarkable that Atari’s machine was even in a position to compete with Commodore’s. The Commodore 64 will always be the peak of Jack Tramiel’s “Religion,” but the Atari ST deserves an honorable mention as the last time his principles actually worked.\n\nTramiel’s new colleagues took the experience they had built up at Commodore and created a machine that featured a Motorola 68000 chip. Like the Commodore 64, it launched with more memory than most competitors—512kb of RAM, which could be upgraded even further. Like the Commodore 64, the computer was reasonably priced—less than $800 (about $2,300 in 2025).\n\nCommodore’s woes were far from over. The company even lost the case it had originally filed against Atari, that some of its employees—including Shivji—were stealing IP for the new company. While the engineers were forced to return some documents they had taken from Commodore when they departed, the court ruled that no infringement of Commodore’s intellectual property took place during the design of the Atari ST.\n\nIn most cases, this would be the end of the story. But no story involving Jack Tramiel is ever that simple. Eyebrows have often been raised in computer forums across the internet at the alleged design similarities between the Atari ST and an aborted Commodore computing project called the “Commodore 900.” Those eyebrows were only raised further when Commodore veteran David Haynes was asked directly about the Atari ST’s origin in 2011.\n\n“At one point while at Commodore, Jack had a few of the then-C900 engineers (I guess they were the second team on the project) meeting ‘off-site’ on some super-secret project. This was probably late 1983 or early 1984,” Haynes replied. “Shortly after Jack left, those guys all followed, and of course surfaced at Atari. With a new 68K computer that looked an awful lot like the second spin of the C900. Well, other than the fact it actually worked this time.”\n\nWhether there is any truth to Haynes’s allegation is unclear. What is indisputable is that Atari achieved a hardware miracle and had the new Atari ST ready for launch by January 1985. It received broadly positive reviews from both industry experts and the wider press. Impressed, they provided it with its nickname: the “Jackintosh.” The Atari ST, and its later variants, sold almost 2 million units.\n\nTramiel confounded both the critics and Gould. He revived Atari almost overnight. It was a remarkable achievement, but it would be his last in the world of computing.\n\nIn 1996, Atari announced that it was merging with disk-drive manufacturer JT Storage. It was only a merger on paper. In reality, JT Storage was buying Atari out. After 11 years of trying to build a new empire with Atari, Jack Tramiel finally decided to bow out.\n\nThe Atari ST was no failure. It was an excellent machine and sold well. For eight years, the Atari ST slugged it out with the Commodore Amiga for the position of top dog in the home-computer market. The problem was that the home-computer market was dying.\n\nPerhaps if they had spotted this sooner, Commodore and Atari would have been able to adapt. Tramiel should have spotted it, because the reason for the decline was the same reason for Commodore’s meteoric rise: price drops.\n\nThe home computer market only existed because it offered a mid-tier option for lower-income households to get on the computing ladder. Home computers offered gaming and productivity in a single package—hence why Commodore had thrived while Don Estridge’s IBM PC had dominated all other markets. In the 1980s, the IBM PC’s price point was low enough to disrupt business and more affluent computer owner markets, but not low enough to beat what Commodore (and later Atari) could offer the average family.\n\nWhile Commodore and Atari spent the late eighties slugging it out like tired old wrestlers, they failed to notice the new contender running toward their ring: Rod Canion’s Compaq. Behind Compaq were the other PC clones such as Hewlett-Packard and Dell. They brought the same ruthless push to drive down cost to the PC market that Tramiel had brought to the home computer market. By the early nineties, people didn’t need a computer under their TV any more. They could have a PC on their desk.\n\nWhether it was Gould or Tramiel who ultimately pulled the trigger on Jack’s exit from Commodore, the irony was that both men were right. Gould had no idea how to run a computer company, only how to loot one. Commodore needed direction, and it never had it after Tramiel. Gould was right about one thing, however. Tramiel’s management philosophy was on borrowed time.\n\nIn the dying days of Atari, Tramiel first tried to push development on a PC clone, and then tried to pivot back into gaming with the Atari Jaguar console. Both plans failed. His tyrannical approach to management left Atari short on talent, and even shorter on friends in supplier, retail, or developer markets. Tramiel had always abused Commodore’s position as a market leader to make money at their expense. They were in no mood to do him favors at Atari. Because of higher expectations, new machines also required complex, multi-year development processes, which entailed significant investment. As Chuck Peddle had always said, Tramiel was never an investor.\n\nOne day in 1982, Michael Tomczyk, who had led the project to develop the Commodore 64, found himself sitting in Jack Tramiel’s office. Tomcyzk had just returned from a trade show in Hanover, Germany. During the course of their conversation, Tomczyk mentioned how impressed he’d been with the Autobahn highway network on the way there.\n\n\"I built that road,\" Tramiel told him matter-of-factly.\n\n“Jack went on to explain that during World War II as a teenager he had been selected to work on the road gangs,” Tomczyk remembered. “He said that it was one way to survive, because they had to feed the people that did that kind of hard labor, or they wouldn't work. ‘We built good roads,’ he said.”\n\nTramiel had never hidden the horrors in his past. He was proud that he had helped build a better future through Commodore and Atari. However, the longer he lived, the more concerned he became that people would forget what that future had cost. And that which is forgotten can be repeated.\n\n\"You know,\" Tramiel said once, \"it's hard to believe it really happened. But it can happen again. In America. Americans like to make rules, and that scares me. If you have too many rules you get locked in a system. It's the system that says this one dies and that one doesn't, not the people. That's why I don't hate the German people. Individuals, yes. Rules, yes. But not all Germans.\n\n\"They just obeyed the rules. But that's why we need more Commodores. We need more mavericks, just so the rules don't take over.\"\n\nWhen Tramiel finally walked away from the computer business in 1996, he didn’t walk away from public life completely. Instead he switched his focus elsewhere, to something he’d begun doing a while before.\n\nIn October 1988, work began on the United States Holocaust Museum in Washington, D.C. The museum was built using $190 million of private funding. That funding included a significant donation from two of the museum’s founding patrons, Jack and Helen Tramiel. In 1990, Jack contributed his own oral history to the museum. It represented a growing desire to tell his own story, and to help other Holocaust survivors preserve theirs.\n\nIn 2005, a new museum that covered the history of Polish Jews was announced in Warsaw, on the site of the Warsaw ghetto. Among the founding benefactors were Jack and Helen Tramiel.\n\nTramiel died in April 2012. In life, he was hated as much as he was loved. Jack Tramiel was always one thing or the other—never in between. What nobody can deny is that he changed the world.\n\nWe live in a future that was conceived by Jack Tramiel. Tramiel didn’t just promise “computers for the masses, not the classes”—he delivered. He forced the entire computing industry to do the same.\n\nTramiel was the first and last king of home computing. That brief age of a computer under every TV or on the desk. The world of technology today is led by people who fell in love with computers because of Jack.\n\nSpeak to a tech founder or visionary. Speak to a CEO or CTO. Speak to a lead software engineer or senior games developer. Ask them who built the computer that made them realize they weren’t just living in the future, but could help shape it.\n\nMost will give you a single word:\n\n“Commodore.”\n\n\n\n\n\nGareth Edwards is a digital strategist, writer, and historian. He has worked for startups and corporations in both the UK and U.S. He is an avid collector of old computers, rare books and interviews, and abandoned cats. Follow him on X, Mastodon, and BlueSky.\n\nTo read more essays like this, subscribe to Every, and follow us on X at @every and on LinkedIn.\n\nWe also build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Write something great with Lex. Deliver yourself from email with Cora.\n\nWe also do AI training, adoption, and innovation for companies. Work with us to bring AI into your organization.\n\nGet paid for sharing Every with your friends. Join our referral program.\n\n\n\n",
      "word_count": 11270,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3479/Screenshot_2025-03-06_at_8.56.44_PM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "the-crazy-ones"
    },
    {
      "url": "https://every.to/thesis/knowledge-work-is-dying-here-s-what-comes-next",
      "title": "Knowledge Work Is Dying—Here’s What Comes Next",
      "author": "Joe Hudson",
      "author_url": "/@joe_7639",
      "publication_date": "May 29, 2025",
      "content": "Knowledge Work Is Dying—Here’s What Comes Next\n\nWhile AI devours information-based roles, OpenAI, Alphabet, and Apple are investing in wisdom work—and you can, too\n\nJoe Hudson works with the executives building AGI at OpenAI—many of whom believe AI will soon do the jobs they're currently doing. But they're not panicking. They're developing entirely different skills that will remain valuable, with Joe’s help. I've known him personally for a few years, and not only is he a sharp thinker, he's also remarkably grounded—someone who faces the uncertainty of the future not with anxiety but with genuine curiosity, compassion, and practical wisdom. In this piece, Joe offers something rare and valuable: a clear-eyed, deeply human path forward that will leave you feeling more capable, not less. (Stay tuned for his upcoming appearance on our podcast AI & I.)—Dan Shipper\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nBefore AI, knowledge set you apart. Knowing more meant earning more. Accumulating skills, developing expertise, and mastering frameworks got you ahead.\n\nToday, as models swallow entire fields overnight, wisdom—skills like emotional clarity, discernment, and connection—is what keeps you indispensable. As CEO of Microsoft, Satya Nadella made it a priority to instill these capacities throughout his organization. In eight years, the company’s market capitalization climbed from $300 billion to $3 trillion.\n\nI work with the people building artificial general intelligence itself—including OpenAI CEO Sam Altman, the company’s cofounder Wojciech Zaremba, its research and compute teams, and senior executives at Google’s DeepMind, Anthropic, and Apple—and they’re racing to master the same three inner skills. Many of them seek me out because they understand a sobering truth: They are building the technology that will make their own skills obsolete. In the not-too-distant future, AGI will be able to do what they can do today—faster, cheaper, and at scale.\n\nMy job is to help these leaders develop their abilities in areas that AI cannot replicate. I help them lead not from fear, ego, or having something to prove, but from a deeper place of wisdom.\n\nHere’s why—and how you can, too.\n\nYou’re not going to get good at AI by nodding through another slide deck. Every Consulting helps teams level up—fast. We’ve trained private equity firms, leading hedge funds, and Fortune 500 companies. Now it’s your turn. Customized training. Hand-held development. A rollout strategy your team will actually use. Let’s make your organization AI-native before your competitors do.\n\nTry us out today.\n\nAI models don’t sleep or burn out; they can absorb entire fields of study in days. One highly trained model will soon be able to outperform an expert in physics, law, and engineering—simultaneously, at any hour. Facts, skills, and expertise will be increasingly commoditized, and even the smartest of us will be replaceable.\n\nIt’s easy to overlook how radical that is. Our entire society is built around knowledge as a scarce, precious resource. School systems, standardized tests, Ivy League pipelines, job interviews, LinkedIn profiles are all mechanisms to measure, prove, and reward how much you know. Hence the rise of over 1 billion knowledge workers: professionals valued for what they knew and could do, like lawyers, engineers, consultants, and programmers.\n\nNow, imagine a world where all that is irrelevant, akin to the ability to build a fire today—occasionally useful, but mostly unnecessary in a world with light bulbs, central heating, and stove tops.\n\nWe all know the person who gets a free pass because they’re good at something—the developer who ships flawless code but shreds morale, the investment banker who triples deal flow but hijacks meetings, and so on.\n\nFor decades, extraordinary knowledge or skill created a protective moat around bad behavior; people muttered, “That’s just how they are,” and kept the peace. But when a model can draft the brief, diagnose the anomaly, or optimize the market strategy in seconds—and do it politely—why keep paying the emotional tax of a brilliant jerk?\n\nBut you don’t have to be a talented blowhard for your skills to be at risk of AI disruption. The leverage has shifted from what you can do to how you show up while doing it. Competence is now table stakes.\n\nAnd when knowledge is no longer scarce, what remains valuable? Wisdom. You can get answers from AI, but how you use those answers takes wisdom.\n\nWisdom is how to live. It is the residue of mistakes, metabolized by time and reflection. It can’t be rushed, and it can’t be copy-pasted. It is an embodied—as in felt in the body—experience, guidance from the inside.\n\nNo matter how intelligent AI becomes, it can’t live your life for you. It can’t feel your body’s signal in a high-stakes negotiation, sense the hidden fear in a boardroom, or hear the unspoken \"no\" behind a client's polite words.\n\nThat’s why tomorrow’s economy will prize wisdom workers. Let’s dive into their three core skills: emotional clarity, discernment, and connection.\n\nMost people think emotional work is about becoming more “regulated” or less reactive. Two of the main strategies I see today are:\n\nThese techniques can be helpful. But when we use them to bypass what's real, they turn into avoidance.\n\nWhether repressed or managed, avoided emotions don’t go away. They return in a pattern I call the “golden algorithm.” It goes like this:\n\nFor example: I don’t want to feel like a failure —> I play it safe —> I feel like a failure. (Drop this prompt into the AI model of your choice to find your own golden algorithms.)\n\nWith emotional clarity, on the other hand, you take your emotions seriously, but not literally.\n\nIt is the ability to recognize your emotions, feel them, and move forward unobstructed—the difference between being caught in the storm and becoming the sky that holds it. Surveys show that this kind of emotional intelligence is already the number-one criteria for managers when considering a team member for a promotion or salary increase.\n\nObsessing over pros and cons lists? Finding yourself in a recurring pattern? Ruminating at night about how to avoid a company setback? These aren’t thinking problems; they’re feeling problems. In fact, studies show that when the emotional center of your brain is impaired, your IQ stays the same, but it takes hours to make a simple decision—like where to eat or what pen color to choose. Neurologically speaking—and contrary to popular belief—we don’t make logical decisions. We make emotional ones. And emotional avoidance clouds our decision-making.\n\nPsychologists echo this: Chronic procrastination shows up less as a time-management failure and more as an emotional struggle—we delay to dodge anxiety, self-doubt, or fear of failure.\n\nI’ve seen this firsthand: Some of the most brilliant founders, executives, and creative professionals I’ve worked with weren’t stuck because they lacked intelligence or strategy. They were stuck because they didn’t know how to deal with their emotions.\n\nThey avoided discomfort or bypassed fear. And they made reactive choices—ones that felt smart in the moment but cost them deeply in the long run. Sometimes it meant burning out their team or walking away from an opportunity too soon, and other times it meant chasing the wrong metric for years.\n\nCompanies are increasingly adopting AI into their workflows—Moderna just plugged more than 3,000 custom GPT agents into every corner of the company, for example. As models handle more and more tasks of execution, people’s jobs will be more focused on decision-making, and emotional clarity will be even more valued than it is today.\n\nIndeed, the two building blocks of a company are (1) decisions and (2) relationships. Emotional clarity underpins both of these. It’s why people like Altman hire me, because they see emotional clarity as “[o]ne of the most critical skills in a post-AGI world.”\n\nPromotions in the age of wisdom won’t go to the people with the most impeccable  spreadsheet, but to those who can transform a team’s silent anxiety into aligned action.\n\nIn the knowledge-work era, we often assumed the person with the best dashboard or most comprehensive analytics was the smartest one in the room.\n\nBut we are drowning in dashboards and real-time feeds, and evidence suggests that piling on more data often hurts decision quality:\n\nDiscernment goes beyond what is true in the stacks of data. It is the ability to see things clearly and zero in on what matters.\n\nWhat most people don’t realize is that your relationship with yourself sets the tone for everything else. If you don’t trust yourself, you won’t trust your team. If you shut down your own desires, you’ll feel resentful of others’ wants. If you’re judging other people, you’ll judge yourself even more.\n\nIn short, if you can’t see yourself clearly, you can’t see the world clearly. And your discernment is compromised.\n\nI’ve worked closely with some of the most accomplished people in the world—people leading multi-billion-dollar companies, building cutting-edge AI tools, or running high-stakes creative teams. The biggest barrier to their growth is almost always the way they relate to themselves when things get hard—or even when they are great.\n\nI once coached a founder who had just raised a major round of funding. On the outside, everything looked great. Inside, he was in a constant war with himself. Every decision was second-guessed. Every meeting left him replaying what he should’ve said. He couldn’t rest, celebrate, or feel the success. The voice in his head kept repeating, “This isn’t enough. Why aren’t you doing more?”\n\nThis sort of negative self-talk can become so familiar that it becomes invisible. But our nervous system can feel the attack, and your body lives in a state of chronic fight-or-flight. From that state, it’s nearly impossible to access creativity, intimacy, or wise decision-making.\n\nThe way to address this is not with more productivity hacks or discipline. I’ve found it far more effective to learn how to befriend yourself and speak to yourself with the same respect you want from others.\n\nIndeed, changing how you relate to yourself is one of the foundations of my work with clients. Here’s an experiment you can try: For 20 minutes every day for a week, listen to the critical voice in your head*.\n\n*Make sure you say “ouch” out loud.\n\nPeople are often stunned by how often they end up saying “ouch”—a visceral reminder of just how relentless that inner critic can be. Naming the sting in real time interrupts the automatic shame-loop and turns passive self-judgment into something you can see, hear, and choose to soften. Bringing your relationship with yourself into light will help you uncover blind spots, see your limiting beliefs, and illuminate your false assumptions—all of which increase your discernment.\n\nThe majority of us have been taught that connection is earned through achievement. We believe that once we become successful, smart, or generous enough, we’ll be worthy of connection.\n\nBut people don’t want you to be perfect. They want to be connected to you.\n\nThis doesn’t mean charisma in the traditional sense; instead, it’s deep relational presence—the ability to attune to others, see and be seen, and create safety even when pressure is high.\n\nThe foundation of my coaching is built on connection. I teach it through a framework called VIEW: Vulnerability, Impartiality, Empathy, and Wonder.\n\nWith VIEW, we access connection not by trying harder, but by removing what is getting in the way of the connection that is always here. I’ve used this framework everywhere from Fortune 500 boardroom discussions to marriages on the brink of divorce. It’s one of the most reliable ways I know to create transformation—not through force, but through presence.\n\nWhen you stop performing and start relating from a place of vulnerability and openness, people can feel you. And that feeling is what builds trust, safety, and deep connection.\n\nThis skill will matter more than ever when knowing things is no longer primary to being effective. Studies show that teams whose members feel safe to speak up learn faster and hit their targets more often. Google’s Project Aristotle, which set out to understand what made teams successful, found that of all variables studied, psychological safety was the number-one predictor of high-performing teams.\n\nWhile people do grow attached to chatbots and develop bonds that soothe loneliness, these connections are fundamentally parasocial and transactional: The flow of care moves in one direction; AI has no skin in the game. Deep connection demands mutual, embodied relational presence—nervous systems coregulating through micro-expressions, tone shifts, and even subtle changes in breathing. AI can model supportive language, but it cannot feel surprise when you walk into the room, nor does its pulse quicken when you share bad news.\n\nThe Harvard Study of Adult Development—the world’s longest-running longitudinal study, tracking people since 1938—found that the single strongest predictor of both happiness and physical health in old age was the warmth of participants’ close relationships. In fact, quality of connection at age 50 predicted health at 80 better than cholesterol levels did.\n\nNo matter how powerful AI becomes, if you want to feel fulfilled, you’ll still need to be deeply connected with other humans. If you want to change the world, you’ll need to be deeply connected with other humans. If you want to be a part of a high-performing team, you’ll need to be deeply connected with other humans.\n\nAI may one day solve the grand unifying theory, cure all disease, and figure out how to protect us from starvation. What it can’t do is tell you how to be when fear, doubt, or the existential nausea of “Now what?” occurs.\n\nHow you answer these questions will set you apart: What do I want and how do I own it? What kind of leader do I want to be? What’s the most effective thing for me to be doing at this moment? What does “effective” even mean to me?\n\nThese are not problems of knowledge or information. They are a matter of wisdom.\n\nIt’s clear to many that we’re already stepping into the age of wisdom work. Every CEO Dan Shipper points to the rise of the allocation economy, where the advent of AI means everyone will become a manager: “You won’t be judged on how much you know, but instead on how well you can allocate and manage the resources to get work done.” Being a great manager requires all three of the skills I’ve described.\n\nSome of the most well-resourced founders and executives in the world are investing in these three areas. That’s not a phenomenon of just my personal clients—people across the business world are prioritizing wisdom more and more. Nadella’s focus on rebuilding Microsoft around an empathy mindset, emphasizing emotional intelligence and self-reflection, has led to a 10-fold jump in the company’s valuation, record engagement scores, and top-quartile (88 percent) CEO approval. Google’s Search Inside Yourself program teaches mindfulness, emotional intelligence, and empathy to engineers. It has provided measurable changes in lower stress, higher engagement, and faster innovation—and is now licensed to executive teams at companies around the world.\n\nInner work isn’t just a personal growth tool anymore. It’s a strategic imperative.\n\n\n\n\n\nThanks to Melody Song, head copywriter at the Art of Accomplishment, for her editorial support. You can follow her on X at @melodaysong.\n\nTo read more essays like this, subscribe to Every, and follow us on X at @every and on LinkedIn.\n\nWe build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Deliver yourself from email with Cora.\n\nWe also do AI training, adoption, and innovation for companies. Work with us to bring AI into your organization.\n\nGet paid for sharing Every with your friends. Join our referral program.\n\n",
      "word_count": 2597,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3593/thesis_joe_hudson(2).png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3565/thumbnail_Eliot_Peper_companion_piece(2).png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3545/thumbnail_tina_companion.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "thesis"
    },
    {
      "url": "https://every.to/thesis/how-to-build-a-truly-useful-ai-product",
      "title": "How to Build a Truly Useful AI Product",
      "author": "Chris Pedregal",
      "author_url": "/@chris_8873",
      "publication_date": "December 9, 2024",
      "content": "How to Build a Truly Useful AI Product\n\nGenerative AI breaks the old startup playbook\n\nI used to take notes during Zoom meetings, toggling between the call screen and a Notion document that housed my notes—always hoping that whatever I jotted down actually made sense when I reviewed it later. Now I use an AI-powered meeting notes tool called Granola that automatically captures what’s happening in my call, so I can stay focused on the conversation. Some of my Every colleagues do as well, so we’re thrilled to publish this piece by Granola cofounder Chris Pedregal in today’s Thesis. In a landscape where the underlying AI models improve faster than developers can build applications for them, Chris argues that building AI products requires an entirely new playbook, and he shares four essential principles drawn from his own experience. If you’re interested in learning more from Chris’s experience, tune in to this week's episode of AI & I, where he talks with Dan Shipper about building Granola and what he’s learned.—Kate Lee\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nWhen you’re building at the application layer—your startup uses an AI model provided by companies like OpenAI and Anthropic—you're relying on technology that is improving at an unpredictable and unprecedented rate, with major model releases happening at least twice a year. If you're not careful, you might spend weeks on a feature, only to find that the next AI model release automates it. And because everyone has access to great APIs and frontier large language models, your incredible product idea can be built by anyone.\n\nMany opportunities are being unlocked—LLMs have opened up product abilities like code generation and research assistance that were impossible before—but you need to make sure you are surfing the wave of AI progress, not getting tumbled by it.\n\nThat’s why we need a new playbook.\n\nHaving spent the last two years building Granola, a notepad that takes your meeting notes and enhances them using transcription and AI, I’ve come to believe that generative AI is a unique space. The traditional laws of “startup physics”—like solving the biggest pain points first or that supporting users gets cheaper at scale—don’t fully apply here. And if your intuitions were trained on regular startup physics, you’ll need to develop some new ones in AI. After developing these intuitions over the last two years, I have a set of four principles for building in AI that I believe every app-layer founder needs to know.\n\nLLMs are undergoing one of the fastest technical developments in history. Two years ago, ChatGPT couldn’t process images, handle complex math, or generate sophisticated code—tasks that are easy for today’s LLMs. And two years from now, this picture will look very different.\n\nIf you’re building at the app layer, it’s easy to spend time on the wrong problems—those that will go away when the next version of GPT comes out. Don’t spend any time working on problems that will go away. It sounds simple, but doing this is hard because it feels wrong.\n\nWe write, and then we build. If you’re a fan of Every's writing, you’ll probably like the products we’ve made to make thinkers more efficient: Spiral to automate repeat writing tasks, Lex to help you write better, and Sparkle to clean up your desktop—for good. With our last discount of the year, we're offering the whole package of writing and software for 33% off.\n\n\n\n\n\nPredicting the future is now part of your job (uncomfortable, right?). To know what problems will stick around, you’ll need to predict what GPT-X-plus-one will be capable of, and that can feel like staring into a crystal ball. And once you have your predictions, you have to base your product roadmap and strategy around them.\n\nFor example, the first version of Granola didn’t work for meetings longer than 30 minutes. The best model at the time, OpenAI’s DaVinci, only had a 4,000-token context window, which limited how long meetings could be.\n\nNormally, lengthening this time frame would have been our top priority. How can you expect people to use a notetaker that only works for short meetings? But we had a hypothesis that LLMs were going to be much better: They’d get smarter, faster, cheaper, and have longer context windows. We decided not to spend any time fixing the context window limitation. Instead, we spent our time improving note quality.\n\nFor a while, we had to actively ignore users who complained about the duration limit. But our hypothesis was right: After a couple of months, context windows got big enough to handle longer meetings. Any work we would have done on that would have been wasted. Meanwhile, the work we did on note quality is one of the main reasons users say they love Granola today.\n\nHistorically, a defining characteristic of software was that the marginal cost of supporting an additional user was close to zero. If you had a product that worked for 10,000 users, it wouldn't cost that much more to support 1 million users.\n\nThis is not true when it comes to AI. The marginal cost of every additional user remains the same, and cutting-edge AI models are really expensive to run. For example, sending the audio of a half-hour meeting to OpenAI’s flagship GPT4o audio model costs about $4. Imagine that cost scaled across thousands of users, every day. There’s also a limit to the number of users your startup can onboard. Even if you had all the money in the world, OpenAI and Anthropic (which makes Claude) don’t have enough compute to support cutting-edge models for millions of users.\n\nFor the first time, it’s possible to provide a better product experience for a small number of users than for millions of users. But this isn’t an obstacle—it’s a big opportunity for startups. Big companies with millions of users literally can’t compete with you because there isn’t enough compute available in the world to provide a cutting-edge experience at scale.\n\nAs a startup, you can give each of your users a Ferrari-level product experience. Use the most expensive, cutting-edge models. Don’t worry about optimizing for cost. If doing five additional API calls (server requests to your LLM provider of choice) makes the product experience better, go for it. It might be expensive on a per-user basis, but you probably won’t have many users at first. And remember: At best, companies like Google can provide their users with a Honda-level product experience.\n\nYou might be wondering what happens when users come flocking to your Ferrari product experience. Won’t you end up in the same position as the big tech companies of today, unable to provide high-quality, cutting-edge services to your users?\n\nThe beauty is that even if your user base is growing exponentially, the cost of AI inference is decreasing exponentially. Today’s cutting-edge models will be affordable commodities in a year or two. Today’s Ferrari’s are tomorrow’s Hondas. Be a Ferrari while you can.\n\nWhen we first started writing prompts for Granola to generate meeting notes, we quickly realized that providing a set of step-by-step instructions doesn't work well in practice. The real world is messy, and it’s nearly impossible to anticipate and write rules for every situation an LLM might encounter. Even if you could cover every scenario, you'd inevitably have conflicting guidance.\n\nWe had an insight: Instead of treating AI models as something that just follows instructions, we should treat them like interns on their first day. An intern is smart but lacks context on what to do and how to do it. The key to an intern's success is to give them the context they need to think like you.\n\nThat's how we approach prompting at Granola now. We provide the model with curated context to guide its thinking. For Granola, the use case is writing great notes from a meeting. The context is understanding who is in the meeting and why it’s being discussed. Our work is to find that information—from the web and other sources—and then get the model to think like you (What are you trying to get out of this meeting? What are your long term goals and how is this meeting in service of that?) and put only the relevant information in the notes. The art is in selecting which context to provide and how to frame it—because no matter how good models get, the context you give them will always matter.\n\nI believe \"context window selection\" will be one of the defining ideas of our time, with implications far beyond AI. During the Industrial Revolution, the brain was described in terms of mechanical machines—blowing off steam, for example. When computers emerged, we started to use terms like “bandwidth” and “storage capacity.” I think we will start describing how the brain works in terms of \"context window selection.” This idea will permeate well beyond tech.\n\nOne fascinating challenge with building AI products today is that you're competing with general-purpose AI assistants like ChatGPT and Claude. They’re pretty good at most things. How do you build something good enough that users will choose you over these Swiss Army knives?\n\nThe only answer is to go narrow—really narrow. Pick a very specific use case and become exceptional at it. The cardinal rule of startups—building something people want—remains consistent in AI, but the bar is higher.\n\nBut here's the plot twist: Exceptional experiences for narrow use cases often have little to do with AI. We spend endless hours on note quality at Granola, but we spend just as much time on features like seamless meeting notifications and great echo cancellation (so our tool works whether you're using headphones or not). The \"wrapper\" around the AI is often the difference between a delightful experience and a great demo that is disappointing to actually use.\n\nGoing narrow also makes it easier to improve the AI part of your product. When AI gets a response right, it’s magical. But when it gets it wrong, it does so in ways that can feel weird and disconcerting. It becomes obvious that you’re not talking with a human, but with an algorithm. Product experiences that fall into the uncanny valley can push users away from your product for good. When you go narrow, it’s much easier to identify the most common AI failure cases, and either mitigate them or try to fail more gracefully.\n\nBuilding in generative AI is like running on a treadmill while traditional tech moves at walking speed. This speed impacts everything from the technical problems you tackle to your timeline for reaching scale. While this acceleration should change your strategy, it doesn’t change the fundamentals of building a good product. You  need to build something people want. There are no shortcuts. You still have to sweat the details. And the most clarifying questions remain deceptively simple: How does this product make me feel when I use it?\n\n\n\n\n\nTo read more essays like this, subscribe to Every, and follow us on X at @every and on LinkedIn.\n\nWe also build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Write something great with Lex.\n\n\n\n",
      "word_count": 1862,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3369/thesis_cover.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3564/thumbnail_eliotpeperimage_2.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3565/thumbnail_Eliot_Peper_companion_piece(2).png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "thesis"
    },
    {
      "url": "https://every.to/thesis/the-end-of-productivity",
      "title": "The End of Productivity",
      "author": "Sari Azout",
      "author_url": "/@sari",
      "publication_date": "November 18, 2024",
      "content": "The End of Productivity\n\nWhy creativity is the new currency of success\n\nArtificial intelligence has the potential to shift our focus from productivity to creativity. As Sari Azout—the founder of knowledge management tool Sublime—argues in her Thesis piece, perhaps it's time to prioritize our creative potential over traditional productivity metrics. Read on to learn how.—Kate Lee\n\nPlus: All Every subscribers can skip the waitlist and get access to Sublime. And exclusively for paid Every subscribers, Sari is hosting a workshop on building your knowledge library for creative work. Click here for details and registration.\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nIn a world where we can outsource productivity to technology, the people who reap the biggest rewards aren’t those who work the fastest.\n\nThey’re the people who make things that are wonderful, original, weird, emotionally resonant, and authentic. As our feeds become flooded with instant, AI-generated content, the most dangerous thing you can do is play it safe.\n\nWe live in a culture that venerates productivity above all else. For centuries, success—particularly in the West—has hinged on a simple dictum: “Do more, faster.” As AI commoditizes speed and output, however, this pursuit will lose its value.\n\nStill, the productivity religion is so ingrained that it’s almost impossible to imagine a different way of working. That’s why, even with AI, we are still fixated on tools that help us do more, faster. As the founder of Sublime, a personal knowledge management (PKM) tool designed for creative thinking, I want to offer a different vision of the possibilities that this technology opens up, one that rescues knowledge work from its frenetic striving toward an impossible ideal of maximum efficiency and shifts our focus back where it belongs: original, meaningful, creative work.\n\nLet’s explore the limitations of today’s productivity tools when it comes to fostering creativity—and how we can design them to help us think more deeply and create more intentionally.\n\n\n\n\n\n\n\n\n\nWhen you write a lot about AI like we do, it’s hard not to see opportunities. We build tools for our team to become faster and better. When they work well, we bring them to our readers, too. We have a hunch: If you like reading Every, you’ll like what we’ve made.\n\nDigital tools designed to enhance our productivity and help us manage information have proliferated over the past two decades. These tools are great for tracking and executing tasks, but less helpful when it comes to figuring out what work we should be doing in the first place.\n\nTools like 3D CAD are excellent for creating designs, but not particularly useful for deciding what to design in the first place. Project management tools such as Asana, Linear, and Trello can help us manage workflows by creating and organizing lists of tasks. But it’s impossible to build the right workflow if you don’t know what outcome you’re working toward. There’s a part of the creative process that these tools simply don’t account for: the difficult, messy, non-linear work of figuring out what you actually want to build.\n\nRory Sutherland, vice chairman of the Ogilvy advertising agency, famously told a story about an office building where people complained that an elevator took too long to arrive. Instead of spending $1 million to make the elevators 5 percent faster, they solved the problem by spending around $100 to add mirrors so people could look at themselves while waiting.\n\nProductivity tools shape our thinking in ways that favor standardization, efficiency, and predictability. They demand structure before inspiration has a chance to strike. They ask for timelines when the problem itself is still hazy. But creativity is not linear. Often, it involves struggling down several blind alleys before finding the right path.\n\nAs Every CEO Dan Shipper writes, most productivity tools are built for convergence, the part of creativity that involves narrowing down and refining ideas. They aren’t built for divergence, which involves opening ourselves up to new ideas and possibilities.\n\nImagine trying to shoehorn the elevator mirror solution into a Linear project. The software would prompt you to move through a neatly organized set of issues: “Research elevator speeds,” “Calculate upgrade costs,” “Implement faster motors.” There’s no task for “Stare at the wall and ponder human psychology,” but sometimes that’s exactly what we have to do.\n\nThe problem extends to PKM tools like Roam, Notion, and Evernote. These platforms market themselves as ways to help us organize and make sense of all kinds of information. But as anyone who has captured ideas for an essay in the same Apple Notes app where they keep track of their dentist appointments can attest, not all information is created equal.\n\nInformation that is worth saving usually falls into two buckets:\n\nFor administrative information, a search bar or hierarchical folder structure is sufficient. When you’re locating your child’s health insurance forms or retrieving your tax returns, you want efficient, predictable retrieval—not exploration.\n\nBut for creative information, what you need is tools that encourage connections, facilitate serendipity, and support non-linear thinking. If you think of tools as places where you spend your time, then Linear is a factory production line, Asana a conveyor belt, Evernote an office cubicle, and X an overcrowded bar. A tool built for creativity should feel like a sunlit artist’s studio—spacious and inspiring, with windows you can open to allow the unexpected in.\n\nThe creative process involves taking existing ideas, making novel connections between them, and combining them into something new. Whether we do this consciously or unconsciously, and whether or not we use PKM tools, the creative process typically involves three steps:\n\nI believe that we can design our tools to enhance our creativity during each of these steps. Let’s explore them.\n\nThe first step in any creative journey is collecting sparks of inspiration—the ideas, quotes, images, and links you love and don't want to forget.\n\nBut here’s the thing: When you find something that resonates, its use is not always immediately apparent. A line in a song might be the seed for your next coding project or inspire the title for the book you’re writing. It can be difficult to predict how something that resonates today might be useful in the future.\n\nThere are two modes of information discovery: foraging and hunting. Foraging is passive. You don’t have a clear goal; you just wander and scroll until something catches your interest. Hunting is active and purposeful. You know what you’re looking for and are consciously searching for it. A good information diet needs both: Foraging helps us decide what is worth hunting for, while hunting allows us to go deep on a specific subject.\n\nMost tools for capturing information force you to choose between one mode and the other. PKM tools like MyMind (which Dan has explored) highlight the convenience of one-click capture. They’re perfect for foraging, as you can use them to save something without having to decide where it belongs, but not particularly helpful for organizing and connecting ideas. Meanwhile, tools like Are.na, Evernote, and Notion force you to immediately decide where a piece of information belongs. This is great when you’re in hunting mode, but not when you have yet to figure out how something might be useful.\n\nTo do our best creative thinking, we need tools that seamlessly support both modes. We should be able to capture ideas effortlessly in the moment, then organize them with purpose when the time is right. This balance between seamless capture and intentionality is essential for supporting creativity.\n\nFor decades, the neurotic hamster in us approached knowledge management by compulsively tagging. We’d find something interesting and slap as many tags on it as we could to increase our chances of finding it again: #machine #robots #tech #ai #productivity #mindfulness.\n\nThis made sense in a pre-AI world, where tagging was the only way to ensure retrieval. But now that AI has given us the gift of semantic search—which surfaces information based on meaning and vibes rather than keywords—we no longer need to rely on rote categorization.\n\nLike Instagram and the bookmark manager Raindrop, Sublime uses collections to organize your information. On the surface, they look a lot like tags, but in practice, they function very differently. If tags answer the question, \"What is this about?,” then collections answer, “In what context will I want to revisit this later?” Instead of organizing information by topic, they ask us to organize it in terms of actionability.\n\nMany of my personal collections have evolved into concrete outputs. Last year, a collection I created called “dreaming of a better internet” became the basis for a print publication. Another, titled “creativity > productivity,” was the inspiration for this very essay. I keep a private collection dedicated to marketing that has convinced me to buy something, and I revisit it every time I need to draft sales copy. Similarly, whenever I’m writing something and get stuck, I like to return to my private \"phrases\" collection, a home for sentences I find particularly resonant.\n\n\n\n\n\nI like to think of collections as a way of creating meaningful containers for creative work—spaces that allow us to develop our ideas, while maximizing our chances of making unexpected connections.\n\nIn his 2012 essay, “More people should write,” writer and programmer James Somers described this process as creating a mental bucket for an idea, thereby unleashing a magnetic force between that idea and the world:\n\nOnce you’ve discovered the right mental buckets, or containers, for your creative work, it’s time to maximize the potential for unexpected connections. But to surface those connections, you also need the right tools.\n\nTraditional note-taking apps such as Apple Notes or Notion lock information into hierarchical systems. They bury ideas inside folders or pages, which restrict them to a single location. PKM tools Capacities and Sublime take the opposite approach. Every piece of information is represented as a standalone “card” that can be combined or connected with others in multiple ways. This approach is more conducive to unexpected collisions between ideas, much as a chef can create countless dishes by combining individual ingredients. At Sublime, we like to think of every card as an atomic unit of knowledge.\n\nHere’s an example: Let’s say you save a quote to a “Quotes” page in your Apple Notes. It just sits there, in this one spot. You can add more quotes, sure, but that’s the extent of its world.\n\n\n\n\n\nIn a card-based system, that quote can live in multiple collections at once, dynamically connected to different concepts and insights. It’s part of a network, not a silo, allowing it to connect with other concepts in ways that would never happen in a static, folder-based system.\n\nThe benefits are multiplied with AI. With Sublime, when you add a card, the AI will surface related ideas—sort of like that insightful friend who always says, “This reminds me of…” The AI's role isn't to automate organization; it's to suggest connections we haven’t considered and amplify our ability to see patterns and possibilities. I like to think of it as inspiration as a service.\n\n\n\n\n\nIn his book Keep Going, author and artist Austin Kleon juxtaposes this messy, networked approach with organization and neatness. “Creativity is about connections, and connections are not made by siloing everything off into its own space. New ideas are formed by interesting juxtapositions, and interesting juxtapositions happen when things are out of place.” Mechanically filing and organizing might feel magical when you're sorting socks or pantry items at home, but it’s not a useful model for creative work. (Sorry, Marie Kondo.)\n\n\n\n\n\nYou’ve gathered ideas, made meaningful connections, and sparked unexpected insights. Now you’re ready to synthesize them into something new.\n\nHere’s the problem: Most tools treat consuming and creating as distinct processes. You compile sources for a book in a note-taking app, but type in a blank page in a different window, on a different platform.\n\nSpeaking from personal experience, however, it feels clear that for our brains, the act of reading and reflecting on a book is not all that different from the act of writing one. In both cases, we are seeking out novel connections, combining existing concepts to produce new ones. So why do we think of the act of consuming, as opposed to producing, as inherently passive? Why do we write in an empty Google Doc, detached from everything that has inspired us to write? Why are we expected to gather ingredients in one kitchen and cook in another?\n\nIt’s puzzling. Many of us have spent years collecting ideas in various PKM tools, but when it comes time to create, we don’t have an integrated way to surface those ideas. This disconnect illustrates a critical need for tools that bridge the gap between collection and creation.\n\nAt Sublime, this is already happening. While writing this essay, any time I found myself wrestling with how to articulate a concept, I would select a sentence and press ctrl+r. Using AI, Sublime would instantly pull up related ideas from both my own library and that of others in the network—including the Austin Kleon reference I included earlier.\n\nThe AI didn’t generate the output for me. It surfaced just-in-time quotes to reinforce my argument, rescue me from my own forgetfulness, and push me to make the occasional creative leap.\n\n\n\n\n\nA few months ago, I built a new tool for Sublime called Canvas. I can search across all of my Kindle, Readwise, and Sublime highlights and inspiration and pull them directly into a spatial canvas. My favorite part is selecting a card on the canvas and surfacing related ideas from other people’s libraries. All those hours spent highlighting and saving ideas are finally paying off: I can surface the information I need, exactly when I need it.\n\n\n\n\n\nBut I also think that something more profound is happening here. Instead of being a passive consumer of the web, I begin to feel as though the internet is molding itself around my intentions, transforming from a distraction machine into a precision instrument for creativity.\n\nToday’s knowledge workers carry a growing sense of anxiety. We have more tools than ever, but these options rarely match how we actually create. Rather than build more technology that keeps us on a miserable hamster wheel of churning out more shallow content, we have a unique opportunity to design tools that encourage us to slow down and create with intention.\n\nWhen it comes to AI, we need to aim higher than the question: “What if you could press a button to generate an essay?” AI can produce infinite amounts of content; quantity is its game. Quality, intention, taste, originality, vision—that’s where we come in.\n\nOur interfaces should facilitate prose-sculpting, meaning-architecting, memory-augmenting, and inspiration-harvesting—all grounded in sources we love and trust. Just as calculators shifted math from rote computation to conceptual exploration, AI can nudge creative work toward the things humans are uniquely good at: thinking and feeling deeply.\n\nBut this future is a possibility, not an inevitability. I believe there are two plausible scenarios for the future of knowledge work. There’s one in which as machines become more human-like in their capabilities, we paradoxically become more machine-like in our pursuit of productivity, focused on efficiency and keeping busy above all else. But there’s another where we lean into ways of working that are more intuitive to us as humans, harnessing AI to help us create more meaningful work.\n\nStill, transitioning to a creativity-first mindset requires much more than just designing better tools. It requires us to shift to a new paradigm that celebrates and nurtures the chaotic, unpredictable, often unquantifiable nature of creativity. Earlier this year, author and essayist Charles Eisenstein discussed how productivity can be counterproductive when we take it to an extreme: “When we gear our society around efficiency, we produce more and more of the measurable, while the immeasurable, the qualitative, and the things we don’t think to measure drain away. Bedazzled by quantitative abundance, we might not be able to see what is lost, but we can definitely feel its absence.”\n\nUltimately, moving away from productivity and toward creativity isn't just an economic necessity, something we need to stand out in the marketplace; it's about reclaiming our humanity and building more fulfilling lives. The goal can’t just be making more stuff. It has to be making something wonderful.\n\n\n\n\n\nSari Azout is the founder of Sublime, a knowledge tool designed for creative thinking. She was previously a partner at Level Ventures and occasionally publishes her writing on Substack.\n\nSublime is currently in an invite-only private beta. Every subscribers can skip the line and join using this link. You can follow Sari’s collection of inspiration for this essay. Want to learn how to curate your own knowledge library? Sari is hosting a workshop exclusively for paid Every subscribers. Click here for details and registration.\n\nTo read more essays like this, subscribe to Every, and follow us on X at @every and on LinkedIn.\n\nWe also build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Write something great with Lex.",
      "word_count": 2844,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3316/Screenshot_2024-11-18_at_10.59.20_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3565/thumbnail_Eliot_Peper_companion_piece(2).png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3564/thumbnail_eliotpeperimage_2.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "thesis"
    },
    {
      "url": "https://every.to/thesis/the-real-value-of-ai-isn-t-general-intelligence",
      "title": "The Real Value of AI Isn’t General Intelligence",
      "author": "Phin Barnes",
      "author_url": "/@phin",
      "publication_date": "November 25, 2024",
      "content": "The Real Value of AI Isn’t General Intelligence\n\nThe market for artificial general intelligence is small. Founders should bet on specialized solutions instead.\n\nSilicon Valley prognosticators often make bold pronouncements about the point at which artificial intelligence (also known as artificial general intelligence or AGI) surpasses human cognitive ability. But while many tech leaders talk at length about their ambitions or fears regarding building AGI, that’s a distraction from something more important, argues venture capitalist Phin Barnes in this week’s Thesis: building good businesses.—Kate Lee\n\n\n\n\n\n“I think the race to AGI is somewhat overblown,” an engineer at my firm recently wrote to me. “As we get closer to AGI, the definition itself will diffuse and fragment—not into five or 10 variations, but into thousands of ‘not really AGI’ solutions.”\n\nThis sentiment captured something I’d struggled to articulate in conversations with founders and fellow investors. Artificial general intelligence (AGI) is typically defined as a form of AI with the cognitive ability to learn, reason, adapt, and perform any intellectual task on par with humans. But the market for AGI—potentially the biggest shift in human-computer interaction in our lifetime—is surprisingly small. The current narrative around AGI has become too simplified, overly corporate in its winner-take-all framing. While AGI’s impact on humanity will surely be profound, the real economic opportunity lies in narrow, cost-efficient models that can handle specialized tasks.\n\nThe global AI market is already worth billions, soon to be trillions—so why would the tremendous promise of AGI create incredible social value but capture significantly less economic value? Consider the actual needs of industry: A manufacturing company doesn't need its AI to write poetry while controlling robot arms. A pharmaceutical firm doesn't need its drug discovery model to also handle customer service.\n\nThe trajectory for AGI, then, seems clear. As AI models get better, they hit a point of being “good enough,” and then pivot toward specialized applications. This specialization—not general intelligence—is where most of the economics of AI will be captured. Down the line, the best founders will likely not be comparing foundation model capabilities, but rather the “build versus buy” decision to create scaffolding around large models (open or closed) for specific needs. The ability to point a model at a specific use case will become the most important problem in the value chain of AI, so foundation model companies will compete to be the easiest to use and integrate.\n\nAs AGI hype collides with reality, understanding the constraints of today’s technology—power, scale, and data—will give builders a strategic edge. Let’s dive into the three biggest opportunity areas I see for builders in AI, as well as a strategic playbook for founders.\n\n\n\n\n\nWhen you write a lot about AI like we do, it’s hard not to see opportunities. We build tools for our team to become faster and better. When they work well, we bring them to our readers, too. We have a hunch: If you like reading Every, you’ll like what we’ve made.\n\nWhy wouldn't everyone adopt AGI for everything once it's available? Simple: economics. Absent a more efficient breakthrough architecture, AGI will be inherently more power-hungry and expensive than specialized models with a narrower focus. And that expense goes beyond just electricity costs for inference, the process by which an AI model applies its trained knowledge to analyze new data and generate outputs. Will AGI run efficiently on your phone? What happens when it demands 100 times more RAM? What if every response comes with noticeable latency?\n\nThese aren't theoretical concerns—they're practical barriers pushing real companies toward narrow use case workflows, infrastructure, and system architecture. This said, builders who understand the constraints are finding ways to turn them into opportunities. Here are the three biggest opportunity areas I’m seeing in play.\n\nTraining GPT-4 reportedly consumed around 500 megawatts during peak runs—roughly equivalent to powering 40,000 U.S. homes. If scaling predictions hold true, a hypothetical AGI model could require three to four gigawatts, which is more than a third of New York City's peak power demand. For context, Google's entire global operation, including all of its data centers, currently uses about 15.4 gigawatts. When a single AI training run starts demanding enough electricity to dim the lights in Manhattan, we've got a problem.\n\nBut perhaps it's more of an opportunity (and not just for nuclear power startups). For over 50 years, hardware and software have performed an intricate dance of efficiency: Hardware engineers push the boundaries of what's possible per watt, and software developers dream up new ways to use that power.\n\nWe've seen this pattern before. When gaming demands outpaced central processing units (CPUs), the industry pivoted and created graphics processing units (GPUs). Now, we're seeing the next wave in software demands, and the hardware market is responding. Google's tensor processing units (TPUs, in development since 2014), startups like Etch and Groq, and Apple's M-series chips are all reimagining chip architecture from different angles. Meanwhile, software techniques like LoRA are revolutionizing how we fine-tune models, dramatically reducing computational needs.\n\nIt’s the cycle of tech at its best. When we hit a wall, we build a door.\n\nThe quest for more compute is forcing companies to distribute training across data centers. Physics becomes our enemy here. Light takes about three milliseconds to travel 1,000 kilometers through fiber-optic cables. For distributed training to work effectively, we need sub-millisecond latency between nodes, and that requires geographic proximity. To satisfy this need, our data centers can't be more than a few hundred kilometers apart, severely limiting where we can build them.\n\nDistributed systems challenges aren’t unique to AI; they're the latest variation of problems that Google, Microsoft, and Amazon have worked around for decades. In 2012, Google's Spanner project (a globally distributed database) solved essentially the same problem: synchronizing vast amounts of data across global data centers with microsecond precision. It may be a different payload, but the same fundamental challenge: How do you orchestrate massive computational tasks across distributed systems with minimal latency? Opportunities are baked into answering that question.\n\nThe third and perhaps most interesting constraint is data. As The Information recently reported, we're approaching a data wall that's both quantitative and qualitative. The entire internet’s text content is estimated at about 100 petabytes, of which GPT-4 is already trained on a significant fraction. Where do we go from here?\n\nSynthetic data might seem like a solution, but it's a circular dependency: We're using AI to create training data for better AI. At some point, you're creating an echo chamber of artificial knowledge, and new models may resemble old ones.\n\nThe real opportunity lies in the vast ocean of untapped, real-world data:\n\nFor founders, these constraints—energy, scalability, and data—are the makings of a clear strategic playbook:\n\nDon’t let those high API costs discourage you. They’re not barriers to entry—they’re your R&D. As these capabilities march down the cost curve through improved infrastructure, optimized architectures, and open-source alternatives, the experiences you've designed and tested will become increasingly viable. Sometimes, the best tool isn't the most powerful one—it's the one that cuts exactly as deep as you need it to. That's where the real market—and the real opportunity—lies.\n\n\n\n\n\nThanks to Alec Flett for editorial support.\n\nPhin Barnes is a cofounder and managing partner at The General Partnership (TheGP), a venture capital firm designed to deliver “sweat equity” agreements in addition to term sheets. Previously, he was a managing partner at First Round Capital. He is on X at @phineasb and occasionally publishes writing in his newsletter.\n\nTo read more essays like this, subscribe to Every, and follow us on X at @every and on LinkedIn.\n\nWe also build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Write something great with Lex.\n\n\n\n",
      "word_count": 1287,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3323/thesis_image_.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3564/thumbnail_eliotpeperimage_2.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "thesis"
    },
    {
      "url": "https://every.to/thesis/the-new-science-of-growth-marketing",
      "title": "The New Science of Growth Marketing",
      "author": "Josh Payne",
      "author_url": "/@josh_8983",
      "publication_date": "January 6, 2025",
      "content": "The New Science of Growth Marketing\n\nThe quantitative revolution took over finance. Now, thanks to AI, it’s coming for growth.\n\nJust as quantitative trading revolutionized finance in the 1980s, AI is ushering in a revolution in growth and marketing. That’s the argument from Coframe founder Josh Payne in this week’s Thesis. The new era of AI-driven growth, Payne writes, will push us forward toward a truly optimized future where businesses can better reach new audiences and turn them into happy customers.—Kate Lee\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nI was first exposed to the field of growth when my last company scaled from zero to unicorn status in just two years—in large part because of our team’s growth marketing efforts.\n\nMy initial impression was that growth marketers had an innate, almost mystical, sense of how to drive metrics. They were masters of finding creative ways to reach new audiences, turn those audience members into prospects, and convert those prospects into happy customers. They were “business whisperers.”\n\nIt was not unlike the impression most people have about traders who work in finance. They assume it’s a dark art of experience and instinct.\n\nYet even the most data-driven and logical traders still have flaws and biases, which quickly compound. In financial trading, gut instincts lead to poor decisions.\n\nWhy am I making this comparison between trading and growth? These two fields seem worlds apart. Trading is East Coast—stocks, bonds, pressed suits, and dress shoes. Growth is West Coast—viral growth loops, north star metrics, hoodies, and sneakers.\n\nAs it turns out, growth, like trading, is both an art and a science. It’s not mystical, but grounded in creating hypotheses, running experiments, and using metrics to rigorously drive success. Today, as the founder of Coframe, an AI growth copilot for websites, I know the truth: Growth people are indeed business whisperers, but their whispering is both systematic and measurable.\n\nAnd now, AI is fueling a new revolution in growth and marketing: a quantitative one. Let’s look at how the quant revolution that transformed finance is doing the same to growth, the early quant experimentation strategies that are working today, and how growth and marketing teams can win by mastering it early.\n\nBut first, we need to first look at how quantitative trading ate the finance world.\n\n\n\n\n\nWhen you write a lot about AI like we do, it’s hard not to see opportunities. We build tools for our team to become faster and better. When they work well, we bring them to our readers, too. We have a hunch: If you like reading Every, you’ll like what we’ve made.\n\nTwo mathematicians sat facing each other amid a scattering of charts, reports, and statements. The first mathematician, Leonard Baum, reflected sullenly, “How could this have happened?” At one point, he was unstoppable. Their fund, Monemetrics, had—in the three short years since its founding in 1981—racked up over $43 million in profit. Monemetrics was on track to become one of the highest-performing hedge funds in the world.\n\nBut, as they say, in a bull market, everyone’s a genius. Following its meteoric rise, Baum’s position, built from instinctive trades and a “buy-and-hold” mentality, had gone the way of Icarus—plummeting to 40 percent in losses, triggering a clause in the fund’s operating agreement, and liquidating the entire position.\n\n“There was no rhyme or reason,” the second mathematician thought. He was right. Jim Simons had built a career as a differential geometrist, living within a theoretical world of order, logic, and rationality. But the market is none of those things. Its movement is far too complex for any human mind to comprehend. It would not be solved on gut instinct alone.\n\nWhen this painful truth sank in, Simons started over. He went on to found a new firm, Renaissance Technologies (RenTec), from the ashes of Monemetrics, and introduced what is perhaps the most important revolution in modern-day finance: quantitative trading.\n\nQuantitative trading (or “quant trading”) hinges on a few tenets:\n\nIf you can predict patterns in the market, you’ve solved it. This early insight—using data and quantitative methods to predict patterns in the market—allowed RenTec to generate better returns than any known trading firm in history. One hundred dollars invested in RenTec’s Medallion Fund in 1988 would be worth over $400 million today.\n\nThe rest is history. Discretionary (human-driven) trading accounted for less than 10 percent of the total trading volume, as estimated by JP Morgan…back in 2017. That number is likely even lower today. Quant trading has eaten the finance world.\n\nWhat Simons—and, eventually, the rest of the world—realized was that in decision-making, the way to consistently outperform everyone else is to have the best data and make the best use of it. While some traders can still outperform in longer-horizon discretionary trading, the majority of capital is best allocated to the machines.\n\nWhat does all this have to do with growth?\n\nIn trading, the objective is to place a series of trades to increase the value of a portfolio. This starts with market research. We use indicators—such as company fundamentals, volatility, and momentum—to deepen our understanding. As we learn about the market, we start to identify patterns and develop hypotheses about assets that the market has mispriced. But we only have so much capital, so we place our bets based on the conviction we have in our hypotheses. If we’re right, we will beat the broader market; that outperformance is called alpha. The portfolio grows, and the cycle continues.\n\nLet’s consider experimentation, which is at the core of growth. In experimentation, we run a series of tests to increase a core business metric. Effective experimentation starts with researching the audience and product. We use indicators and second-order metrics and tools—such as heatmaps, segment information, and user journey statistics—to deepen our understanding. As we learn about the audience and product, we start to identify patterns and develop hypotheses about how to improve our metrics. But we only have so much website traffic and team bandwidth, so we place our bets based on the impact we think each will ‌have. If we’re right, our new website will have a higher conversion rate than the original; that outperformance is called lift. The business grows, and the cycle continues.\n\nSound familiar? In both cases, we are making thoughtful decisions about where to “invest.” We can choose to make small, safe, incremental bets, or take big, high-volatility, high-return swings. The psychology (and emotional roller coaster) is similar.\n\nExperimentation in digital products is relatively new. A/B testing didn’t become widespread until 2010, and only over the past decade or so have tech companies more widely adopted disciplines like growth engineering. But the early signs already seem to favor quantitative approaches.\n\nSean Colombo, the vice president of engineering at Duolingo, attributes the company’s exponential growth directly to their experimentation: The quicker you launch winning experiments, the quicker those changes impact your growth. Colombo references Duolingo’s experimentation with push notifications as a primary lever for their growth.\n\nWhile the idea of letting machines optimize user experiences is not new—recommendation algorithms are central to social networks like Instagram, TikTok, and Facebook—key challenges have prevented us from applying quantitative trading strategies to broader surface areas.\n\nIn particular, the outputs are vastly different. In trading, outputs are decisions on whether to buy or sell, which are purely numerical. Given the right input data, the simplest machine learning algorithms have proven quite capable of outperforming humans.\n\nIn experimentation, however, the outputs are different modalities entirely: product experiments or variants, which consist of combinations of copy, images, code, and user journey logic. Let’s say we have a pricing page that has a radio button layout—with the options stacked, like the Bloomberg pricing page—and we want to test a two-column layout, like the Wall Street Journal pricing page. This requires a design team to produce new visual designs, a content team to produce any additional content, an engineering team to write the code, and so on.\n\nEnter generative AI.\n\nSuddenly, we have a magic intelligence that is able to crunch the hyper-complex modalities of language, code, and vision in a principled and data-driven fashion—and with increasing ease. That pricing page change we were concerned about earlier? It can now be done in minutes, rather than in weeks, with the correct tooling and setup. We can use signals that human teams typically don’t even bother to consider in order to drive lift. We can optimize across hundreds or thousands of experiments rather than just a few—and we can do it continuously. The only remaining bottleneck is the traffic available, and even here we can use quantitative methods to squeeze more juice out of this traffic and, eventually, personalize our user interfaces entirely one-to-one.\n\nThis is a wholly new kind of experimentation—quant experimentation.\n\nQuant trading didn’t start out using microwaves for nano-second-level trade execution or satellite imagery to count cars in parking lots. Quant trading emerged from humble beginnings, with relatively simple strategies like mean reversion and pairs trading performing well early on. Over the decades, as strategies matured and new approaches were discovered, quant trading became an essential tool in the financial toolkit.\n\nIn the same way, quant experimentation will evolve to become an essential tool in the growth toolkit. But we don’t have to wait decades to see a couple of basic quant experimentation strategies that are working today, in order of increasing complexity:\n\nAt a recent dinner that Coframe hosted for growth engineering heads of Meta, Netflix, OpenAI, Microsoft, and other companies, many mentioned that they already regularly use off-the-shelf models to generate experiment ideas. For example, they might give ChatGPT a screenshot of a landing page and ask it to recommend ways to increase conversion, and it might suggest adding social proof above the fold of your landing page, tweaking a form that has multiple fields visible to only exposing one at a time to minimize user commitment and friction—or, yes, changing a button’s color from green to red. This approach is surprisingly effective even with minimal context, but it becomes more powerful when you incorporate historical experiment results and backlogs, more information about the audience, and a system that allows the model to iteratively learn what works best over time, which leads to…\n\nLanding pages, messaging campaigns, and other public-facing user experiences rely on engaging content to convert visitors into customers. But because of the manual work involved in creating this content and collecting feedback on its performance, marketing and growth teams traditionally only test a few variations in a given experiment. AI automates most of this, letting us move through the feedback loop not only quickly but continuously.\n\nHere’s a simplified example of how we might apply this quant experimentation strategy to a website headline. The system generates a few headline variants, which are tested in randomized trials on the site. Based on the results, we generate a few new headlines to replace lower-performing ones (while balancing the tradeoff between exploration and exploitation), incorporate these new headlines in the next trial, and repeat the cycle ad infinitum.\n\n\n\n\n\nContinuous optimization in this way also has the benefit of preventing content from becoming stale. The process may involve a human in the loop to approve or guide the variations, but at its core, it is inherently machine-driven and quantitative.\n\nAs a business grows, the number of audience segments typically does as well. And while ads, keywords, and referring websites can each yield a very large number of distinct audience segments, the number of segments a team can effectively target is limited by human bandwidth. When done manually, this process is highly tedious to run and manage, and is intractable at true scale.\n\nBut as we’ve seen above, it’s comparably easy for machines to strategize, develop content, deploy experiences, and learn from the results. By setting guardrails and having humans verify instead of creating the content, businesses can ensure these experiences are highly relevant and personalized for far more people.\n\n\n\n\n\nWhile it’s much easier to verify outputs than it is to create them, at some level, even verification becomes difficult to manage. This principle extends to quant experimentation broadly. Fortunately, this is another area that generative AI excels at: By rigorously defining precise parameters and rules by which outputs must abide, we can also have the AI perform checks at scale, drastically reducing the risk of problematic outputs (this applies to content created by humans as well). And while not yet practical due to the current cost of token generation, you can see where this might be headed: total one-to-one personalization—a different page, site, and experience for each customer.\n\nThis is only the beginning. We see companies starting to discover and deploy more advanced quant strategies in all aspects of marketing and growth every month. As with any tool, quant experimentation requires its own artisanry and judgment—indeed, an entirely new way of thinking. In quant trading, traders carefully define a clear strategy with a scope and guardrails before letting the machines loose. The same is true in quant experimentation: A high-level strategy is defined, specific elements of the user experience are scoped, and guardrails are put in place. Then the machines do what they do best: optimize.\n\n\n\n\n\nTo read more essays like this, subscribe to Every, and follow us on X at @every and on LinkedIn.\n\nWe also build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Write something great with Lex.\n\n\n\n",
      "word_count": 2247,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3388/thesis_man.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3565/thumbnail_Eliot_Peper_companion_piece(2).png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "thesis"
    },
    {
      "url": "https://every.to/working-overtime/i-hired-chatgpt-as-my-career-coach",
      "title": "I Hired ChatGPT as My Career Coach",
      "author": "Katie Parrott",
      "author_url": "/@katie.parrott12",
      "publication_date": "October 7, 2024",
      "content": "I Hired ChatGPT as My Career Coach\n\nAI changed how I think about work—and myself\n\nWhen Katie Parrott lost her job, she turned to an unlikely source for career guidance: ChatGPT. In this piece, Katie details her experiment using AI as a career coach, exploring its strengths and limitations in providing originality, accountability, structure, empathy, and clarity. Her journey reveals both the potential and pitfalls of AI in personal development, underscoring that while AI can be a powerful tool for self-reflection, the real work of career growth remains deeply human.—Kate Lee\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nA few weeks ago, my therapist floated the idea that I should hire a career coach. It would have been a great idea—if I hadn’t just lost my job.\n\nI’m certainly the type who could benefit from a career coach. My relationship with work has always been fraught, and I am at a particularly murky spot in my career. In the past 10 years, I’ve worn a lot of hats: I’ve worked at companies, agencies, and as a freelancer. I’ve worked in software, healthcare, and venture capital. I’ve been an individual contributor and a people manager. And yet, I feel no closer to knowing “what I want to do with my life” than I did when I graduated from college.\n\nSo yes, I wanted help. But while I’m lucky enough to have “runway,” as startups say, that doesn’t mean I have $100–$150 per hour to spend on a career coach.\n\nSomething I do have, however, is a subscription to ChatGPT.\n\nI figured if I couldn’t retain the services of a human career coach, why not try AI? I consider myself an AI skeptic, but even I am often astonished by what large language models can do. I’ve read Dan Shipper’s essays in Chain of Thought; I’ve seen how you can use AI for deeper thinking. If ChatGPT really is a copilot for the mind, as I’ve been promised, shouldn’t it be able to help me navigate the big, messy question of what I am doing with my life?\n\nSo, one day last month, I opened ChatGPT—with some dread, some hope, and lots of curiosity—and typed this prompt:\n\n\n\n\n\nWhat follows is part performance review of ChatGPT in the role of my career coach and part descent into AI’s uncanny valley. Let’s start at the very beginning.\n\nAt the outset of this experiment, I spent some time thinking about what I would want in a career coach. If I could program mine (which, let’s be clear, is exactly what I am doing), what features would I want it to have?\n\nI wanted originality—not the same platitudes I could read on LinkedIn or in the Personal Growth section at Barnes & Noble. I definitely needed accountability and structure—something to motivate me and keep me from getting distracted. And on a certain level, I just craved empathy. The last few years have been a slog, professionally. Each role I’ve taken on has felt, to one degree or another, like trying to fit a round peg into a round hole. I just wanted someone who could understand what that felt like. And finally, clarity. That’s really what I was after, ChatGPT or no ChatGPT: a sense of direction for the next stage of my career.\n\nThe question in front of me, the question this whole experiment revolves around, was: Could ChatGPT give me all of that?\n\nIt didn’t seem fair not to tell the bot the parameters it was being judged against. So I entered these stipulations into my custom instructions. I specified that I wanted ChatGPT to act as a career coach with expertise in content marketing, tech, and startups. I asked it to provide actionable advice, challenge my assumptions, and offer encouragement when appropriate. In other words, I told it what I needed from a career coach in a way I’d honestly probably have a hard time doing to a human being.\n\n\n\n\n\nWith these instructions in place, I began our first “session.” Put that in AI’s “pros” section: CareerGPT is always in session.\n\nOnce I set up CareerGPT, as I’ll now call it, the first thing it gave me was an intake survey—not all that different from what you might expect from a human career coach.\n\n\n\n\n\n\n\n\n\nFor example, I’ve rediscovered that, yes, writing is the work that interests and energizes me. And that’s a question the chatbot asked me directly: What kind of work energizes you, even if it doesn’t perfectly align with what you’ve done before? That may not be the most novel question, but it’s one that genuinely caused me to step back and take my answer seriously.\n\nSo, how does it all balance out? How do we rate CareerGPT for originality in our performance review? I’m going to say meets expectations.\n\nOriginality is all well and good, but what’s the point of a career plan if you don’t have someone holding you accountable for executing it? I’m not always the most disciplined when left to my own devices. I tend to chase whatever opportunity seems new and interesting (and also attainable). What I needed from CareerGPT wasn’t just ideas—I needed a mechanism for actually getting those ideas off the ground. Can CareerGPT offer a prescription for my shiny object syndrome?\n\nWell, it depends. There isn’t really a mechanism for ChatGPT to provide accountability. It can’t send me push notifications or meet at regularly scheduled times with fees for missed appointments. You have to prompt ChatGPT or schedule your own sessions with it. ChatGPT doesn’t care.\n\nI’ve found ChatGPT to be a bit of a pushover in other ways, too. If I veer off course or procrastinate, it doesn’t call me out or give me a reality check. For example, I told the AI, “I think I want to pivot into full-time writing,” and at the time it responded with enthusiastic support and ideas for how to do that. But when I second-guess myself and tell it, “Maybe I should focus on strategy work instead,” it doesn't respond, \"Wait a minute—what happened to the writing goal we discussed?” It just rolled with the new idea.\n\n\n\n\n\nAnd for the most part, it has. It’s started asking me: Is this really what you want to be doing? And it’s also held me accountable in a different way. In a moment of nuance I can’t take credit for prompting, it challenged my thinking that I have to choose between writing and strategy. Chat essentially called me out for black-and-white thinking, the same way my therapist—or a human career coach—would.\n\n\n\n\n\nOf all the things I wanted from CareerGPT, the one I was most confident that it could give me was structure. If I wanted logic and intellectual rigor for my career quest, who better to deliver that than a machine designed to process vast amounts of data and draw conclusions based on patterns?\n\nTo be honest, my early impressions on this front were hit and miss. A lot of the time, ChatGPT’s responses to my prompts seemed to open five new doors when what I needed was help walking through one.\n\nI decided to change how I prompted it. Instead of asking vague, open-ended questions like, “What should I do with my career?” I started breaking down questions into specific components. I started to structure my queries more intentionally, so that CareerGPT could give me structure back.\n\nFor example, I asked it to help me come up with my own personal “positioning statement” based on a framework I once learned while working at an advertising agency:\n\n\n\n\n\nIn doing this, something surprising happened: I realized that by giving ChatGPT more specific prompts, I was forcing myself to think more clearly about what I wanted. It wasn’t just about asking better questions to get better answers; it was about developing the mental discipline to figure out what exactly I was trying to solve. In many ways, I was training myself just as much as I was training ChatGPT.\n\nSo, how do we grade CareerGPT for structure? I’d say it exceeds expectations—as long as you’re willing to do the work to meet it halfway.\n\nMy favorite quote about love is that it is about “bottomless empathy, born out of the heart’s revelation that another person is every bit as real as you are.” I think that’s a beautiful summary of what many of us are looking for in a partner. It’s also a beautiful summary of what I wanted from CareerGPT.\n\nIt’s a fundamental thing we want from anyone who works in the “emotional labor force”—be they therapists, career coaches, or cast members at Disney World. We want to feel understood. We want someone to say, “Yes, I hear you. I am on your side.” Could ChatGPT deliver that kind of support?\n\nI realize there’s something paradoxical about saying I want CareerGPT’s emotional labor when I just said I wanted it to stop being such a “yes” bot. That’s a tension that exists at the heart of any coach-coachee relationship. On one hand, we want validation, support, and guidance—someone or something to tell us we're on the right track and make the path forward seem less daunting. On the other hand, true growth often comes from being challenged. A human coach finds the right balance with a combination of intuition, practice, and social cues. How does CareerGPT fare?\n\nA few weeks back, I was struggling with a decision about publishing an essay I had written for my newsletter. I worried that it was too personal and that my audience would hate it. I typed my angst into ChatGPT and the output I got back surprised me:\n\n\n\n\n\nAnyway, Chat certainly gives an effective pep talk, whether that’s something it learned to do or the net aggregate of all of the Internet circa 2021 pointing in the direction of, “Yay, you can do it!” A few days ago, I was feeling despondent about my ability to make it as a writer, and I typed my angst out at ChatGPT:\n\n\n\n\n\nLesson learned: ChatGPT has mastered cheerleader mode, but it also keeps things businesslike by directing focus back to the task at hand. How do we rate CareerGPT on empathy? Meets expectations.\n\nOne of my favorite things about writing is that I never know what I think until I write it down, but once I write it down, it becomes obvious. Writing is an exercise in clarity—in making apparent what it is you already think.\n\nUltimately, that’s what prompting ChatGPT is: a form of very specific, strategic writing. Do I think my experiment with ChatGPT has added clarity to my thinking? Yes, it has. It’s true that GPT-4 is a reasoning engine, and it’s helped me reason through my career to a level of, if not exactly clarity, then at least more purposeful uncertainty.\n\nI give CareerGPT credit: It has helped me formalize my thoughts and offered guidance that, at times, nudged me toward a clearer understanding of what I want. But, as with so many of these tools, the real work was still mine. Clarity, it turns out, doesn’t arrive gift-wrapped from a digital assistant or even a human coach. It’s something I had to dig out for myself, question by question, prompt by prompt.\n\nFor providing clarity in my job exploration, I give ChatGPT meets expectations.\n\nOn some level, I wanted ChatGPT to assign me my perfect life path—one that fits me so well I didn’t need to question it, based on some hidden logic or insight that was inaccessible to my human brain.\n\nBut as much as I’ve hoped for one unique, career-clarifying answer, that’s not what generative AI offers. It’s a mirror that helps me see my own thinking, not a map that leads me to some predetermined destination. It provides structure where I ask for it, challenges when I prompt it, and clarity when I’m willing to dig for it. But the real work—of deciding, questioning, and ultimately owning my career journey—is ultimately up to me.\n\nThat said, when I look over the many conversations I have had with ChatGPT since I started this experiment, I see progress. I’ve updated my résumé, revived my newsletter, reconnected with colleagues, and pursued opportunities that excite me. I’ve thought deeply and strategically about what I want from the next stage of my career whereas, left to my own devices, I may have leaped blindly into yet another role without thinking about whether it will lead me where I ultimately want to go.\n\nWhat this experiment taught—or maybe reinforced—is that generative AI isn't a magic genie that will deliver a clear-cut career path on demand. Instead, it's a tool—a powerful one—that can help you sharpen your thinking, ask better questions, and uncover insights you might otherwise overlook. But at the end of the day, it’s still just a tool. True clarity, direction, and answers come from the process of engaging with the prompts and doing the hard work yourself. AI can help guide the way, but the journey is yours to take.\n\n\n\n\n\nTo read more essays like this, subscribe to Every, and follow us on X at @every and on LinkedIn.\n\n\n\n",
      "word_count": 2195,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3277/Cover_Image_Frame-1.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3583/thumbnail_03_career_advice.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3596/thumbnail_aimemo.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3468/thumbnail_Screenshot_2025-02-24_at_10.33.50_AM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "working-overtime"
    },
    {
      "url": "https://every.to/working-overtime/the-once-and-future-history-of-knowledge-work",
      "title": "The Once and Future History of Knowledge Work",
      "author": "Katie Parrott",
      "author_url": "/@katie.parrott12",
      "publication_date": "November 22, 2024",
      "content": "The Once and Future History of Knowledge Work\n\nTechnology brought knowledge work into this world. Can AI take it out?\n\nArtificial intelligence is changing the value of knowledge work—something that Katie Parrott, as a knowledge worker herself, has been grappling with. So it’s a fitting topic of exploration for the debut piece of her column, Working Overtime, in which she’ll examine the historical impact of technology through the lens of workers and the systems they participate in. (Longtime Every readers may recognize her byline from when she served as our managing editor.) Knowledge work is a term, Katie writes, that’s long made her somewhat uncomfortable because of its elitist connotations. But the rise of AI offers an opportunity to reevaluate both the lingo and the role that so-called knowledge workers play in society and the economy.—Kate Lee\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nIn 1999, management consultant Peter Drucker made a prediction that was either prophecy or hubris: Knowledge workers, he wrote in California Management Review, would be “the most valuable asset of a 21st-century institution.” A quarter of the way through the century, however, the future of knowledge work has never been more uncertain—thanks in no small part to generative AI.\n\nThe term “knowledge work” has always made me uneasy. Coining the term in 1959, Drucker defined it as “high-level” professionals who use their theoretical and analytical expertise, often gained through formal education, to create products and services. I couldn’t begin to tell you how to wire a house or repair a car. Those jobs require immense skill and vast knowledge, yet they are rarely classified as “knowledge work.” This corporate lingo carries more than a tinge of classism, social hierarchy, and condescension—as if real work happens only in front of a computer screen, pushing pixels around and complaining about the hardship of having one’s camera on during Zoom calls.\n\nThat said, as a marketer, I very much fit Drucker’s definition of a knowledge worker, regardless of how that makes me feel. And as someone who would like to pay her bills for the next 50-plus years, I have a vested interest in understanding how AI will affect knowledge work—and thus, my career.\n\nPerhaps it wouldn’t be such a bad thing if knowledge work were to see a shakeup in the wake of AI. After all, it’s become a little big for its own britches over the past couple of decades, dominating our collective understanding of what makes a “good job.” Maybe knowledge work deserves to be taken down a few notches.\n\nWith the proliferation of new models capable of doing everything from writing code to creating images to completing legal documents, we’re approaching an inflection point in the evolution of knowledge work. So it’s worth taking stock, both of the road that got us here and the roads we could go down next. Think of this essay as a visit from the ghosts of knowledge work past, present, and future, and then ask: What might the future hold for knowledge work—and what kind of work do we want to shape the rest of the 21st century?\n\n\n\n\n\nWhen you write a lot about AI like we do, it’s hard not to see opportunities. We build tools for our team to become faster and better. When they work well, we bring them to our readers, too. We have a hunch: If you like reading Every, you’ll like what we’ve made.\n\nDrucker may have coined “knowledge work,” but the concept didn’t spring forth from his brain fully formed and ready to complete Jira tasks. The term may only go back a few decades, but people have been doing knowledge work for millennia. Oral storytellers, monks inking manuscripts, gentlemen scientists writing treatises on the origin of species and other such ideas—all of these represent prototypical forms of what today we recognize as knowledge work.\n\nThe fate of knowledge work and technology have long gone hand in hand. If we’re tracing knowledge work’s modern iteration, the starting point is the Industrial Revolution. The introduction of factories, complex machines, and assembly lines meant that fewer people were needed to do manual labor, and in their place arose a need for management strategies and administrative and clerical work. By the time Drucker, a longtime New York University professor and winner of the Presidential Medal of Freedom, came up with the term “knowledge work” in the late 1950s, mainframe computers had already arrived, with their ability to crunch data at many, many multiples the speed of human data analysts.\n\nAnd then came the personal computer in 1974. And Microsoft Excel in 1987. And public access to the World Wide Web in 1991. Each subsequent technological innovation accelerated the rate at which work could get done and, yes, rendered some occupations obsolete or less prevalent. But it also brought with it new forms of knowledge work and new knowledge workers with specialized skills to do that work. Computer programmers, information technology and cybersecurity professionals, web designers, digital marketers—all were created in response to modern technology.\n\nAs knowledge work has grown, so has its status. Economists talk about the “skill premium”—the difference in pay between “high-skill” workers with advanced education, training, or expertise, and “low-skill” workers with fewer qualifications or specialized skills. For decades, the skill premium has increased—even as the number of knowledge workers has grown, as economist Daniel Susskind wrote in his 2020 book A World Without Work. More than 60 percent of U.S. workers are classified as “white collar” as of 2023, yet these jobs continue to command higher wages than most “low-skilled,” “blue-collar” jobs. This flies in the face of conventional wisdom about supply and demand, which tells us that a product, even labor, grows less valuable the more supply exists.\n\nThe forces of technological change have not been as kind to other segments of the economy. The past few decades have seen a “hollowing out” of the middle class—a sort of unequal barbell effect that, yes, has pushed some earners into the economy’s penthouse, but has pushed far more into the basement.\n\nThere are factors at play here besides technology—most significantly, the offshoring of manufacturing and the U.S.’s subsequent transition into a predominantly service-based economy. But even there, technology has played a starring role, facilitating communication and productivity even when teams are oceans apart. And so the pattern stands: When new technology is introduced, knowledge work benefits while other forms of labor take a hit. The question then becomes: Will generative AI continue this pattern, or break it?\n\n\n\n\n\nIn the decades between the Industrial Revolution and the AI revolution, it seemed like knowledge work was marked safe from the rise of automation. When management consultants and economists stressed the threat to “routine tasks,”  it called to mind cashiers and assembly line workers, not lawyers, graphic designers, and—yes—management consultants. After all, how could you automate the complex, cognitive tasks that defined office life—things like writing reports, analyzing data, crafting strategies, or managing teams, right? Right?\n\nWell, the joke’s on us. As it turns out, machines can do all of those things better, faster, or at the very least cheaper than humans can. The Pew Research Center, the Brookings Institution, and McKinsey and Company all forecast that the workers most likely to see “exposure” to generative AI are more educated and in higher-paid fields such as computer science, business and finance, legal, and management.\n\nThis shift has ushered in what Every’s Dan Shipper calls an allocation economy, where the value of work increasingly hinges not on traditional labor but on how we allocate scarce resources—time, attention, and focus. In this new paradigm, the question becomes less about what AI can do and more about how we choose to use it, what we allow it to replace, and what we choose to preserve as uniquely human.\n\nTechnology has historically had two countervailing effects on labor—what economists call the “substituting force,” which replaces labor, and the “complementary force,” which augments it. Generative AI optimists argue the complementary force has won out through each subsequent wave of technology. A classic example is the ATM, which should have replaced bankers but correlated with an increase in bankers instead as those bankers, freed from the tedium of counting out bills, put their financial knowledge to work developing new products and services for bank customers to take advantage of. Generative AI will be no different, proponents claim. It will give knowledge workers “superpowers,” automating away the boring, tedious aspects of knowledge work and leaving more time for high-level, creative, and emotional tasks—the kind of tasks, the thinking goes, that only humans can perform.\n\nHowever, not everyone who studies AI’s impact is so bullish. With generative AI poised to automate an increasing number of business activities—as much as 70 percent , according to McKinsey—critics worry there simply won’t be enough work left over for most workers to do. For the first time in history, the argument goes, technology’s substituting force will overwhelm the complementary force. Already, Susskind writes, the most valuable company in the world, Apple, employs about 20 percent as many people (160,000) as the most valuable company of 50 years ago, AT&T (750,000). If this shrinking trend continues, and with the possibility of one-person billion-dollar companies on the horizon, there may just not be enough work to go around—even for knowledge workers.\n\nWhile much of the discourse around AI’s impact tends to polarize around “more jobs” or “fewer jobs,” there is a third alternative: different jobs. Some economists predict that, unlike industrial automation, AI will reduce the skill premium, acting as a corrective force on the disparity between wages for “skilled” and “unskilled” labor. They argue that generative AI can help restore “middle-skill, middle-class” jobs to the U.S. market that were displaced by industrial automation and globalization. And then the question becomes: If knowledge work no longer commands a wage premium—if new pathways open up that lead to economic security and even prosperity—who will still choose knowledge work, and who will choose something else?\n\nNow comes the part where we peer down the possible roads that generative AI could lead us. The blueprints for each of these roads are in our hands—we have the materials to build them at the ready. So which one will we build?\n\nTechnology continues to do what it has done for more than a century: create new jobs. Meanwhile, AI lowers the barrier to entry, more people can become knowledge workers, and knowledge work itself becomes democratized. The economic pie grows and everyone gets a bigger slice. As more people join the ranks, the exclusive luster of knowledge work dims—but that’s a good thing. The deglamorization of knowledge work levels the playing field between it and other forms of labor, and professions that have historically been devalued and marginalized—such as care work and service work—assume their place among the things “humans do best.”\n\nAI doesn’t just replace some of us—it displaces a lot of us. The hollowing of the labor market not only continues but accelerates, with a small class of elite knowledge workers holding on to the complex, creative jobs that AI can’t quite manage, while everyone else finds themselves funneled into lower-paying, less secure roles. Knowledge work becomes hyper-specialized, a luxury job for the few, and its aura of prestige and exclusivity ossifies into a silicon ceiling that is impossible for most of the population to crack.\n\nWith AI doing the grunt work, we’re free to pursue our passions. Knowledge work and the cult of productivity lose their centrality to our identities, and instead, we engage in creative endeavors, pursue hobbies, and take on entrepreneurial projects—not because we have to, but because we want to. It’s the dream of a post-scarcity economy: Work becomes optional, and we’re left with the freedom to explore what matters most to us.\n\nThe future of knowledge work may be uncertain, but we have a say in how AI reshapes our lives and livelihoods. It’s easy to feel dwarfed by the pace of technological change, to imagine that the future of work is something that happens to us, rather than something we have the power to shape.\n\nBut this perspective gives us too little credit. We have agency, as workers, voters, and participants in the economy, to advocate for frameworks that guide AI’s influence in directions that support human dignity, opportunity, and equality. Instead of letting the sheer efficiency and velocity of technology dictate our path, we can demand social and economic norms that center people alongside profit.\n\nThis will require a collective will to prioritize humanity over efficiency, and depth over speed. It means questioning the motives behind AI deployment—who benefits, who loses, and who decides. It means writing legislation, regulations, and industry policies that protect meaningful work for all and exploring new forms of social and economic support for those affected by this shift.\n\nThe future of knowledge work is not a foregone conclusion. It’s a construction site where we have the chance to lay down each brick with intention. It's also an opening, a chance to imagine a world where work doesn’t define us, where we have space to pursue what we love, regardless of whether what we love comes with a desk or a degree attached. That world isn’t guaranteed, but it’s there if we’re willing to build it—brick by brick, pixel by pixel, person by person.\n\n\n\n\n\nKatie Parrott is a writer, editor, and content marketer focused on the intersection of technology, work, and culture. You can read more of her work in her newsletter.\n\nTo read more essays like this, subscribe to Every, and follow us on X at @every and on LinkedIn.\n\nWe also build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Write something great with Lex.\n\n\n\n",
      "word_count": 2302,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3321/Screenshot_2024-11-22_at_9.36.24_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3389/thumbnail_Screenshot_2025-01-07_at_11.17.17_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3468/thumbnail_Screenshot_2025-02-24_at_10.33.50_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3583/thumbnail_03_career_advice.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "working-overtime"
    },
    {
      "url": "https://every.to/working-overtime/ai-phobia-is-really-just-fear-that-easier-equals-cheating",
      "title": "AI Phobia Is Just Fear That ‘Easier’ Equals ‘Cheating’",
      "author": "Katie Parrott",
      "author_url": "/@katie.parrott12",
      "publication_date": "April 15, 2025",
      "content": "AI Phobia Is Just Fear That ‘Easier’ Equals ‘Cheating’\n\nWhat a wave of ‘zero-AI’ policies reveals about our obsession with hard work\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nThe stories follow a familiar pattern. A writer reports they have been dropped by a client—not because their work is bad or inaccurate, but because an AI detection tool flagged their human-written content as machine-generated.\n\nThese aren’t isolated incidents. From the U.S. to the UK to South Africa to Pakistan, writers have been caught in a bizarre paradox: accused of using AI when they haven’t, while agencies, freelancer platforms, and individual clients alike double down on “zero-AI” policies enforced by detection tools that are, at best, inconsistent. One writer went as far as to offer to screen-record himself typing an article to prove it was “real.” A copywriter in Ohio sent his client time-stamped drafts to prove he’d written it himself—but the client walked anyway.\n\nWhy do these businesses care so much? I suspect they aren’t really worried about AI—they're clinging to an old belief that if work isn't visibly difficult to produce, it must be less valuable. When we dig beneath the surface of \"no-AI\" policies and detection tools, we find an age-old assumption that worth must be measured in struggle. This mindset shows up again and again, from “hustle culture” and the “rise and grind’ mindset that defined the 2010s to recent return-to-office mandates that prioritize presence over performance. In a culture that values butts in seats and availability on Slack, it becomes easy to mistake friction for effort and effort for worth.\n\nOddly enough, the very thing we’re resisting—the ease of AI—might be what sets us free. AI isn’t the first tool to challenge how we think about work, but it may be the most direct. By shifting the locus of effort, AI forces us to confront our dysfunctional relationship with work. It holds up a mirror to our culture’s deeply rooted belief that struggle equals value—and in that reflection lies a rare opportunity: to reimagine work in terms of outcomes, not optics; human flourishing, not performance theater.\n\n\n\n\n\nMake email your superpower\n\nNot all emails are created equal—so why does our inbox treat them all the same? Cora is the most human way to email, turning your inbox into a story so you can focus on what matters and getting stuff done instead of on managing your inbox. Cora drafts responses to emails you need to respond to and briefs the rest.\n\n\n\n\n\nModern resistance to AI is just the latest chapter in a long history of moral anxiety about ease. From colonial Massachusetts—where idleness was literally illegal—to the rise of “scientific management” in the early 1900s, visible labor has been equated with virtue.\n\nThe Puritans made work a spiritual mandate. The Luddites died defending the dignity of skilled labor. And when Frederick Taylor brought stopwatch logic to factory floors in 1911, union leaders warned it would turn “proud artisans into mindless machines.” From era to era, new tools have triggered the same fear: not just of obsolescence, but of losing the moral weight we attach to effort.\n\nA century after Taylor's stopwatch-wielding efficiency experts, we're still obsessed with measuring the performance of work rather than its results. Only now, the surveillance is digital, constant, and often invisible.\n\nAnne Helen Petersen once memorably described this as \"LARPing your job\"—performing a theatrical version of productivity. Workers engage in elaborate displays of \"being at work\": staying visible on Slack, responding to emails at all hours, and maintaining a digital presence that signals industriousness. The tools have evolved—from software that monitors keyboard activity to AI that analyzes facial expressions in video calls—but the underlying philosophy remains pure Taylorism.\n\nThe irony is that these measurements often have little correlation with value creation. Knowledge work rarely follows linear patterns. Our most valuable contributions often come from reflection, seemingly \"unproductive\" conversations, exploration of dead ends, and invisible mental processing.\n\nConsider a writer working on a complex piece. Their most productive day might involve two hours staring out a window thinking, a long walk where they mentally structure their argument, and 30 minutes of rapid typing. But depending on who’s doing the measuring—a client, a manager, a budget-conscious private equity buyer—only those final 30 minutes might count as “real” work.\n\nThis narrow view of productivity—favoring what can be seen, tracked, or timed—helps explain our conflicted relationship with AI. Yes, impact matters, and it would be overly simplistic to claim organizations don’t reward outcomes. But in many contexts, especially where results are hard to measure, visible effort still carries disproportionate weight. When so much of our working life is spent proving we’re working, it’s no wonder we’re uneasy with tools that make effort disappear.\n\nWhen people reject AI-assisted work, they often cite concerns about quality, authenticity, or ethics. But look closer, and you'll find the same reflex that makes us suspicious of any solution that seems too easy. AI triggers this response powerfully because it doesn't just make work easier—it can make it look effortless, even when it’s not. A writer might use AI to structure a draft—but the real work lies in shaping the argument, refining the tone, and deciding what’s worth saying. The labor hasn’t disappeared. It’s just moved somewhere less visible.\n\nWhat makes resistance to AI fascinating is how it differs from previous technological advances. When calculators became widespread, nobody argued that \"real mathematicians\" should still do long division by hand. When word processors replaced typewriters, we didn't insist that \"authentic writing\" required correction fluid. Resistance to these technologies tended to be more about the importance of the journey than the validity of the destination. For instance, teachers worried about calculators because they feared students would lose the ability to think mathematically.\n\nBut the aforesaid writers on LinkedIn are professionals, not undergraduates trying to hit a word count. They aren’t trying to skip the hard part. They’ve spent years developing a voice, a process, a point of view. Those are the skills that make them valuable, not the fact that they can put one word after the other. Yet even when the output is demonstrably good—too good, by the standards of whoever happens to be deciding at that moment—there’s a tendency to dismiss that work as less legitimate because it didn’t look hard to produce. The writer’s expertise, honed over years, gets erased the moment a tool enters the frame.\n\nAI isn't just another technology to adapt to. It's potentially the most powerful catalyst we've ever had for breaking our unhealthy relationship with effort. Unlike previous technological shifts that changed how we performed work, AI offers us a chance to fundamentally rethink why we work and how we measure its value.\n\nHere's what a healthier approach might look like:\n\nReflection, curation, context-setting, deciding what not to do—these are some of the most valuable forms of labor in an AI-assisted world. But they’re often invisible because they don’t “look” like work.\n\nAI doesn’t eliminate labor; it redistributes it. What’s left behind is often harder to measure, but far more human. It’s time we recalibrated our definition of productivity to include the quiet, often invisible thinking that makes good work possible.\n\nAs AI handles more routine tasks, our definition of expertise needs to evolve. The most valuable skills won't be the ones AI can replicate. They'll be uniquely human abilities: asking better questions, seeing connections across domains, applying ethical judgment, building relationships, and imagining new possibilities.\n\nThis isn't a retreat from technology; it's an evolution enabled by it. AI can act as a force multiplier for human creativity, handling the mechanical aspects of work that have historically consumed our time and energy. When AI handles the drudgery, we're free to focus on the meaningful parts of work that deserve our attention.\n\nPart of the anxiety around AI is not knowing what’s being paid for. When the work looks effortless, how do we value it? We need new models of communication and trust that make invisible labor visible: explaining what decisions were made, which tools were used, where discernment was applied. Not performative updates—but real transparency that restores confidence in both the process and the person.\n\nThe rise of AI is forcing us to confront our complicated relationship with effort and worth. But this reckoning was long overdue. Our attachment to suffering as a proxy for value has been undermining our work, well-being, and creativity for centuries.\n\nAs we navigate this transition, AI offers us more than just new capabilities. It offers liberation from centuries of equating worth with struggle. It gives us a chance to build something fundamentally better—a relationship with work that values impact over appearance, efficiency over suffering, and human flourishing over performance.\n\nWhat if we saw AI not as a threat to authentic work, but as the tool that finally frees us from the tyranny of unnecessary effort? What if the \"AI revolution\" isn't about replacing humans, but about releasing us from Industrial Age assumptions about labor that have constrained us for too long?\n\nIt won't be easy to break habits of mind that date back to the Puritans, but AI challenges our assumptions about necessary effort so fundamentally that it could finally break the link between suffering and value that has defined work for generations.\n\nThe next time someone reflexively rejects AI-assisted work, we might gently ask: Are you concerned about the quality, or just uncomfortable with the ease?\n\n\n\n\n\nWe build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Write something great with Lex. Deliver yourself from email with Cora.\n\nWe also do AI training, adoption, and innovation for companies. Work with us to bring AI into your organization.\n\nGet paid for sharing Every with your friends. Join our referral program.\n\n\n\n",
      "word_count": 1634,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3552/Screenshot_2025-04-15_at_10(2).53.16_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3389/thumbnail_Screenshot_2025-01-07_at_11.17.17_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3583/thumbnail_03_career_advice.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3568/thumbnail_vibe-coder-cauldron.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "working-overtime"
    },
    {
      "url": "https://every.to/working-overtime/every-ceo-is-writing-the-same-ai-memo-here-s-what-they-re-really-saying",
      "title": "Every CEO Is Writing the Same AI Memo. Here’s What They’re Really Saying.",
      "author": "Katie Parrott",
      "author_url": "/@katie.parrott12",
      "publication_date": "June 2, 2025",
      "content": "Every CEO Is Writing the Same AI Memo. Here’s What They’re Really Saying.\n\nBehind the ultimatums and urgency, leaders are admitting they need your help\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\n\n\nYour CEO is about to write an AI memo.\n\nI know because I've been collecting them like disaster preparedness manuals, and they're multiplying faster than ChatGPT responses. It’s a professional survival instinct: If I know what these CEOs want, I’ll be able to give it to them—and I’ll be safe from this particular flavor of apocalypse.\n\nBarely a week goes by without another internal memo screenshot rocketing across X or LinkedIn, mixing optimism about what AI promises with urgency about what it portends. The results come across as part pep talk, part ultimatum: Get fluent with AI, or get left behind.\n\nIt all kicked off when Shopify CEO Tobi Lütke posted his memo to X, declaring that \"reflexive AI usage is now a baseline expectation” at the e-commerce giant. Within weeks, similar manifestos emerged from Duolingo, Box, Fiverr, and Walleye Capital. The speed of the cascade itself is a signal: AI sophistication has reached a point where CEOs feel compelled to act. Fast.\n\nThese aren't just corporate communications; they're cultural artifacts—real-time documentation of how organizations are processing the biggest shift in knowledge work since we all got email addresses. Digital archeologists of the future will look at documents like these as they piece together the story of how people navigated the earliest days of AI in the workplace.\n\nSo why wait? Let's see what these memos reveal about where work is headed, what leaders really mean when they say \"be AI-first,\" and—most importantly—how to navigate the productive tension between executive vision and ground-level reality. Because mark my words: If your CEO hasn’t sent out the “AI memo” or some kind of directive about how AI is or isn’t to be deployed, they’re about to. May this survey help you prepare.\n\nYou’re not going to get good at AI by nodding through another slide deck. Every Consulting helps teams level up—fast. We’ve trained private equity firms, leading hedge funds, and Fortune 500 companies. Now it’s your turn. Customized training. Hand-held development. A rollout strategy your team will actually use. Let’s make your organization AI-native before your competitors do.\n\nTry us out today.\n\nReading these memos back-to-back is like watching five directors tackle the same script. The plot points are identical—AI is here, we need to adapt, the future depends on it—but the emotional registers couldn't be more different.\n\nOn one end, there's Will England, CEO of hedge fund Walleye Capital (an Every Consulting client), practically vibrating with enthusiasm. ChatGPT isn't just a tool; it's a \"magical elixir that makes you 20 percent smarter instantly.\" His memo reads like a tent revival for the algorithmically enhanced. \"Not using these tools is like refusing to use the internet in 1995,\" he declares. \"That's just dumb.\"\n\nOn the other end sits Fiverr's CEO Micha Kaufman, who opens with the rhetorical equivalent of a cold shower: \"AI is coming for your jobs. Heck, it's coming for my job too.\" He suggests employees might need to \"scream hard in front of the mirror\" before getting to work. It's radical candor turned up to eleven—part motivational speech, part existential crisis.\n\nBetween these poles, the other CEOs strike different notes. Lütke wraps Shopify's mandate in philosophical metaphors about red queens and constant running. Box's CEO Aaron Levie stays pragmatically focused on eliminating \"drudgery.\" Luis von Ahn at Duolingo took what seemed like the measured strategist approach, comparing AI to the company’s prescient mobile bet. (Note: Von Ahn has since reversed course on key parts of their memo after consumer backlash over plans to replace human contractors with AI.)\n\nBut look past the tonal differences and a unified message emerges. Every memo shares three core elements:\n\nThese aren't stone tablets handed down from the C-suite. They're leaders thinking out loud about a transformation that's moving too fast  for anyone to fully grasp it. The range of tones—from evangelical to apocalyptic—reveals just how much uncertainty lives beneath the surface of these seemingly definitive declarations.\n\nIf messaging reveals what CEOs are feeling, implementation shows what they actually value. The tactics they choose and outcomes they track expose their real priorities—and what they think AI adoption should look like. Here's what their approaches reveal.\n\nLütke kicked off the memo trend by baking AI into Shopify's infrastructure. AI usage joins performance reviews, teams must prove they can't automate before getting headcount, and every project's prototype phase \"should be dominated by AI exploration.\" The focus is on multiplier effects—top talent plus AI yielding \"100x\" gains. AI isn't an add-on anymore; it's how Shopify defines competence.\n\nWalleye Capital’s England turns adoption into a competitive sport: $25,000 bounties for tool suggestions, public leaderboards with \"real cash prizes,\" weekly meetups. He's betting traders will refresh their ChatGPT stats like they track P&Ls. Success is simple—who's using it, how often, which departments lead. If you can gamify trading, you can gamify AI.\n\nLevie frames AI as liberation from \"drudgery\" with a twist: Teams that automate keep the savings for strategic projects. It’s an approach built around incentives—giving teams an upside and a reason to engage. Box tracks how much faster ideas move from concept to execution. The bet: AI savings shouldn't return to the CFO—they should fund your next breakthrough.\n\nVon Ahn at Duolingo takes the most aggressive stance: Phase out contractors for AI-capable work, make AI use part of hiring and reviews, prove automation before adding headcount. They're measuring transformation—which processes got rebuilt, how much content creation accelerated. The message: Don't tweak human systems, rebuild them (though von Ahn has since walked back parts after consumer backlash).\n\nKaufman offers to talk with Fiverr employees one-on-one about AI’s ramifications for their work,  pushing individuals to become \"prompt engineers\" and \"exceptional talents.\" No company metrics here—just personal transformation. Who's mastering their domain's AI tools? His framing is stark: Master AI or face \"career change in a matter of months.\"\n\nNotice what's missing across all five memos: traditional business metrics. No one's promising \"20 percent productivity gains by Q3\" or specific ROI targets—that is, not yet. They're tracking activity—usage, adoption, transformation.\n\nThis gap between mandate and measurement creates unexpected breathing room. While your CEO insists AI is urgent, they can't yet define what \"winning\" looks like. That uncertainty is your opportunity. You get to help write the success metrics, shape what \"good\" AI usage means in your role, and demonstrate value before it's codified into KPIs. By the time your company figures out what to measure, you'll already be the expert who helped define it.\n\nThe CEOs are essentially admitting: We don't know what we're optimizing for yet. We just know we need to move faster than competitors. Five experiments, five approaches. The variation itself is the message: We're all making this up as we go.\n\nYour CEO just dropped their AI manifesto, or you're sensing one brewing ahead of the next all-hands meeting. Here's how to navigate your organization's AI moment without waiting for someone to hand you a roadmap.\n\nFirst, decode what your CEO is really anxious about. Is it competitive pressure (that “we can't miss this wave” energy that led Duolingo to move too fast)? Efficiency mandates (Box's \"eliminate drudgery\")? Existential positioning (Fiverr's \"adapt or die\")? The specific anxiety shapes the opportunity. If they're worried about competition, show them differentiation. If it's efficiency, show how AI multiplies your impact. If it's survival, prove irreplaceability.\n\nStart documenting everything. Not just your wins—your experiments, failures, and half-baked theories. Public learning is the unlock. That quick prompt that saved you an hour? Write it down. The workflow that didn't quite work? Document why. You're not just building your own playbook; you're creating organizational knowledge.\n\nFind your bridge role. The gap between executive vision and daily reality isn't empty space—it's where the real work happens. Maybe you become the translator who helps your team understand what \"AI-first\" means for their specific work. Maybe you're the experimenter who tests tools and shares what sticks. Maybe you're the skeptic who asks the hard questions that make implementations better.\n\nRun weekly experiments. Pick one task you do regularly and try automating part of it. Not the whole thing—just one step. Share what you learn, especially the failures. Building \"reflexive AI usage\" isn't about perfection; it's about practice.\n\nWhat makes this moment remarkable is that leaders are mandating AI adoption while admitting they don't have all the answers. That admission creates an opening for everyone else. The rules are being written by whoever shows up to write them. Every prompt you craft, every workflow you reimagine, every experiment you run becomes part of your organization's AI playbook. You're not just following a transformation—you're designing it.\n\nThe most valuable employees right now might not be the ones with the most AI expertise. They're the ones who see the gap between what leadership imagines and what actually works—and who steps in to bridge it. They're turning vague mandates into practical systems, philosophical anxiety into actionable processes.\n\nWhether your CEO's memo reads like a tech evangelist's manifesto or an existential crisis, it gives you room to shape not just how you work, but how your entire organization adapts to this shift.\n\nThe only wrong response is waiting for someone else to figure it out first. The conversation has already started.\n\n\n\n\n\nKatie Parrott is a writer, editor, and content marketer focused on the intersection of technology, work, and culture. You can read more of her work in her newsletter.\n\nTo read more essays like this, subscribe to Every, and follow us on X at @every and on LinkedIn.\n\nWe build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Deliver yourself from email with Cora.\n\nWe also do AI training, adoption, and innovation for companies. Work with us to bring AI into your organization.\n\nGet paid for sharing Every with your friends. Join our referral program.\n\n",
      "word_count": 1673,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3596/aimemo.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3583/thumbnail_03_career_advice.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3568/thumbnail_vibe-coder-cauldron.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3468/thumbnail_Screenshot_2025-02-24_at_10.33.50_AM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "working-overtime"
    },
    {
      "url": "https://every.to/working-overtime/i-tried-ai-coding-tools-now-i-want-to-learn-to-code",
      "title": "I Tried AI Coding Tools. Now I Want to Learn to Code.",
      "author": "Katie Parrott",
      "author_url": "/@katie.parrott12",
      "publication_date": "March 17, 2025",
      "content": "I Tried AI Coding Tools. Now I Want to Learn to Code.\n\nHere’s what they don’t tell you about vibe-coding tools: They’re gateway drugs.\n\nWas this newsletter forwarded to you? Sign up to get it in your inbox.\n\n\n\nOne night last month, instead of booting up my Switch for another thrilling session of Stardew Valley, I decided I wanted to play a different kind of game. I decided I wanted to build an app.\n\nIt sounds crazy to say that so casually. Sure, I’m just going to throw together a quick MVP. I don’t write code. I don’t read code. But yeah, why not?\n\nTwo hours later, I had a minimum viable product ready to ship.\n\nThus was my introduction to the world of “vibe coding.” With AI-powered coding tools like Cursor, Replit, and my personal favorite, Lovable, anyone—even someone like me, with zero programming experience—can build functional applications just by describing what they want. In other words, based on the vibes.\n\nOf course, any technology shift this massive has its pitfalls and tradeoffs, and we’ll talk about those. But ultimately, it worked—for my modest use case, at least. It knocked down the mental block that has kept me away from software development since I became aware it was an option in high school. And if the buzz on my X feed and other corners of the internet I frequent is any indication, we’re in the middle of, well, a vibe shift.\n\nI used to hate being told to “learn to code.” I was defensive of the skills I already had. At the same time, I was afraid in that small, sneaky way that makes you avoid things that might reveal an uncomfortable truth. What if I couldn’t hack it—literally or figuratively? What if I wasn’t wired for this kind of thinking?\n\nFor a long time, the way I dealt with this was simple: I ignored it. I stuck to what I was good at. I worked around engineers, but I never wanted to be one. And I certainly didn’t want to hear, yet again, that learning to code was some kind of universal career insurance policy.\n\nNow that I’ve spent some time playing around with AI tools, though, I can’t believe I’m saying this: I kind of wish I knew how to code.\n\n\n\n\n\nGood ideas are all you need. Everything else can be done with the help of AI. Use LTX Studio to storyboard, develop, and bring your vision to life in seconds. Then, dive into their suite of ever-growing customization features to refine your creative vision:\n\nTell authentic, inspiring, and interesting stories, without cutting corners.\n\n\n\n\n\nBefore we get into the nitty-gritty, some backstory: How did I, an English and German Literature major, find myself staying up until 2 a.m. wrangling APIs and edge functions? I blame Every.\n\nWe have this thing called Think Week: a week per quarter where everybody at Every takes time off from their regular job tasks to explore ideas that don’t fit neatly into their daily work. One of the assignments in our most recent Think Week was to try an AI tool we’d never used before.\n\nI’d been meaning to redo my website for a while. The one I had was a holdover from 2017, built in Weebly, back when WYSIWYG was the hotness. It was functional but clunky, a relic from a time when I thought “owning your platform” meant cobbling something together with drag-and-drop tools.\n\nSo when our engineering lead Andrey Galko suggested I check out Lovable, a new AI-powered app builder that bills itself as “the last piece of software,” I figured, why not? I pulled up the site, created an account, and when the chat window opened up, I typed a single prompt:\n\n\"Create a website for a writer, editor, and content strategist who specializes in thought leadership for early-stage startups, builders, and VCs.\"\n\nSeconds later, Lovable spit out something eerily close to what I wanted—clean, polished, professional. Maybe a little “B2B SaaS 101” in its aesthetics, but miles better than anything I’d ever been able to put together.\n\nAnd then I felt it: a rush of satisfaction. A flicker of pride. The sudden, thrilling recognition that I had made something. “Look at that. I built that,” I thought. And then: “What can I build next?”\n\nSo I got ambitious. The contact page on my old website was just my email address in static text. This time, I wanted something more sophisticated—a real, live contact form that potential clients could fill out and would get routed to my inbox. Maybe I could even get it to send an automated email in reply.\n\nNext thing I knew, I was juggling a comic book movie cast’s worth of tools—none of which I would have touched even a month ago:\n\nThe website materialized with nothing needed from me except the patience to wait the ten seconds it took to load. But once I wanted the site to do something, like capture emails, the cracks in my knowledge started to become obvious.\n\nI kept hitting roadblocks. A missing API key, a misconfigured webhook, a permissions error in Supabase. Lovable would suggest fixes, and I would blindly copy-paste them into whatever terminal or settings panel it pointed me toward. But I had no idea if what I was doing was solving anything—or just introducing new problems down the line.\n\nI wanted to get into the code. To fix things. To do what I do when I write: tinker, refine, shape. But I couldn’t, because I don’t read code.\n\nThis felt backward somehow. AI was supposed to remove the need for technical knowledge, not make me want to learn it. Yet here I was, realizing that having a tool that could do it for me made me want to learn how to do it myself.\n\nI thought hitting these roadblocks would frustrate me into quitting. I’m not the most persistent person—I figured I’d accept my limits and return to the safe confines of turnkey solutions. Instead, it had the opposite effect. The more I bumped up against things I didn’t understand, the more I wanted to spend the time and effort to learn how they worked. I started thinking, ”What else could I make if I actually knew what I was doing?”\n\nI’ve kept “idea farms’ for writing for years—running lists of topics, angles, and thought starters for content. Now, I was keeping a different kind of idea farm: features I wanted to add, tools I wanted to try. Ideas like:\n\nIt’s an exciting, heady place to be: feeling like you can make anything, like the only limit is your imagination for the next killer app. Here’s the thing though: With AI doing the work, I was lost.\n\nThere’s a reason I hit a wall with my contact form. DIY tools and AI-generated code can take you far, but only so far. And when you don’t fully understand what’s happening under the hood, those limits are frustratingly opaque.\n\nThere are tradeoffs here:\n\nAI can spin up a website in minutes, but the moment something breaks, you realize how little you actually understand about how it works. If your site goes down or a critical function stops working, you can’t just logic your way through a fix—you either need technical knowledge or you wind up spamming your messaging window:\n\nStill not working.\n\nPlease fix.\n\nWhat’s going on here.\n\nOh no, something broke :(\n\nThat can get expensive fast—in time, and in dollars. I’ve had to level up my Lovable subscription twice already to get past messaging limits. If I were fluent in code, I could switch to the code view and troubleshoot the problem myself. AI coding tools give you a shortcut to the finished product, but they don’t teach you the mechanics that keep it running.\n\nI’ve learned that going around making big, dramatic changes and additions to things on a whim tends to break them. That must be why “real” developers go through all those steps, like wireframes and detailed feature outlines, before they jump into building.\n\nHere’s an example of one of my tribulations: I built an app called the Earned Secret Excavator. It’s a tool that guides aspiring thought leaders to their unique idea and generates a brief for them to follow to execute that idea, complete with framing—contrarian, narrative, practical, philosophical, etc.—for maximum impact. But as soon as I tried to add the ability for the user to select a different framing from the one the LLM recommended, the whole thing fell apart.\n\nThere's a strange psychological tension that emerges when AI lets you \"build\" rather than buy. I found myself spending hours tweaking my custom-built contact form when I could have used a ready-made solution like Typeform, or even just a mailto: link. The satisfaction of saying \"I built this\" (even if \"I\" mostly involved prompting an AI) can’t replace “I know this is going to work every time”—even though off-the-shelf software comes with built-in analytics, security patches, and user testing that my cobbled-together solutions don’t have.\n\nThis is why I think “build vs. buy” is going to be a big topic of conversation. Everyone will have their own answers to that question, and plenty of people won’t want to spend their one wild and precious life wallowing in code, AI-generated or otherwise. I’m not going to bother building a content repurposing tool, for example—why would I? Spiral gets the job done better than I ever could.\n\nAs our own Danny Aziz, Spiral’s general manager, put it, “Build your ‘little wrapper’ away, anon.” Someone will want to use it.\n\nThe last few weeks have made me realize that there’s a middle ground between total technical illiteracy and full-stack expertise. AI tools like Lovable lower the barrier to entry—not enough to make me a developer overnight, but enough to let me get started, explore, iterate, and at least try to troubleshoot.\n\nThat’s where things are heading—not just for me, but for a lot of people. For years, the work world was divided into two camps:\n\nBefore last month, I had always assumed that gap was insurmountable for someone like me—that if you weren’t fluent in code, you were permanently relegated to the role of “user,” dependent on engineers to build things that make your life easier.\n\nThe rise of vibe coding tools has dramatically widened a messy, in-between space where you have the ability to build just enough, to experiment and tinker without having to commit to years of learning.\n\nI’ve spent years optimizing for ease—sticking to the tools I already knew, outsourcing the things I didn’t. AI has made me rethink that. Because while it’s never been easier to start building, I’m realizing that real leverage comes from understanding how to go further.\n\nI’ve resisted learning to code because it felt like a referendum on the value of my existing skills. Now, I want to learn—because I want to know what’s going on in all those lines of SQL Lovable keeps asking me to approve.\n\nI don’t know if I need to learn to code, necessarily, or if AI’s blazing-fast progress will make it pointless before I’ve gotten very far. But if this is what it feels like to build something for yourself: I want to know what else I’ve been missing.\n\n\n\n\n\nWe build AI tools for readers like you. Automate repeat writing with Spiral. Organize files automatically with Sparkle. Write something great with Lex. Deliver yourself from email with Cora.\n\nWe also do AI training, adoption, and innovation for companies. Work with us to bring AI into your organization.\n\nGet paid for sharing Every with your friends. Join our referral program.",
      "word_count": 1942,
      "images": [
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3490/Screenshot_2025-03-17_at_9.43.52_AM.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3583/thumbnail_03_career_advice.png",
          "description": "",
          "type": "cover"
        },
        {
          "url": "https://d24ovhgu8s7341.cloudfront.net/uploads/post/cover/3468/thumbnail_Screenshot_2025-02-24_at_10.33.50_AM.png",
          "description": "",
          "type": "cover"
        }
      ],
      "column": "working-overtime"
    }
  ]
}